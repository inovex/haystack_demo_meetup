{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LLM applications with **Haystack**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haystack Concepts we will cover:\n",
    "\n",
    "- Nodes\n",
    "- Pipelines\n",
    "- (Agents)\n",
    "- (Document-Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creating our Knowledge-Base : Indexing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haystack, version 1.21.2\n"
     ]
    }
   ],
   "source": [
    "!haystack --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import Crawler, EmbeddingRetriever\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from helper_functions.preprocessor import CustomPreProcessor\n",
    "\n",
    "# Init documentstore with custom \n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"embedding\": {\"type\": \"dense_vector\", \"dims\": 384},\n",
    "            \"authors\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"keyword\"},\n",
    "            \"date\": {\n",
    "                \"type\":   \"date\",\n",
    "                \"format\": \"dd.MM.yyyy\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(index=\"blogs_clean1\", custom_mapping=mapping)\n",
    "\n",
    "# Define nodes\n",
    "crawler = Crawler(\n",
    "    urls=[\"https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/\"],   # Websites to crawl\n",
    "    filter_urls=[\"https://www.inovex.de/de/blog/\"],\n",
    "    crawler_depth=1,    # How many links to follow\n",
    "    output_dir=\"data/blogs_clean1\",  # The directory to store the crawled files, not very important, we don't use the files in this example\n",
    ")\n",
    "\n",
    "preprocessor = CustomPreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=True,\n",
    "    split_by=\"word\",\n",
    "    split_length=200,\n",
    "    split_respect_sentence_boundary=True,\n",
    "    split_overlap=50,\n",
    ")\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "        embedding_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        document_store=document_store,\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_node(component=crawler, name=\"crawler\", inputs=['File'])\n",
    "indexing_pipeline.add_node(component=preprocessor, name=\"preprocessor\", inputs=['crawler'])\n",
    "indexing_pipeline.add_node(component=retriever, name=\"EmbeddingRetriever\", inputs=[\"preprocessor\"])\n",
    "indexing_pipeline.add_node(component=document_store, name=\"document_store\", inputs=['EmbeddingRetriever'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/\n",
      "Ignore https://www.inovex.de/de/blog/\n",
      "Clean https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/\n",
      "Ignore https://www.inovex.de/de/blog/author/tnguyen/\n",
      "Clean https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/\n",
      "Clean https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 4/4 [00:00<00:00, 40.19docs/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3728ee019b294c879dcffb919e1f88a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = indexing_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'documents': [   <Document: {'content': 'This article will elaborate a method for generating abstractive perspective dialogue summarization. Unlike regular dialogue summarization, perspective summarizations aim to outline the point of view of each participant within a dialogue. This work provides an approach to fit datasets intended for regular dialogue summarization to the task of perspective summarizations. It furthermore presents an architecture that can be a solid foundation for this task.\\n\\nIntroductionDefining summarizationMonologue summarizationDialogue summarizationPerspective dialogue summarizationEstablished dialogue summarization methodsData pre-processingDialogSum datasetAcquiring perspective summary annotationsCleaning and correcting the labelsAssigning the labels to the corresponding speakerArchitectureMulti-head encoderTrainingLoss functionSetupResultsDiscussion and future workChallengesFuture workConclusion\\nIntroduction\\nFor centuries humans have been living in a society where conversations are the quintessence of information exchange. In today’s age, this form of communication has been evolving for generations and has become an essential part of what defines our current society. We can therefore assume that it will keep evolving and holding its role as human society continues to grow. While dialogues between humans are a core interaction in our daily life, they not only provide information, result in new insights for all participants and outsiders, but also fulfill our social needs. Hence, conversing between people has many different traits. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 0, '_split_overlap': [{'doc_id': 'e83e81a302c38c522dd948cfb6ab1f99', 'range': (1172, 1541)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '47648771beabbceba1710614e68b700'}>,\n",
      "                     <Document: {'content': 'We can therefore assume that it will keep evolving and holding its role as human society continues to grow. While dialogues between humans are a core interaction in our daily life, they not only provide information, result in new insights for all participants and outsiders, but also fulfill our social needs. Hence, conversing between people has many different traits. These traits can define how getting information across makes the experience more enjoyable, which can hold its amount of valuable information.\\nAlthough relatively young, the research in dialogue summarization has been thriving over the past few years. Some literature has followed various approaches to building automated dialogue summarizers which returned promising results. Most of them are trained on the SAMSum corpus, a dataset containing chat messenger conversations, or corpora such as the AMI business meeting corpus, which includes spoken dialogues in a particular domain such as business meetings. However, both do not reflect the general tone of humans conversing daily. The SAMSum corpus comes closer to dialogues that would be held in our daily life, but they are still chat conversation nonetheless. Past works have generally trained on dialogues that do not reflect our everyday chitchat.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 1, '_split_overlap': [{'doc_id': '47648771beabbceba1710614e68b700', 'range': (0, 369)}, {'doc_id': '5a2ff2c22d2ebee76077bcb15770512f', 'range': (747, 1274)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'e83e81a302c38c522dd948cfb6ab1f99'}>,\n",
      "                     <Document: {'content': 'Most of them are trained on the SAMSum corpus, a dataset containing chat messenger conversations, or corpora such as the AMI business meeting corpus, which includes spoken dialogues in a particular domain such as business meetings. However, both do not reflect the general tone of humans conversing daily. The SAMSum corpus comes closer to dialogues that would be held in our daily life, but they are still chat conversation nonetheless. Past works have generally trained on dialogues that do not reflect our everyday chitchat.\\nIn summer 2021, the DialogSum corpus was released along with its challenge. The dialogues in this dataset are spoken, and about daily topics such as holiday travels, bachelor parties, and so on. At the time of this writing, this is the closest a corpus gets to spoken daily life dialogues and provides a novel challenge for the domain of dialogue summarization. This is crucial as it strongly resembles the dialogues we hold in everyday life and thus can be used more generally. That way, we have access to a large-scale dataset on which no previous work has trained a model. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 2, '_split_overlap': [{'doc_id': 'e83e81a302c38c522dd948cfb6ab1f99', 'range': (0, 527)}, {'doc_id': '45239d6f3bf2af72df989e46fd48e7e', 'range': (723, 1103)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5a2ff2c22d2ebee76077bcb15770512f'}>,\n",
      "                     <Document: {'content': 'At the time of this writing, this is the closest a corpus gets to spoken daily life dialogues and provides a novel challenge for the domain of dialogue summarization. This is crucial as it strongly resembles the dialogues we hold in everyday life and thus can be used more generally. That way, we have access to a large-scale dataset on which no previous work has trained a model. Although past architectures, trained with the SAMSum corpus, have prevailed quite well in general dialogues, there has been no research in summarizing the positions of each participant.\\nDefining summarization\\nMonologue summarization\\nSummarizing according to Merriam Webster, is the action of reducing a given text into a concise and shorter version of it, the summary. In particular, this summary must cover the main points succinctly and should be comprehensive. There is no strict rule about what the process of summarization must look like as it often depends on the original text, its length, and its messages. Therefore summarizing can be done arbitrarily as long as it meets the properties defined above. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 3, '_split_overlap': [{'doc_id': '5a2ff2c22d2ebee76077bcb15770512f', 'range': (0, 380)}, {'doc_id': '7b55c1417ee6e414502a6d338103a7b6', 'range': (750, 1091)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '45239d6f3bf2af72df989e46fd48e7e'}>,\n",
      "                     <Document: {'content': 'In particular, this summary must cover the main points succinctly and should be comprehensive. There is no strict rule about what the process of summarization must look like as it often depends on the original text, its length, and its messages. Therefore summarizing can be done arbitrarily as long as it meets the properties defined above. These properties generalize the task of summarization well enough for dialogue summarization to be not coherently different from general text summarization when it comes to the final results. Merely the process of creating such a summary is inherently more challenging. Translating this task into a problem would look like the following:\\nS = fM(D)\\nwhere S is the output summary, fM\\xa0is the function for summarizing, and D\\xa0is the input document to be summarized. While S is the target to be computed and D an input variable that cannot be controlled, fM remains to be optimized and properly engineered to generate good summaries. Constructing the function fM is the research of text summarization which has shown great results with the help of Deep Learning methods.\\nDialogue summarization\\nMany guidelines and techniques exist for summarizing text in general. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 4, '_split_overlap': [{'doc_id': '45239d6f3bf2af72df989e46fd48e7e', 'range': (0, 341)}, {'doc_id': 'd5a3bff72a67fc08af56e1976f3491cd', 'range': (803, 1199)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '7b55c1417ee6e414502a6d338103a7b6'}>,\n",
      "                     <Document: {'content': 'While S is the target to be computed and D an input variable that cannot be controlled, fM remains to be optimized and properly engineered to generate good summaries. Constructing the function fM is the research of text summarization which has shown great results with the help of Deep Learning methods.\\nDialogue summarization\\nMany guidelines and techniques exist for summarizing text in general. The conceptual process of creating dialogue summaries remains the same as its results. Therefore a formula similar to the one we defined for monologue summarization could be used. However, based on the source dialogues, this process cannot be as easily simplified as it has been barely the case for text summarization. Using therefore fM again would not make much sense here. The summarization function needs to be specialized in summarizing dialogues.\\nS = fD(D)\\nfD denotes the function for summarizing dialogues. When keeping the core differences between monologues and dialogues in focus, it becomes evident that monologue summaries align stylistically very well with their source text as both texts follow a narrative style or an observer-style of text. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 5, '_split_overlap': [{'doc_id': '7b55c1417ee6e414502a6d338103a7b6', 'range': (0, 396)}, {'doc_id': '1190d263180e4b7c3e57040394c930ca', 'range': (773, 1153)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'd5a3bff72a67fc08af56e1976f3491cd'}>,\n",
      "                     <Document: {'content': 'The summarization function needs to be specialized in summarizing dialogues.\\nS = fD(D)\\nfD denotes the function for summarizing dialogues. When keeping the core differences between monologues and dialogues in focus, it becomes evident that monologue summaries align stylistically very well with their source text as both texts follow a narrative style or an observer-style of text. This is not the case for dialogue summarizations, as conversations are transcribed with direct speeches between at least two parties, which does not align with the outcoming abstractive summarizations in terms of linguistic style. Therefore, the input D has to be processed differently from fM as the style for output S will differ a lot from D. Aside from this high-level observation, dialogues are inherently much different from normal documents or monologues as already covered. These differences make it more difficult to reuse fM but do not have a large influence on the overall concept like above mentioned textual style. Finding and optimizing a function fD has been growing as a research field over the past years.\\nPerspective dialogue summarization\\nWe consider perspective dialogue summarization to be a derivative of dialogue summarization related to it. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 6, '_split_overlap': [{'doc_id': 'd5a3bff72a67fc08af56e1976f3491cd', 'range': (0, 380)}, {'doc_id': 'c553c779dd18ee4659e3f925b10cd7e', 'range': (863, 1245)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '1190d263180e4b7c3e57040394c930ca'}>,\n",
      "                     <Document: {'content': 'These differences make it more difficult to reuse fM but do not have a large influence on the overall concept like above mentioned textual style. Finding and optimizing a function fD has been growing as a research field over the past years.\\nPerspective dialogue summarization\\nWe consider perspective dialogue summarization to be a derivative of dialogue summarization related to it. The premise is similar to dialogue summarization as it deals with the same input type. In this case, it is the output that is different. In perspective dialogue summarization, we receive more than one output, i.e., one summary for each dialogue speaker. Assume we have such function fP that accomplishes that, we can say that this problem follows this equation:\\nSP = fP(D)\\nSP = (s1, s2, …, sk)\\nWhere SP is the collection of all generated summaries. si, where i ∈ (1, …, k), denotes a separate summarized view of the i-th person in dialogue D. D is a history of utterances from k person. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 7, '_split_overlap': [{'doc_id': '1190d263180e4b7c3e57040394c930ca', 'range': (0, 382)}, {'doc_id': '836e32516993531a241842324a5fcae0', 'range': (637, 969)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'c553c779dd18ee4659e3f925b10cd7e'}>,\n",
      "                     <Document: {'content': 'Assume we have such function fP that accomplishes that, we can say that this problem follows this equation:\\nSP = fP(D)\\nSP = (s1, s2, …, sk)\\nWhere SP is the collection of all generated summaries. si, where i ∈ (1, …, k), denotes a separate summarized view of the i-th person in dialogue D. D is a history of utterances from k person. In this article, we describe our approach for finding a function fP\\nEstablished dialogue summarization methods\\nThanks to the strong foundation the literature on document summarization has delivered, researchers could leverage these results as a foundation for potential architecture summarizing dialogues. Hence, research in automated dialogue summarization has shown promising results over the past years. All the works we have analyzed in this thesis deliver single outputs and abstractive summaries. We have not found any research on automated dialogue summarizers delivering multiple outputs or abstractive summaries of each speaker’s view and position. Nonetheless, the existing work on dialogue summarization we have found still shows great potential. It thus can be further utilized as a starting point for our goal of achieving automated abstractive perspective dialogue summarization.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 8, '_split_overlap': [{'doc_id': 'c553c779dd18ee4659e3f925b10cd7e', 'range': (0, 332)}, {'doc_id': 'c041e7723f87c5b593e69eb922bef5b3', 'range': (836, 1226)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '836e32516993531a241842324a5fcae0'}>,\n",
      "                     <Document: {'content': 'We have not found any research on automated dialogue summarizers delivering multiple outputs or abstractive summaries of each speaker’s view and position. Nonetheless, the existing work on dialogue summarization we have found still shows great potential. It thus can be further utilized as a starting point for our goal of achieving automated abstractive perspective dialogue summarization.\\nWe investigated three architectures that have shown promising results for dialogue summarization and also claimed state-of-the-art performance at the time of their writing.\\nControllable Abstractive Dialogue Summarization with Sketch Supervision\\nWe refer to this literature as CODS. It generates summarization by constructing so call sketch summarizations before. The authors put lots of emphasis on controllability, as this approach allows the user to define how many sentences the model should generate for summaries. The work can be found on Github.\\nCoreference-Aware Dialogue Summarization\\nThis works leveraged the information coreferences can yield. Given the sentence\\nBill is going home. He just came from work.\\nwe immediately know that the pronoun ‚He‘ refers to the person named ‚Bill‘.  The authors describe these occurrences as co-references and they provide connection to previous sentences and subjects which can benefit the performance for the model. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 9, '_split_overlap': [{'doc_id': '836e32516993531a241842324a5fcae0', 'range': (0, 390)}, {'doc_id': '1cd114e5a9267e8f5818235b150af853', 'range': (943, 1353)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'c041e7723f87c5b593e69eb922bef5b3'}>,\n",
      "                     <Document: {'content': 'Coreference-Aware Dialogue Summarization\\nThis works leveraged the information coreferences can yield. Given the sentence\\nBill is going home. He just came from work.\\nwe immediately know that the pronoun ‚He‘ refers to the person named ‚Bill‘.  The authors describe these occurrences as co-references and they provide connection to previous sentences and subjects which can benefit the performance for the model. Their work can be found here.\\nMulti-View Sequence-to-Sequence Models with Conversational Structure\\nEach participant in a conversation may have an intent. These intents can be detected in the utterances the participant gives. Moreover, dialogues can reach different stages where the topic but also the dynamic between the utterances can change. The authors of this work analyzed dialogues and defined different views from which the stages of each dialogue can be seen. With these multiple views, the architecture is capable of extracting more relevant information from the dialogue. You can find the published work here.\\nData pre-processing\\nDialogSum dataset\\nWith the growing interest and success in the research of dialogue summarization, there were already dialogue datasets. Most existing research used the AMI meeting corpus, which is considered to be small-scale, or the SAMSum dataset, which contains written dialogues. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 10, '_split_overlap': [{'doc_id': 'c041e7723f87c5b593e69eb922bef5b3', 'range': (0, 410)}, {'doc_id': '5cd0fa57b469ccadbc9dc9c8ec40310e', 'range': (993, 1335)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '1cd114e5a9267e8f5818235b150af853'}>,\n",
      "                     <Document: {'content': 'You can find the published work here.\\nData pre-processing\\nDialogSum dataset\\nWith the growing interest and success in the research of dialogue summarization, there were already dialogue datasets. Most existing research used the AMI meeting corpus, which is considered to be small-scale, or the SAMSum dataset, which contains written dialogues. These characteristics bring relevant differences to monologues. With the motivation to provide a corpus that contains spoken dialogue with general topics for them to be closer to our daily life conversations, the authors proposed the DialogSum corpus in May 2021.\\nThe dialogues originated from Dailydialog, MuTual, and DREAM. Dailydialog contains over 13 thousand conversations. Those dialogues were extracted from websites for practicing the English language. MuTual and DREAM are 6,000 and 9,000 transcripted spoken dialogues originating from English listening exam material. The authors complemented the dataset with additional exchanges from speaking practice websites for English learners. Given the origins of these samples, the DialogSum consists mainly of conversations about topics that are present in real life, for instance, business meetings, restaurant reservations, or banking services. However, their origins stem from different sources. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 11, '_split_overlap': [{'doc_id': '1cd114e5a9267e8f5818235b150af853', 'range': (0, 342)}, {'doc_id': '1d07e67ea24c60210d09acf8a3932fa5', 'range': (921, 1295)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5cd0fa57b469ccadbc9dc9c8ec40310e'}>,\n",
      "                     <Document: {'content': 'The authors complemented the dataset with additional exchanges from speaking practice websites for English learners. Given the origins of these samples, the DialogSum consists mainly of conversations about topics that are present in real life, for instance, business meetings, restaurant reservations, or banking services. However, their origins stem from different sources. Since these conversations are intended to help English learners to practice the language, they have clear communication patterns and intents while being of reasonable length.\\nIt was necessary to clean and pre-process the data as they all have a different origin. Non-English characters were omitted, typos and grammatical errors were corrected, and, based on text similarity, duplicates were removed as well. Continuous utterances had to be merged into one longer statement for each conversation. Furthermore, definite names of the speakers were dropped and substituted with tags, i.e., #Person1# and #Person2#. Accumulating the samples and pre-processing them resulted in a corpus of 13,460 dialogues. The authors decided to split the data into a training set with 12,460, a validation set with 500, and a test set with equally many samples as the validation set.\\nAfter that, the dialogues needed to be annotated. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 12, '_split_overlap': [{'doc_id': '5cd0fa57b469ccadbc9dc9c8ec40310e', 'range': (0, 374)}, {'doc_id': 'e3b716465bc09b50fa1662550f511033', 'range': (987, 1289)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '1d07e67ea24c60210d09acf8a3932fa5'}>,\n",
      "                     <Document: {'content': 'Accumulating the samples and pre-processing them resulted in a corpus of 13,460 dialogues. The authors decided to split the data into a training set with 12,460, a validation set with 500, and a test set with equally many samples as the validation set.\\nAfter that, the dialogues needed to be annotated. To ensure the high quality of the annotations, criteria must be met for each annotated summary. It should:\\n\\nconvey the most salient information,\\nbe no longer than 20% of the original conversation length,\\npreserve important named entities within the conversation,\\nbe phrased from an observer’s perspective, and\\nbe phrased in formal language.\\n\\nAt first glance, the third object might contradict the fact that the speaker’s identities are not annotated in the dialogue. However, named entities and co-reference might occur during the speech, thus revealing the identity of a speaker. This name should be considered in the annotation and might be an essential factor in the information or semantic comprehension in the summary. If no name is mentioned in the dialogue, the previously defined tags should be used instead in the label. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 13, '_split_overlap': [{'doc_id': '1d07e67ea24c60210d09acf8a3932fa5', 'range': (0, 302)}, {'doc_id': 'cffa73298242e59ea0958df926528fbd', 'range': (770, 1132)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'e3b716465bc09b50fa1662550f511033'}>,\n",
      "                     <Document: {'content': 'However, named entities and co-reference might occur during the speech, thus revealing the identity of a speaker. This name should be considered in the annotation and might be an essential factor in the information or semantic comprehension in the summary. If no name is mentioned in the dialogue, the previously defined tags should be used instead in the label. Annotators with degrees in English Linguistics or Applied Linguistics were hired to write the summaries for the DialogSum corpus. We also refer to the annotated summaries as gold labels. On top of the criteria, those annotators were required to give heed to a set of aspects.\\nTense Consistency: The summaries should observe the conversation as if they were held in\\xa0present time and thus use proper tense for events before and after the dialogue.\\nDiscourse Relation: Summarized events can hold relevant discourse and causal relations. The summary should preserve these relations when present.\\nEmotions: Compared to monologues with a neutral position, such as newspaper and academic articles, social conversations are often set with emotions. Important emotions related to the events of the conversation should also be explicitly described in the gold label.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 14, '_split_overlap': [{'doc_id': 'e3b716465bc09b50fa1662550f511033', 'range': (0, 362)}, {'doc_id': '92c0d45ab533014a5bda6bf56917797b', 'range': (809, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'cffa73298242e59ea0958df926528fbd'}>,\n",
      "                     <Document: {'content': 'Discourse Relation: Summarized events can hold relevant discourse and causal relations. The summary should preserve these relations when present.\\nEmotions: Compared to monologues with a neutral position, such as newspaper and academic articles, social conversations are often set with emotions. Important emotions related to the events of the conversation should also be explicitly described in the gold label.\\nIntent Identification: The summary should describe the outcomes of the dialogue and the speakers‘ intents when identifiable.\\nIn addition to these quality criteria, the labels underwent extra quality control. By using cross-validation between different annotators twice, the annotations were checked until they met the requirements. In case of insufficient quality, the annotators were asked to re-annotate the respective dialogue. The authors paid extra attention to the test set and let it get annotated three times by three different annotators. Then they compared these summaries by calculating pair-wise ROUGE scores. As a result, the annotators might have used different linguistic styles but still overlapped largely in the logical order and primary content. An additional jury was hired to perform a human evaluation on the DialogSum data. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 15, '_split_overlap': [{'doc_id': 'cffa73298242e59ea0958df926528fbd', 'range': (0, 410)}, {'doc_id': 'fc71db57845c6db7f45a5d9bbb74ad7f', 'range': (842, 1257)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '92c0d45ab533014a5bda6bf56917797b'}>,\n",
      "                     <Document: {'content': 'The authors paid extra attention to the test set and let it get annotated three times by three different annotators. Then they compared these summaries by calculating pair-wise ROUGE scores. As a result, the annotators might have used different linguistic styles but still overlapped largely in the logical order and primary content. An additional jury was hired to perform a human evaluation on the DialogSum data. They were faced with 50 randomly chosen dialogues and their respective summaries from the test set and had to give a rating from one to five, with five being the highest possible score.\\nAcquiring perspective summary annotations\\nIn this section, we explain how we preprocess the data for further steps in particular how we prepare the labels so that they can be used for perspective dialogue summarization.\\nSince the dialogues and labels are all in English, English grammar can be leveraged to split the summaries. Most sentences usually have at least a subject in combination with a verb. There can be other segments as well, such as time, adverbs, locations, or sub-sentences which, again, follow the same rule. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 16, '_split_overlap': [{'doc_id': '92c0d45ab533014a5bda6bf56917797b', 'range': (0, 415)}, {'doc_id': '6034d8a85bfc40956d4fe56b6efd9a83', 'range': (822, 1128)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'fc71db57845c6db7f45a5d9bbb74ad7f'}>,\n",
      "                     <Document: {'content': 'Since the dialogues and labels are all in English, English grammar can be leveraged to split the summaries. Most sentences usually have at least a subject in combination with a verb. There can be other segments as well, such as time, adverbs, locations, or sub-sentences which, again, follow the same rule. With the help of a part of speech (POS) tagger, we were able to classify each segment of every sentence in each summary.\\nWe used the constituency parser with ELMo embeddings as it has shown good evaluation results. It was trained on the Penn Treebank corpus, which is also a guide to understanding the POS tagger’s output. The sentences were output in a tree-like structure, with the token S, denoting the part of speech ‚Sentence‘ as a root node. This structure helps us to split the sentences accordingly. We first start by extracting the sub-sentences. Often sentences can consist of multiple other nested sentences, which we refer to as sub-sentences. It is important to note that sub-sentences appear in many different forms and might be whole sentences. The constituency parser does a decent job of detecting those, yet it is not entirely accurate. Therefore extra heuristics were necessary. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 17, '_split_overlap': [{'doc_id': 'fc71db57845c6db7f45a5d9bbb74ad7f', 'range': (0, 306)}, {'doc_id': 'a4292ef8eb2d436ecd365661b4dd2fa2', 'range': (863, 1204)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '6034d8a85bfc40956d4fe56b6efd9a83'}>,\n",
      "                     <Document: {'content': 'Often sentences can consist of multiple other nested sentences, which we refer to as sub-sentences. It is important to note that sub-sentences appear in many different forms and might be whole sentences. The constituency parser does a decent job of detecting those, yet it is not entirely accurate. Therefore extra heuristics were necessary. To find the sub-sentences, we took every part labeled as Sentence (S) except for the root, i.e., the complete sentence itself.\\nAdditionally, we looked for Coordinating Conjunctions (CC) as their primary function is to connect two sentences. The POS that appears after the conjunction will be considered a sentence. This approach results in sub-sentences that seem to be evident as such. However, there are other indications of sub-sentences except for conjunctions. Due to some inconsistencies in the results of the constituency parser, it is still possible for some of the extracted sentences, to begin with ‚and‘ which is relatively uncommon in English speeches. We wanted the sentences to be independent as necessary and therefore omit ‚and‘ as a part of the sentence. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 18, '_split_overlap': [{'doc_id': '6034d8a85bfc40956d4fe56b6efd9a83', 'range': (0, 341)}, {'doc_id': 'f082b41843a8332271a2c1357d0df69a', 'range': (808, 1113)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a4292ef8eb2d436ecd365661b4dd2fa2'}>,\n",
      "                     <Document: {'content': 'Due to some inconsistencies in the results of the constituency parser, it is still possible for some of the extracted sentences, to begin with ‚and‘ which is relatively uncommon in English speeches. We wanted the sentences to be independent as necessary and therefore omit ‚and‘ as a part of the sentence. Splitting these sentences results in a more extensive set of sentences that all follow the same rules of English grammar to be a complete sentence. We use these extracted sentences for further processing.\\nGrammatically, it is possible for subordinate clauses to be standalone sentences. Therefore we extract certain subordinate clauses from each subsentence we have got at this point. The POS parser is capable of detecting subordinate clauses and tags them with ‚SBAR‘. For clauses, it is also necessary to only extract all segments that make it possible for the clauses to be able to stand as single sentences. For example, the sentence\\n(S I can’t believe (SBAR that John went without me.))\\ncontains the tags S and SBAR. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 19, '_split_overlap': [{'doc_id': 'a4292ef8eb2d436ecd365661b4dd2fa2', 'range': (0, 305)}, {'doc_id': '3baae8f3871026414ed02e921305811d', 'range': (691, 1028)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f082b41843a8332271a2c1357d0df69a'}>,\n",
      "                     <Document: {'content': 'The POS parser is capable of detecting subordinate clauses and tags them with ‚SBAR‘. For clauses, it is also necessary to only extract all segments that make it possible for the clauses to be able to stand as single sentences. For example, the sentence\\n(S I can’t believe (SBAR that John went without me.))\\ncontains the tags S and SBAR. It is evident that the whole sentence can be without a doubt classified with S. The segment covering the fact, that John went without the speaker is a subordinate clause that starts with ‚that‘. Extracting the clause as it is would result in\\nthat John went without me.\\nwhich is not a sentence that can stand alone. Removing the relative pronoun would make it a real sentence and does not affect the meaning, even if it was still connected with the original sentence:\\nJohn went without me.\\n(S I can’t believe (SBAR John went without me.))\\nIt was therefore necessary to define a set of what we call dependent prepositions. These prepositions are conjunctions such as the one in the previous example ‚that‘ which functioned as a relative pronoun. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 20, '_split_overlap': [{'doc_id': 'f082b41843a8332271a2c1357d0df69a', 'range': (0, 337)}, {'doc_id': 'f78d4d97f3d073c20e7226e6c727b099', 'range': (653, 1081)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '3baae8f3871026414ed02e921305811d'}>,\n",
      "                     <Document: {'content': 'Removing the relative pronoun would make it a real sentence and does not affect the meaning, even if it was still connected with the original sentence:\\nJohn went without me.\\n(S I can’t believe (SBAR John went without me.))\\nIt was therefore necessary to define a set of what we call dependent prepositions. These prepositions are conjunctions such as the one in the previous example ‚that‘ which functioned as a relative pronoun. The dependent prepositions cannot be removed from the clause, unlike in the previous example, as this would alter the meaning of the clause. Moreover, these prepositions often refer to another segment of the same sentence which is also reflected in their meaning. We created a set of dependent prepositions based on the explored data:\\nif, though, before, although, beside, besides, despite, during, unless, until, via, upon, unlike, like, with, within, without, because\\nWe are aware that there could be many more words that would fall in this category, however, this set should be large enough to cover most of the subordinal clauses and diving deeper into this problem is out of the scope of this thesis.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 21, '_split_overlap': [{'doc_id': '3baae8f3871026414ed02e921305811d', 'range': (0, 428)}, {'doc_id': 'cd882dcb26e74aaa4868f2fb7c469d9', 'range': (693, 1134)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f78d4d97f3d073c20e7226e6c727b099'}>,\n",
      "                     <Document: {'content': 'We created a set of dependent prepositions based on the explored data:\\nif, though, before, although, beside, besides, despite, during, unless, until, via, upon, unlike, like, with, within, without, because\\nWe are aware that there could be many more words that would fall in this category, however, this set should be large enough to cover most of the subordinal clauses and diving deeper into this problem is out of the scope of this thesis.\\nBy now, all subordinate clauses that have been detected by the constituency parser have been gathered. However, there are still other cases where one could find such a clause. In general, every sentence has at least a subject combined with a verb. Therefore, it would suffice to find segments that fulfill this criterion. Subjects are usually referred to as either nouns (NN, NP, NNP) or personal pronouns (PP). Thus, we can easily detect potential clauses by finding children in the constituency tree that are either a noun or a pronoun. Those are the starting segments of the clause. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 22, '_split_overlap': [{'doc_id': 'f78d4d97f3d073c20e7226e6c727b099', 'range': (0, 441)}, {'doc_id': '7aee4fc658e25ee5f367a2ff52f47225', 'range': (690, 1027)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'cd882dcb26e74aaa4868f2fb7c469d9'}>,\n",
      "                     <Document: {'content': 'Therefore, it would suffice to find segments that fulfill this criterion. Subjects are usually referred to as either nouns (NN, NP, NNP) or personal pronouns (PP). Thus, we can easily detect potential clauses by finding children in the constituency tree that are either a noun or a pronoun. Those are the starting segments of the clause. Consider the following extract of a tagged summary:\\n(S\\n(NP (NNP Doctor) (NNP Hawkins))\\n(VP\\n(VP\\n(VBZ advises)\\n(NP (PRP him))\\n(S\\n(VP\\n(TO to)\\n(VP (VB have) (NP (CD one)) (NP (DT every) (NN year))))))\\n(. .)\\n…\\nThe segment Doctor Hawkins is the subject labeled NP and marks the beginning of the candidate clause. After that, it is still necessary to determine how many subsequent segments need to be added to the potential clause. Whenever another conjunction like and or another clause gets classified as SBAR, one can consider that until this point, the clause in question can be used in a sentence and added to the previously extracted sentences. Analogously, when the next tagged segment right from the candidate clause is not labeled with SBAR it is not a new subordinate clause. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 23, '_split_overlap': [{'doc_id': 'cd882dcb26e74aaa4868f2fb7c469d9', 'range': (0, 337)}, {'doc_id': '2321ac0db69a5b52d8f2116f3bd9e8e1', 'range': (763, 1116)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '7aee4fc658e25ee5f367a2ff52f47225'}>,\n",
      "                     <Document: {'content': 'Whenever another conjunction like and or another clause gets classified as SBAR, one can consider that until this point, the clause in question can be used in a sentence and added to the previously extracted sentences. Analogously, when the next tagged segment right from the candidate clause is not labeled with SBAR it is not a new subordinate clause. This is also the case whenever adverbs (ADVP), adjectives (JJ, JJR, JJS), verbs (VP, VBP), and other pronouns are the next right segment as they were usually a grammatical object when the subject was found in a previous part.\\nIn the extract above, we already detected a subject, Doctor Hawkins. Thus, the clause starts with „Doctor Hawkins …“. Sentences are read from left to right in the English language, and we can therefore flatten the constituency tree as follows:\\n(NP (NNP Doctor) (NNP Hawkins)) (VP (VP (VBZ advises) (NP (PRP him)) …\\nIt is now evident that the next segment is not labeled with SBAR or S but with VP. That means the next segments are not a new clause and therefore belong to the previous segment, i.e.', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 24, '_split_overlap': [{'doc_id': '7aee4fc658e25ee5f367a2ff52f47225', 'range': (0, 353)}, {'doc_id': 'a91ede2a3b248f747e2b387f6248e89c', 'range': (698, 1077)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '2321ac0db69a5b52d8f2116f3bd9e8e1'}>,\n",
      "                     <Document: {'content': 'Sentences are read from left to right in the English language, and we can therefore flatten the constituency tree as follows:\\n(NP (NNP Doctor) (NNP Hawkins)) (VP (VP (VBZ advises) (NP (PRP him)) …\\nIt is now evident that the next segment is not labeled with SBAR or S but with VP. That means the next segments are not a new clause and therefore belong to the previous segment, i.e., it is part of the clause we have built so far for this example. Therefore we concatenate the segment to our current clause:\\nDoctor Hawkins advises him to have one every year.\\nConsider another tagged extract of a summary:\\n(NP ($ #) (NN Person1) (NNS #))\\n(VP (VBZ ’s) (ADJP (JJ angry)))\\n(SBAR\\n(IN because)\\n(S\\n(NP ($ #) (NNP Person2) (NN #))\\n…\\nIn this example, at the highest level of the parsed tree, we have got the labels NP, VP, SBAR. By following our approach, we get the subordinate clause\\n#Person1#’s angry.\\nThe subsequent segments that appear after the one labeled VP are processed independently as separate clauses because the next segment is labeled SBAR.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 25, '_split_overlap': [{'doc_id': '2321ac0db69a5b52d8f2116f3bd9e8e1', 'range': (0, 379)}, {'doc_id': 'bae5745b1573a8bc230600be11316988', 'range': (557, 1044)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a91ede2a3b248f747e2b387f6248e89c'}>,\n",
      "                     <Document: {'content': 'Consider another tagged extract of a summary:\\n(NP ($ #) (NN Person1) (NNS #))\\n(VP (VBZ ’s) (ADJP (JJ angry)))\\n(SBAR\\n(IN because)\\n(S\\n(NP ($ #) (NNP Person2) (NN #))\\n…\\nIn this example, at the highest level of the parsed tree, we have got the labels NP, VP, SBAR. By following our approach, we get the subordinate clause\\n#Person1#’s angry.\\nThe subsequent segments that appear after the one labeled VP are processed independently as separate clauses because the next segment is labeled SBAR.\\nThese clauses are standalone sentences that will be used as summaries for every person after further data cleaning, preprocessing, and assignment.\\nCleaning and correcting the labels\\nAs mentioned earlier, the constituency parser does not work completely accurately and we also consider that our approach for splitting the labels has its flaws. During the process of creating the new annotations, we found several cases where we had to simply hardcode the proper summaries. There were cases where the sentence was cut off or not properly structured. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 26, '_split_overlap': [{'doc_id': 'a91ede2a3b248f747e2b387f6248e89c', 'range': (0, 487)}, {'doc_id': '249e8f579ddcb5a61814bd8b5972df7e', 'range': (635, 1035)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'bae5745b1573a8bc230600be11316988'}>,\n",
      "                     <Document: {'content': 'Cleaning and correcting the labels\\nAs mentioned earlier, the constituency parser does not work completely accurately and we also consider that our approach for splitting the labels has its flaws. During the process of creating the new annotations, we found several cases where we had to simply hardcode the proper summaries. There were cases where the sentence was cut off or not properly structured. It was also necessary to remove the whitespaces which were inserted by the POS tagger, as suffixes such as ‚ll or ’s or special characters like hyphens (-) or dots (.) were also classified separately. For the suffixes, we simply removed the whitespace in front of them. In the case of hyphens, whitespaces before and after them had to be omitted. Dots were completely erased as they are also often part of titles such as Dr or Ms, denote the end of a sentence, or act as the decimal point in numbers like in the following example:\\nShe has a GPA 3.92.\\nFor this particular sentence, our approach even split it into two separate sentences. This was caused by the POS model constructing the constituency tree as the following one:\\n(S she has a GPA 3. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 27, '_split_overlap': [{'doc_id': 'bae5745b1573a8bc230600be11316988', 'range': (0, 400)}, {'doc_id': 'ec6b2e4ae3ca4968615319bbf8e7a070', 'range': (748, 1147)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '249e8f579ddcb5a61814bd8b5972df7e'}>,\n",
      "                     <Document: {'content': 'Dots were completely erased as they are also often part of titles such as Dr or Ms, denote the end of a sentence, or act as the decimal point in numbers like in the following example:\\nShe has a GPA 3.92.\\nFor this particular sentence, our approach even split it into two separate sentences. This was caused by the POS model constructing the constituency tree as the following one:\\n(S she has a GPA 3. (S 92.))\\nThis was one sample where we had to manually correct it to a proper summary, too. These dots can cause problems when getting treated like the regular end of sentence tokens since for those, it would make sense to keep whitespace after the dot, but not for decimal numbers. We manually inserted them at the end of each sentence again. There were also cases where single dots were classified as a sentence. We removed these entries from our annotation set thus resulting in a set of summaries that were split into single, shorter sentences.\\nAssigning the labels to the corresponding speaker\\nWith the subordinate clauses extracted as independent sentences, the next step was to assign them to \\\\textit{Person1} and \\\\textit{Person2} accordingly.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 28, '_split_overlap': [{'doc_id': '249e8f579ddcb5a61814bd8b5972df7e', 'range': (0, 399)}, {'doc_id': 'ee4dff1c438cc1be73d6693e93108f14', 'range': (743, 1149)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ec6b2e4ae3ca4968615319bbf8e7a070'}>,\n",
      "                     <Document: {'content': 'There were also cases where single dots were classified as a sentence. We removed these entries from our annotation set thus resulting in a set of summaries that were split into single, shorter sentences.\\nAssigning the labels to the corresponding speaker\\nWith the subordinate clauses extracted as independent sentences, the next step was to assign them to \\\\textit{Person1} and \\\\textit{Person2} accordingly.\\nAs mentioned in the section for acquiring the labels, our sentences always contain a subject. These subjects can be either\\n\\n„#Person1#“ or „#Person2#“,\\na name,\\nor a personal pronoun\\n\\nIn the former two cases, it is trivial how to assign the sentence properly. Personal pronouns are used as a coreference and there imply a reference to the previous sentence. Since the sentences are in chronological order, i.e., the order when they appear has not been altered in the previous process, we assign sentences with a pronoun to the person the previous sentence has been assigned to. Assigning sentences where the grammatical subject is a name is more complicated than in the earlier two cases.\\nBefore assigning all extracted clauses to the speakers, we used a Named Entitiy Recognition (NER) model based on ELMo embeddings. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 29, '_split_overlap': [{'doc_id': 'ec6b2e4ae3ca4968615319bbf8e7a070', 'range': (0, 406)}, {'doc_id': 'f908d9a44327ea35d3ac7e9c39d42e78', 'range': (816, 1224)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ee4dff1c438cc1be73d6693e93108f14'}>,\n",
      "                     <Document: {'content': ', the order when they appear has not been altered in the previous process, we assign sentences with a pronoun to the person the previous sentence has been assigned to. Assigning sentences where the grammatical subject is a name is more complicated than in the earlier two cases.\\nBefore assigning all extracted clauses to the speakers, we used a Named Entitiy Recognition (NER) model based on ELMo embeddings. We discovered that in our samples the token Person caused the model to output ambiguous, inconsistent classifications. Additionally, there are issues with occurrences of # as well. Therefore, before performing named entity recognition, it was necessary to substitute all occurrences of #Person1# and #Person2# to XYZ1 and XYZ2 respectively as this will guarantee that the NER model will not recognize these entities as Persons or Organization, i.e.,\\xa0label them with O. Afterwards, we executed NER on all sentences and converted all names that were found to only lower case characters and kept them in a set. Then we added xyz1 and xzy2 to the set as well. This set of all occurring names will be crucial for assigning the labels. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 30, '_split_overlap': [{'doc_id': 'ee4dff1c438cc1be73d6693e93108f14', 'range': (0, 408)}, {'doc_id': '4cd1c49cdbec6abe00937e5bee9e9fdc', 'range': (857, 1138)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f908d9a44327ea35d3ac7e9c39d42e78'}>,\n",
      "                     <Document: {'content': ',\\xa0label them with O. Afterwards, we executed NER on all sentences and converted all names that were found to only lower case characters and kept them in a set. Then we added xyz1 and xzy2 to the set as well. This set of all occurring names will be crucial for assigning the labels. Since all occurrences of #Person1# and #Person2# have been changed, we need to assign sentences with XYZ1 and XYZ2 to the speakers accordingly. It is quite common that names are mentioned in spoken conversations. We generalize the intention of this into three cases:\\n\\nIntroducing oneself\\nDirectly speaking to a person, for example:\\xa0Hey Daniel! Can you help me?\\nTalking about another party that is not part of the dialogue, for instance: Have you seen Sara’s dog?\\n\\nIf a speaker introduces themselves, the most used clauses are\\n„I am“, „I’m“, „name is“, „name’s“\\nFinding the name in the summary sentence in combination with one of these clauses automatically assigns the summary sentence to the speaker who said the clause. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 31, '_split_overlap': [{'doc_id': 'f908d9a44327ea35d3ac7e9c39d42e78', 'range': (0, 281)}, {'doc_id': 'ecd2182172d1bcde4cb0a61a870ea9e1', 'range': (643, 1003)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '4cd1c49cdbec6abe00937e5bee9e9fdc'}>,\n",
      "                     <Document: {'content': 'Talking about another party that is not part of the dialogue, for instance: Have you seen Sara’s dog?\\n\\nIf a speaker introduces themselves, the most used clauses are\\n„I am“, „I’m“, „name is“, „name’s“\\nFinding the name in the summary sentence in combination with one of these clauses automatically assigns the summary sentence to the speaker who said the clause. If, however, the name is mentioned in an utterance without an introductory clause, then that means that the speaker does not introduce themselves and the sentence gets therefore assigned to the other person. This is a rather generalized approach to solving this problem as there are some exceptional cases. For example,\\nHave you seen Sara’s dog?\\nclearly does not imply any form of introduction or directly speaking to the other person. In these cases, the speaker is talking about another party that is not present in this conversation. Another challenge is that it is difficult to catch all forms of introductions. In our method, both\\nHer name is Jessica.\\nand\\nThe name’s John.\\nimply that the speakers are introducing themselves although in the first example the speaker clearly introduces a third party. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 32, '_split_overlap': [{'doc_id': '4cd1c49cdbec6abe00937e5bee9e9fdc', 'range': (0, 360)}, {'doc_id': '44069b058cd54c5d77acab0b0898a2f8', 'range': (797, 1165)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ecd2182172d1bcde4cb0a61a870ea9e1'}>,\n",
      "                     <Document: {'content': 'In these cases, the speaker is talking about another party that is not present in this conversation. Another challenge is that it is difficult to catch all forms of introductions. In our method, both\\nHer name is Jessica.\\nand\\nThe name’s John.\\nimply that the speakers are introducing themselves although in the first example the speaker clearly introduces a third party. Introductions are often not clear in dialogues as it can be seen in the following example:\\n#Person1#: Who am I talking with?\\n#Person2#: This is Jane speaking.\\nCovering all forms of self-introduction is a major challenge and is out of scope for this article.\\nWe mentioned earlier that sentences with a pronoun will be assigned to the person that the previous sentence got assigned. The main exception here are the pronouns they and their. Sentences with subjects that were referred to with these pronouns were assigned to both parties. All sentences that could not be assigned by our methods were assigned to both speakers. After all labels were assigned, we changed the tokens XYZ1 and XYZ2 back to #Person1# and #Person2#.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 33, '_split_overlap': [{'doc_id': 'ecd2182172d1bcde4cb0a61a870ea9e1', 'range': (0, 368)}, {'doc_id': 'ddff458e141a9307e8305d5c44112507', 'range': (750, 1092)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '44069b058cd54c5d77acab0b0898a2f8'}>,\n",
      "                     <Document: {'content': 'The main exception here are the pronouns they and their. Sentences with subjects that were referred to with these pronouns were assigned to both parties. All sentences that could not be assigned by our methods were assigned to both speakers. After all labels were assigned, we changed the tokens XYZ1 and XYZ2 back to #Person1# and #Person2#.\\nThe previous sections covered the creation of our new DialogSum dataset which now contains summaries for each person in each dialogue. We simply add these new labels to the corresponding dialogue from which the sentences of the annotation originated. The following example gives an idea of what the labels look like:\\nsummaries: {\\n„Person1“: „#Person1# thinks the rent is expensive. #Person1 disagrees.“,\\n„Person2“: „#Person2# lists the advantages of the house Person1 wants to rent. #Person2# suggests sharing it to decrease the total amount of the rent. #Person2# tells #Person1# it helps to save money on fares, and #Person1#’ll think about it.\\n}Architecture\\nMulti-headed neural networks have an adequate backbone network that has learned the salient features of the input data. As the name suggests, multiple different output heads are attached at the end of this backbone. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 34, '_split_overlap': [{'doc_id': '44069b058cd54c5d77acab0b0898a2f8', 'range': (0, 342)}, {'doc_id': '5877061fd8805811b779ec0db94edb2a', 'range': (898, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ddff458e141a9307e8305d5c44112507'}>,\n",
      "                     <Document: {'content': '#Person2# tells #Person1# it helps to save money on fares, and #Person1#’ll think about it.\\n}Architecture\\nMulti-headed neural networks have an adequate backbone network that has learned the salient features of the input data. As the name suggests, multiple different output heads are attached at the end of this backbone. The salient information the backbone has been trained on is forwarded to each head while each head is trained on its task. The following figure shows an example from a multi-headed neural network with two heads.\\n\\nAdditionally, each head has its different task, either regression or classification. Thus, the neural network returns two different outputs.\\nWe leveraged the fact that a multi-headed neural network returns two different results as this is congruent with our goal to generate two distinct summaries for a single input dialogue. Therefore, we will plug in two heads to a dialogue summarization model. However, unlike the example from the previously shown image we are not training two completely different tasks since both outputs are of the same type of task, i.e., both outputs are abstractive summaries. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 35, '_split_overlap': [{'doc_id': 'ddff458e141a9307e8305d5c44112507', 'range': (0, 321)}, {'doc_id': '11c0ad1665504525586f461753181d20', 'range': (676, 1139)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5877061fd8805811b779ec0db94edb2a'}>,\n",
      "                     <Document: {'content': 'We leveraged the fact that a multi-headed neural network returns two different results as this is congruent with our goal to generate two distinct summaries for a single input dialogue. Therefore, we will plug in two heads to a dialogue summarization model. However, unlike the example from the previously shown image we are not training two completely different tasks since both outputs are of the same type of task, i.e., both outputs are abstractive summaries. We aimed for heads specifically trained on one single speaker and therefore only generated a summary for a single speaker. We modified the encoder of our baseline architecture by adding two additional heads. These two heads then lead back to one common decoder that generates the summaries for each speaker. From the point where the encoder splits into two heads, we passed each encoding separately to the decoder and used our annotations for each person for calculating the loss respectively.\\nMulti-head encoder\\nAs mentioned above, we only modified the encoder in order to use further encode the learned features within the context of the annotated summary of a single person. The following figure displays the architecture we have described.\\n\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 36, '_split_overlap': [{'doc_id': '5877061fd8805811b779ec0db94edb2a', 'range': (0, 463)}, {'doc_id': '6fe00a005a1f2d4c6d4c44e709c1beb6', 'range': (772, 1208)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '11c0ad1665504525586f461753181d20'}>,\n",
      "                     <Document: {'content': 'From the point where the encoder splits into two heads, we passed each encoding separately to the decoder and used our annotations for each person for calculating the loss respectively.\\nMulti-head encoder\\nAs mentioned above, we only modified the encoder in order to use further encode the learned features within the context of the annotated summary of a single person. The following figure displays the architecture we have described.\\n\\nEach copy is a hard copy of the very last encoder layer and, therefore, initialized with identical weights. We used the BART encoder that was trained in the works of CODS\\xa0 as the backbone for our encoder. Since both additional encoder heads are copied from the last layer of the backbone, they also share the same internal architecture as BART Layers, as shown here\\n\\nFurthermore, the encoding process can be then formulated as\\nH = EBART({x0, x1, …, xn})\\nHk = Ek(H),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\nwhere EBART describes the BART encoding of n tokens xi and Ek denotes the additional encoding process for the k-th head respectively as shown in the figure above. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 37, '_split_overlap': [{'doc_id': '11c0ad1665504525586f461753181d20', 'range': (0, 436)}, {'doc_id': '297c528e05971947b33a12b8c58f4848', 'range': (642, 1080)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '6fe00a005a1f2d4c6d4c44e709c1beb6'}>,\n",
      "                     <Document: {'content': 'Since both additional encoder heads are copied from the last layer of the backbone, they also share the same internal architecture as BART Layers, as shown here\\n\\nFurthermore, the encoding process can be then formulated as\\nH = EBART({x0, x1, …, xn})\\nHk = Ek(H),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\nwhere EBART describes the BART encoding of n tokens xi and Ek denotes the additional encoding process for the k-th head respectively as shown in the figure above. We only applied the idea of multi-headed neural networks in the encoder as we aimed to increase parameters as little as possible. We also do not want the model to learn anything different for the summary generation part as the style of outputs for regular dialogue summarization, and each summary of a single person should be similar. Thus, we left the decoder part as it is. Again, we used a BART decoder for fine-tuning from the works CODS which has been trained on the SAMSum datasets. The following equation completes the encoder-decoder process of our approach:\\nYk = DBART(Hk)\\nYk = (y0,k, …, ym,k),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\n\\nYkis the sequence of tokens yi,k for person k acquired from the decoder DBART. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 38, '_split_overlap': [{'doc_id': '6fe00a005a1f2d4c6d4c44e709c1beb6', 'range': (0, 438)}, {'doc_id': 'b705f8e514a3f127328414daea753d44', 'range': (815, 1137)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '297c528e05971947b33a12b8c58f4848'}>,\n",
      "                     <Document: {'content': 'Again, we used a BART decoder for fine-tuning from the works CODS which has been trained on the SAMSum datasets. The following equation completes the encoder-decoder process of our approach:\\nYk = DBART(Hk)\\nYk = (y0,k, …, ym,k),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\n\\nYkis the sequence of tokens yi,k for person k acquired from the decoder DBART. The decoder processed the encodings Hk from each of the k heads separately. In our environment, H1 and H2 as well as Y1 and Y2 were not computed concurrently but sequentially.\\nTraining\\nLoss function\\nSince we have two different outputs for the DialogSum dataset, conventional training and computation of the loss are not possible. The significant difference is that we receive two results from the neural network and have two labels for computing the loss. It is important to incorporate both outputs in the training process and to ensure that the outputs and the weights of both new encoder heads, given that the weight initialization is equal for all components, also differ from each other.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 39, '_split_overlap': [{'doc_id': '297c528e05971947b33a12b8c58f4848', 'range': (0, 322)}, {'doc_id': '433d4507782aed5e9e4a49c16e07df4c', 'range': (653, 1015)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'b705f8e514a3f127328414daea753d44'}>,\n",
      "                     <Document: {'content': 'The significant difference is that we receive two results from the neural network and have two labels for computing the loss. It is important to incorporate both outputs in the training process and to ensure that the outputs and the weights of both new encoder heads, given that the weight initialization is equal for all components, also differ from each other.\\nDuring training, we calculated the loss for each single encoder output and then used the maximum of both to punish the model for the worse performing head and thus making the learning process more challenging. We chose the Cross-Entropy loss function and obtained the following equations for the loss:\\nCE(Y, Ȳ) = –∑yi ·log ȳi\\nLk = CE(Yk, Ȳk}),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\nLE = max(L1, L2)\\nwhere CE(Y, Ȳ) is the Cross-Entropy loss function, Lk denotes the loss that the k-th encoder head causes. Note that Lk includes the output from the decoder instead of only the encoder head. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 40, '_split_overlap': [{'doc_id': 'b705f8e514a3f127328414daea753d44', 'range': (0, 362)}, {'doc_id': '193b00b5b855711ca96fde93155c27b1', 'range': (573, 928)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '433d4507782aed5e9e4a49c16e07df4c'}>,\n",
      "                     <Document: {'content': 'We chose the Cross-Entropy loss function and obtained the following equations for the loss:\\nCE(Y, Ȳ) = –∑yi ·log ȳi\\nLk = CE(Yk, Ȳk}),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\nLE = max(L1, L2)\\nwhere CE(Y, Ȳ) is the Cross-Entropy loss function, Lk denotes the loss that the k-th encoder head causes. Note that Lk includes the output from the decoder instead of only the encoder head. We then acquire the loss LE as described above with the label Ȳk for person k. We compared the similarity between the encoded outputs and multiplied them with a penalizing parameter γ, which acts as a weight for considering the similarity in the loss function. We sum the product with LE to penalize the learning process accordingly if the outputs are too similar.\\nS = mean(SIM(H1, H2))\\nL = LE + γS\\nSIM is the similarity function from which we additionally calculate the mean for the score S to be a scalar still representative of similarity. For SIM we chose cosine similarity. This computes the total loss L from which it is now possible to acquire the training gradients.\\nSetup\\nFor training, we used the weights from the pre-trained CODS architecture. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 41, '_split_overlap': [{'doc_id': '433d4507782aed5e9e4a49c16e07df4c', 'range': (0, 355)}, {'doc_id': '9b39b2ed5b0e78c4325029bec100c863', 'range': (721, 1110)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '193b00b5b855711ca96fde93155c27b1'}>,\n",
      "                     <Document: {'content': 'S = mean(SIM(H1, H2))\\nL = LE + γS\\nSIM is the similarity function from which we additionally calculate the mean for the score S to be a scalar still representative of similarity. For SIM we chose cosine similarity. This computes the total loss L from which it is now possible to acquire the training gradients.\\nSetup\\nFor training, we used the weights from the pre-trained CODS architecture. We left most of the parameters to the default, which its authors have set; for instance, we used learning rate 5e-5. We trained the model with AdamW and set our penalizing parameter γ to 0.8. Early stopping was implemented, yet, we set the patience parameter to a higher number since the task itself is somewhat more abstract. We wanted to observe the learning behavior, particularly the behavior of the validation metrics, in a longer training process. Therefore, we set patience to 100 and trained the model for 107 epochs in total where we also saved the checkpoints. For validation, we used the ROUGE-1 F1-score to measure the model’s performance on the validation set over time. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 42, '_split_overlap': [{'doc_id': '193b00b5b855711ca96fde93155c27b1', 'range': (0, 389)}, {'doc_id': '159809a76ce0e031a900a54e99edddf5', 'range': (717, 1073)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '9b39b2ed5b0e78c4325029bec100c863'}>,\n",
      "                     <Document: {'content': 'We wanted to observe the learning behavior, particularly the behavior of the validation metrics, in a longer training process. Therefore, we set patience to 100 and trained the model for 107 epochs in total where we also saved the checkpoints. For validation, we used the ROUGE-1 F1-score to measure the model’s performance on the validation set over time. We utilized the similarity score as an additional parameter since, especially at the beginning, the pre-trained model tends to generate general dialogue summarizations for each person, resulting in two identical outputs for each person.\\nResults\\nWe trained the architecture as described in the section above on our version of the DialogSum dataset. We kept track of the loss, validation metrics, and similarity scores during training. The model consistently minimized loss on both training and validation sets, resulting in converging loss curves that were approximating 0. However, the validation and similarity curves fluctuated as shown in the figure below.\\n\\nIt shows that the F1-score is not only fluctuating but also monotonically decreasing. This made it difficult to use conventional early stopping, which is why we looked for the optimal checkpoint in terms of F1 score and similarity. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 43, '_split_overlap': [{'doc_id': '9b39b2ed5b0e78c4325029bec100c863', 'range': (0, 356)}, {'doc_id': '3749912a8c41aabd4ccde4d10bc47cf0', 'range': (930, 1249)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '159809a76ce0e031a900a54e99edddf5'}>,\n",
      "                     <Document: {'content': 'However, the validation and similarity curves fluctuated as shown in the figure below.\\n\\nIt shows that the F1-score is not only fluctuating but also monotonically decreasing. This made it difficult to use conventional early stopping, which is why we looked for the optimal checkpoint in terms of F1 score and similarity. The similarity curve shows a behavior similar to the curve of the F1 score. In the early epochs, the validation metrics were relatively high, reaching an F1 score up to approximately 0.34. In contrast, the similarity was also very high, indicating that at this point, the summaries for Person1 and Person2 would be identical. After that, the similarity score and F1 score were constantly going down. Between epochs 40 and 60, the similarity of the outputs decreases even faster, and the F1-score is slightly increasing. We then chose the checkpoint that reached the highest F1 score and the checkpoint with the lowest similarity score, epoch 50. These three checkpoints were then tested on the test set of DialogSum. The following paragraphs show the generated summaries samples from each checkpoint.\\nHighest F1-Score (2 Epochs):\\n\\nPerson1: #Person2# cannot stand the noise in her room. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 44, '_split_overlap': [{'doc_id': '159809a76ce0e031a900a54e99edddf5', 'range': (0, 319)}, {'doc_id': 'c7c0a9279e0e4a5b57a4d4e053230125', 'range': (840, 1205)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '3749912a8c41aabd4ccde4d10bc47cf0'}>,\n",
      "                     <Document: {'content': 'We then chose the checkpoint that reached the highest F1 score and the checkpoint with the lowest similarity score, epoch 50. These three checkpoints were then tested on the test set of DialogSum. The following paragraphs show the generated summaries samples from each checkpoint.\\nHighest F1-Score (2 Epochs):\\n\\nPerson1: #Person2# cannot stand the noise in her room. She was woken up several times by the noise the baggage elevator made. They do not have any spare rooms today, but there will be some tomorrow.\\nPerson2: #Person2# cannot stand the noise in her room. She was woken up several times by the noise the baggage elevator made. They do not have any spare rooms today, but there will be some tomorrow.\\n50 Epochs:\\nPerson1: #Person1# will change #Person2#’s room for her as it is too noisy. #Person2# will wait till tomorrow as a tour company will be leaving tomorrow morning.\\nPerson2: #Person2# cannot stand anymore the room for her because it is too noisy. #Person1# cannot change the room for her because a tour company will be leaving tomorrow morning. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 45, '_split_overlap': [{'doc_id': '3749912a8c41aabd4ccde4d10bc47cf0', 'range': (0, 365)}, {'doc_id': '2028e61e71455efdcd06e6480aa2ec2c', 'range': (709, 1061)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'c7c0a9279e0e4a5b57a4d4e053230125'}>,\n",
      "                     <Document: {'content': '50 Epochs:\\nPerson1: #Person1# will change #Person2#’s room for her as it is too noisy. #Person2# will wait till tomorrow as a tour company will be leaving tomorrow morning.\\nPerson2: #Person2# cannot stand anymore the room for her because it is too noisy. #Person1# cannot change the room for her because a tour company will be leaving tomorrow morning. #Person2# will wait till tomorrow\\nLowest similarity score (106 Epochs):\\nPerson1: 0 what can i do for you 1 none 2 none 3 none 4 none 5 none 6 none 7 none 8 none 9 none 10 none\\nPerson2: 0 none 1 none 2 none 3 none 4 none 5 none 6 none 7 none 8 none 9 none 10 none\\nThe checkpoint reaching the highest F1 score has been trained for two epochs. Although it got a decent F1 score for ROUGE-1 it produced summaries for both persons, which were identical. This is also reflected in its similarity score. Its similarity score is close to 1, and in the produced summaries one can see that the generated summaries might be good candidates for a regular dialogue summarization but are not distinguishable from each other. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 46, '_split_overlap': [{'doc_id': 'c7c0a9279e0e4a5b57a4d4e053230125', 'range': (0, 352)}, {'doc_id': 'e88317148a43b47e8fd51bd455dec8a3', 'range': (694, 1063)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '2028e61e71455efdcd06e6480aa2ec2c'}>,\n",
      "                     <Document: {'content': 'Although it got a decent F1 score for ROUGE-1 it produced summaries for both persons, which were identical. This is also reflected in its similarity score. Its similarity score is close to 1, and in the produced summaries one can see that the generated summaries might be good candidates for a regular dialogue summarization but are not distinguishable from each other. The former aspect can be explained with the CODS backbone, which was trained for dialogue summarization.\\nThe model trained for 50 epochs seems to be the most promising model for perspective dialogue summarization. Although not accurate, the summaries from Person1 and Person2 are different from each other, and they do seem like a usable summary.\\xa0 The summary sentence for Person1\\n#Person1# will change #Person2#’s room for her as it is too noisy.\\nand the summary sentence for Person2\\n#Person2# cannot stand any more the room for her because it is too noisy.\\nboth represent the perspective or situation of each person, respectively. The next sentence for person1\\n#Person2# will wait till tomorrow as a tour company will be leaving tomorrow morning.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 47, '_split_overlap': [{'doc_id': '2028e61e71455efdcd06e6480aa2ec2c', 'range': (0, 369)}, {'doc_id': '21829ed5e151fe6041962976fc795389', 'range': (718, 1118)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'e88317148a43b47e8fd51bd455dec8a3'}>,\n",
      "                     <Document: {'content': 'The summary sentence for Person1\\n#Person1# will change #Person2#’s room for her as it is too noisy.\\nand the summary sentence for Person2\\n#Person2# cannot stand any more the room for her because it is too noisy.\\nboth represent the perspective or situation of each person, respectively. The next sentence for person1\\n#Person2# will wait till tomorrow as a tour company will be leaving tomorrow morning.\\nand the one for Person2\\n#Person1# can’t change the room for her because a tour company will be leaving tomorrow morning\\ntake the position of the other speaker again. However, the last summary sentence of Person2 reflects that person’s position again. On a semantic level, the summaries for both persons do contain the dialogue’s content. There are some minor flaws in the generated output, such as „cannot stand any more the room for her“ which is not grammatically correct. The clause „cannot stand any more“ was existent in the dialogue, and having it next to „the room“ did preserve the original meaning. Note that this example happens to be a more ideal case where our model’s performance was not too bad. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 48, '_split_overlap': [{'doc_id': 'e88317148a43b47e8fd51bd455dec8a3', 'range': (0, 400)}, {'doc_id': '3c6dcfb5e812f06f6a1a5fac86283db3', 'range': (739, 1110)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '21829ed5e151fe6041962976fc795389'}>,\n",
      "                     <Document: {'content': 'There are some minor flaws in the generated output, such as „cannot stand any more the room for her“ which is not grammatically correct. The clause „cannot stand any more“ was existent in the dialogue, and having it next to „the room“ did preserve the original meaning. Note that this example happens to be a more ideal case where our model’s performance was not too bad. Given that the similarity score is still high (higher than 0.8), the generated summaries for each person in many other dialogue samples still tend to be identical or nearly identical. In most outputs, the perspective of the other speaker is also summarized.\\nThe model with the lowest similarity score clearly generated the worst outputs. Since the backbone is based on CODS, the model overfit after training for 106 epochs and produced only the keyphrases and summary sketches, which are used in the underlying architecture.\\nThe model that trained for 50 epochs came the closest to perspective summarization in our experiments. It reached an F1-Score of 0.2294 and a similarity score of 0.89 on the test set of our version of the DialogSum dataset. Nonetheless, during training, the loss converged towards 0. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 49, '_split_overlap': [{'doc_id': '21829ed5e151fe6041962976fc795389', 'range': (0, 371)}, {'doc_id': 'ca9e5e408f5b2d528e13e90b48a85665', 'range': (710, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '3c6dcfb5e812f06f6a1a5fac86283db3'}>,\n",
      "                     <Document: {'content': 'Since the backbone is based on CODS, the model overfit after training for 106 epochs and produced only the keyphrases and summary sketches, which are used in the underlying architecture.\\nThe model that trained for 50 epochs came the closest to perspective summarization in our experiments. It reached an F1-Score of 0.2294 and a similarity score of 0.89 on the test set of our version of the DialogSum dataset. Nonetheless, during training, the loss converged towards 0. We assume that the architecture tried to learn embeddings that lie between the targets for Person1 and Person2, thus reducing the loss but increasing the F1 score. Individual results of this model, such as the one above, show that using a multi-head encoder attached to a single decoder might be a good foundation for perspective dialogue summarization. In our experiments, the results were not convincing enough to use our architecture for an accurate automated system for summarizing each speaker’s perspective. It instead provides a direction in which future work could achieve this. Many factors might have influenced the outcome of our work and approach. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 50, '_split_overlap': [{'doc_id': '3c6dcfb5e812f06f6a1a5fac86283db3', 'range': (0, 470)}, {'doc_id': 'd27208d7013c86528719d3809f0a1c0f', 'range': (635, 1130)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ca9e5e408f5b2d528e13e90b48a85665'}>,\n",
      "                     <Document: {'content': 'Individual results of this model, such as the one above, show that using a multi-head encoder attached to a single decoder might be a good foundation for perspective dialogue summarization. In our experiments, the results were not convincing enough to use our architecture for an accurate automated system for summarizing each speaker’s perspective. It instead provides a direction in which future work could achieve this. Many factors might have influenced the outcome of our work and approach. Solving them could provide great potential for our architecture to eventually generate precise and accurate summarizations for each person in a conversation that are distinctive from each other.\\nDiscussion and future work\\nChallenges\\nNo research exists for perspective dialogue summarization. This made it difficult to develop a viable architecture and required us to outline an approach from scratch. We stated that perspective dialogue summarization and regular dialogue summarization are related to each other. However, the equations we have defined are different from each other. Note that these equations are each very abstract definitions of each task. Due to the difference between these two equations, it is necessary to find a function fP, which is inherently different from function fD. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 51, '_split_overlap': [{'doc_id': 'ca9e5e408f5b2d528e13e90b48a85665', 'range': (0, 495)}, {'doc_id': '6f821c01f664cb3c8b6050ac45e7c522', 'range': (897, 1291)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'd27208d7013c86528719d3809f0a1c0f'}>,\n",
      "                     <Document: {'content': 'We stated that perspective dialogue summarization and regular dialogue summarization are related to each other. However, the equations we have defined are different from each other. Note that these equations are each very abstract definitions of each task. Due to the difference between these two equations, it is necessary to find a function fP, which is inherently different from function fD. This conceptual difference implies that the neural architecture for perspective dialogue summarization must differ from the one for regular dialogue summarization. Therefore, we had to accumulate the characteristics of such an architecture, for example, having multiple outputs, processing an input dialogue for summarization, or being a generative text model. We combined different concepts for each characteristic into one sequence-to-sequence architecture that generates distinct summaries for each person. Since this work is one of the first in perspective dialogue summarization, the combination of multi-headed neural networks in sequence-to-sequence architectures containing an encoder-decoder structure is a novelty we have not discovered in our literature research. Therefore, we could not define clear expectations regarding the performance of our model. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 52, '_split_overlap': [{'doc_id': 'd27208d7013c86528719d3809f0a1c0f', 'range': (0, 394)}, {'doc_id': '2763aab65aa71fad04ed48268a823b56', 'range': (756, 1259)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '6f821c01f664cb3c8b6050ac45e7c522'}>,\n",
      "                     <Document: {'content': 'We combined different concepts for each characteristic into one sequence-to-sequence architecture that generates distinct summaries for each person. Since this work is one of the first in perspective dialogue summarization, the combination of multi-headed neural networks in sequence-to-sequence architectures containing an encoder-decoder structure is a novelty we have not discovered in our literature research. Therefore, we could not define clear expectations regarding the performance of our model. We showed that overall the performance of our trained model is meager and between its ROUGE-1 F1 scores and the ones from previous work is a clear gap. Nonetheless, some predicted samples have shown potential, promising better results if further improvements are made.\\nMany possible factors might influence the performance of our approach. We assume that a multi-headed encoder is a decent starting point to building better architectures for generating summaries for each person. One reason why the performance of our model was not high could be that the architecture has not been able to distinguish between Person1 and Person2. Although both heads share the same common input dialogue, extracting the features for distinguishing between each speaker is still necessary. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 53, '_split_overlap': [{'doc_id': '6f821c01f664cb3c8b6050ac45e7c522', 'range': (0, 503)}, {'doc_id': '144dc2c34fc29617069bfd14a03d13e4', 'range': (844, 1275)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '2763aab65aa71fad04ed48268a823b56'}>,\n",
      "                     <Document: {'content': 'We assume that a multi-headed encoder is a decent starting point to building better architectures for generating summaries for each person. One reason why the performance of our model was not high could be that the architecture has not been able to distinguish between Person1 and Person2. Although both heads share the same common input dialogue, extracting the features for distinguishing between each speaker is still necessary. If this is not the case, the model might still try to summarize for all participants. The predictions from our best model have shown that some sentences which should be designated for the other speaker i are nevertheless part of the summary for speaker j, where i≠j.\\nOne possible solution would build the architecture around additionally differentiating between the persons. This could be done in various ways, such as splitting the dialogue into k sets for k speakers where each set Ui contains the utterances for speaker i and then passing these sets to the architecture. That would require the architecture to accept multiple inputs and to recover the dynamic conversational information flow, i.e.', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 54, '_split_overlap': [{'doc_id': '2763aab65aa71fad04ed48268a823b56', 'range': (0, 431)}, {'doc_id': '77a8910332748715039db36bf71c799f', 'range': (807, 1131)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '144dc2c34fc29617069bfd14a03d13e4'}>,\n",
      "                     <Document: {'content': 'This could be done in various ways, such as splitting the dialogue into k sets for k speakers where each set Ui contains the utterances for speaker i and then passing these sets to the architecture. That would require the architecture to accept multiple inputs and to recover the dynamic conversational information flow, i.e., utterance ui,t of person i at position index t relies on the information of a previous utterance uj,v of person j at position index v, where i≠j and t > v. Another idea is to add more encoding layers for each head to increase the complexity and therefore learn the necessary features to focus on the salient information important for one speaker. Inserting more encoding layers is not the only way to increase the model complexity. However, it is always important to keep in mind higher complexity comes with more parameters and a higher risk of overfitting. Another major problem in our model is the high similarity between the generated outputs. By incorporating the similarity score of the hidden states in training in a more sophisticated way, the model might produce more distinct summaries for each dialogue.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 55, '_split_overlap': [{'doc_id': '144dc2c34fc29617069bfd14a03d13e4', 'range': (0, 324)}, {'doc_id': '741779a9c2ac55a3ba280215ddfef3d2', 'range': (759, 1141)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '77a8910332748715039db36bf71c799f'}>,\n",
      "                     <Document: {'content': 'However, it is always important to keep in mind higher complexity comes with more parameters and a higher risk of overfitting. Another major problem in our model is the high similarity between the generated outputs. By incorporating the similarity score of the hidden states in training in a more sophisticated way, the model might produce more distinct summaries for each dialogue.\\nThe high similarity could also be related to the training data our model trained on. It is essential to mention that the lack of research in perspective dialogue summarization also comes with a limited selection of datasets. There were no corpora that contained the necessary annotations at all for this specific task. We had to create our solution for automatically creating perspective summary annotations, which required us to dive deeper into the linguistic level. This area of our work likely left some improvements to be desired. Sentences can follow a nested and very complex structure, making it quite challenging to come up with all necessary heuristics that can precisely split all annotations and assign them correctly to each person. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 56, '_split_overlap': [{'doc_id': '77a8910332748715039db36bf71c799f', 'range': (0, 382)}, {'doc_id': '85f916012daee6c4328c4317e79a941', 'range': (702, 1128)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '741779a9c2ac55a3ba280215ddfef3d2'}>,\n",
      "                     <Document: {'content': 'We had to create our solution for automatically creating perspective summary annotations, which required us to dive deeper into the linguistic level. This area of our work likely left some improvements to be desired. Sentences can follow a nested and very complex structure, making it quite challenging to come up with all necessary heuristics that can precisely split all annotations and assign them correctly to each person. For instance, our set of dependent prepositions will not cover all sentence conjunctions that either make one clause dependent on the other or connect two stand-alone sentences. Another example is utterances that introduce a person, which can be very ambiguous. There, the person might be either introducing themselves or another third party not necessarily partaking in the conversation. We also relied on machine learning models, which were able to tag the part of speeches of each original annotation. Although they have shown excellent results, they are not working perfectly. We found sentences that followed a very similar structure on which the POS tagger could not consistently make similar inferences. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 57, '_split_overlap': [{'doc_id': '741779a9c2ac55a3ba280215ddfef3d2', 'range': (0, 426)}, {'doc_id': 'ba9338d5d19603f91f35e4912bd1905c', 'range': (816, 1137)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '85f916012daee6c4328c4317e79a941'}>,\n",
      "                     <Document: {'content': 'We also relied on machine learning models, which were able to tag the part of speeches of each original annotation. Although they have shown excellent results, they are not working perfectly. We found sentences that followed a very similar structure on which the POS tagger could not consistently make similar inferences. These loopholes in our data pre-processing step might be the leading cause for a relatively high similarity score of around 0.778 which makes it difficult for our model to produce very distinctive summaries for each speaker. The gold labels we created are based on the references from DialogSum. Therefore, the quality of our gold labels is not as high as that of the DialogSum labels because the creation and evaluation process were not as polished. In addition, the annotations of DialogSum were written to summarize the whole dialogue. The semantic traits of this intention could still be found in our labels, which might also affect the quality of the model-generated summaries.\\nOn a high level, improvements can be made in the architecture and data creation process. However, in each of them, multiple areas can be improved and turn out to be relatively tricky. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 58, '_split_overlap': [{'doc_id': '85f916012daee6c4328c4317e79a941', 'range': (0, 321)}, {'doc_id': '150f90451c28dcf810c1e5402c5e1dc9', 'range': (861, 1188)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ba9338d5d19603f91f35e4912bd1905c'}>,\n",
      "                     <Document: {'content': 'The semantic traits of this intention could still be found in our labels, which might also affect the quality of the model-generated summaries.\\nOn a high level, improvements can be made in the architecture and data creation process. However, in each of them, multiple areas can be improved and turn out to be relatively tricky. Resolving all problem areas can lead to better results but would go beyond the scope of this thesis. We want to encourage future work for automated perspective summarization by listing these problem areas.\\nFuture work\\nAs we developed our methods, we identified problem areas and thus clarified the requirements for this task. Future work on perspective dialogue summarization can address these areas and needs to surpass the performance our model reached.\\nImproving the architecture: This does not necessarily mean increasing the model complexity. Since our architecture builds on the CODS model, which already has shown success and therefore has its degree of complexity, the depth of our architecture can consequently be considered deep. A high degree of complexity usually raises the number of parameters which slows down the training and requires more memory. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 59, '_split_overlap': [{'doc_id': 'ba9338d5d19603f91f35e4912bd1905c', 'range': (0, 327)}, {'doc_id': '83ab90514d2ff1f53f1536323f15c855', 'range': (876, 1191)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '150f90451c28dcf810c1e5402c5e1dc9'}>,\n",
      "                     <Document: {'content': 'Since our architecture builds on the CODS model, which already has shown success and therefore has its degree of complexity, the depth of our architecture can consequently be considered deep. A high degree of complexity usually raises the number of parameters which slows down the training and requires more memory. Then again, as explained earlier, adding more encoding layers could help the model distinguish every speaker and produce better summaries. In addition, multi-headed neural networks do not have to be the only solution for this task. There are many different architectural styles for designing a neural network. Therefore, it is necessary to identify the crucial requirements where we think that the distinction between each speaker is one of them.\\nExtending the data creation: This addresses the problem of high similarity between the labels we have created. The low degree of variance between the made references is very likely to be linked to the negative correlation of F1 and dissimilarity measurements in our model’s performance, i.e., the higher the F1 score, the more similar the generated summary pairs. Our heuristics and approach only scratched the surface of this problem area, potentially posing a whole work on its own. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 60, '_split_overlap': [{'doc_id': '150f90451c28dcf810c1e5402c5e1dc9', 'range': (0, 315)}, {'doc_id': '3e20d2fed82b8a7d75e44d7503534b39', 'range': (874, 1247)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '83ab90514d2ff1f53f1536323f15c855'}>,\n",
      "                     <Document: {'content': 'The low degree of variance between the made references is very likely to be linked to the negative correlation of F1 and dissimilarity measurements in our model’s performance, i.e., the higher the F1 score, the more similar the generated summary pairs. Our heuristics and approach only scratched the surface of this problem area, potentially posing a whole work on its own. When splitting the labels for perspective summaries, many linguistic and semantic features need to be considered. Extending and enhancing the proposed creation process would lead to fewer default steps, where a summary sentence is 1) well split and 2) assigned correctly to one person instead of being assigned to all persons.\\nCreating new data and annotations: Last but not least, we suggest that more data is always a beneficial resource for any deep learning task. Currently, there are no datasets available specifically for perspective dialogue summarization. While splitting the labels of regular summaries and assigning them to each speaker respectively, the semantic context is nonetheless different from summaries that are intended for a specific task. The labels of DialogSum are written in an observer style. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 61, '_split_overlap': [{'doc_id': '83ab90514d2ff1f53f1536323f15c855', 'range': (0, 373)}, {'doc_id': 'b1f8e4aaa0f71e6a19dd9005c7180bad', 'range': (842, 1192)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '3e20d2fed82b8a7d75e44d7503534b39'}>,\n",
      "                     <Document: {'content': 'Currently, there are no datasets available specifically for perspective dialogue summarization. While splitting the labels of regular summaries and assigning them to each speaker respectively, the semantic context is nonetheless different from summaries that are intended for a specific task. The labels of DialogSum are written in an observer style. However, this ‚observer‘ is to observe all parties in dialogue, so that the sentences are formed accordingly. These semantic and syntactic features will remain, even if the data pre-processing went smoothly, and still can influence the training process. Therefore, a dataset designated for this task with the same degree of quality assessment opens new promising paths for developing automated perspective dialogue summarizers.\\nWe are aware that there could be many more factors that affect the performance of our model. During this thesis’s creation, the aspects we just mentioned were the most prevalent we faced. Thus, we strongly emphasize those due to the fact that we experienced most obstacles caused by them.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 62, '_split_overlap': [{'doc_id': '3e20d2fed82b8a7d75e44d7503534b39', 'range': (0, 350)}, {'doc_id': '40242811711c22d51a361636e940f318', 'range': (605, 1067)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'b1f8e4aaa0f71e6a19dd9005c7180bad'}>,\n",
      "                     <Document: {'content': 'Therefore, a dataset designated for this task with the same degree of quality assessment opens new promising paths for developing automated perspective dialogue summarizers.\\nWe are aware that there could be many more factors that affect the performance of our model. During this thesis’s creation, the aspects we just mentioned were the most prevalent we faced. Thus, we strongly emphasize those due to the fact that we experienced most obstacles caused by them.\\nConclusion\\nOur contribution is an approach to building a neural network capable of generating summaries for each speaker in a dialogue, a method for creating reference summaries for perspective dialogue summarization, and an augmented set of reference labels for the DialogSum corpus. These labels contain summaries for each speaker gained from the original reference summary and can be used for training. Furthermore, this task of per-person dialogue summarization is new and has no literature record. With this work, we further refined the requirements and problem areas that frequently occur when building such a neural network.', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 63, '_split_overlap': [{'doc_id': 'b1f8e4aaa0f71e6a19dd9005c7180bad', 'range': (0, 462)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '40242811711c22d51a361636e940f318'}>,\n",
      "                     <Document: {'content': 'Definition und Bedeutung der industriellen BildverarbeitungGrundlagen und Funktionen der BildverarbeitungstechnologieEinsatzbereiche und Vorteile der industriellen BildverarbeitungAnwendungen der industriellen BildverarbeitungHerausforderungen und Lösungen in der industriellen BildverarbeitungZukunftstrends und EntwicklungenVorteile der Industriellen Bildverarbeitung für UnternehmenFazit\\nDefinition und Bedeutung der industriellen Bildverarbeitung\\nDie industrielle Bildverarbeitung ist zur Schlüsseltechnologie in modernen Unternehmen geworden, in denen die Analyse von Bildern zur Prozessoptimierung und Qualitätskontrolle unerlässlich ist. Sie nutzt fortschrittliche Technologien, um visuelle Daten aus Produktionsumgebungen zu extrahieren und diese zur Automatisierung, Qualitätskontrolle und Effizienzsteigerung zu verwenden. In diesem Blogbeitrag werfen wir einen detaillierten Blick auf die spannende Welt der industriellen Bildverarbeitung einschließlich ihrer Funktionsweise, Anwendungen, Herausforderungen und der Vorteile, die sie bietet.\\nGrundlagen und Funktionen der Bildverarbeitungstechnologie\\nDie industrielle Bildverarbeitung umfasst mehrere Schritte:\\n\\nErfassung von Bildern durch Kameras und Sensoren\\nVerarbeitung und Analyse dieser Bilder mittels Algorithmen\\nErkennung von Abweichungen, die auf Probleme hinweisen können\\nAutomatisierung von Prozessen basierend auf gewonnenen Informationen zur Qualitätskontrolle und Effizienzsteigerung\\n\\nZuerst werden Bilder mithilfe von Kameras und Sensoren in der Produktionsumgebung erfasst. Leistungsstarke Algorithmen verarbeiten und analysieren diese Bilder, um relevante Informationen oder Muster zu extrahieren, einschließlich der Erkennung von Qualitätsproblemen oder Anomalien. Hierbei sind nicht nur präzise Kameras, sondern auch algorithmische Fähigkeiten entscheidend, um die erfassten Daten sinnvoll zu interpretieren.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 0, '_split_overlap': [{'doc_id': 'f37eaebb4d9f27c15cd82cf265cc7212', 'range': (1052, 1887)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '4986bcb305c392d4b3c141155bc543c5'}>,\n",
      "                     <Document: {'content': 'Grundlagen und Funktionen der Bildverarbeitungstechnologie\\nDie industrielle Bildverarbeitung umfasst mehrere Schritte:\\n\\nErfassung von Bildern durch Kameras und Sensoren\\nVerarbeitung und Analyse dieser Bilder mittels Algorithmen\\nErkennung von Abweichungen, die auf Probleme hinweisen können\\nAutomatisierung von Prozessen basierend auf gewonnenen Informationen zur Qualitätskontrolle und Effizienzsteigerung\\n\\nZuerst werden Bilder mithilfe von Kameras und Sensoren in der Produktionsumgebung erfasst. Leistungsstarke Algorithmen verarbeiten und analysieren diese Bilder, um relevante Informationen oder Muster zu extrahieren, einschließlich der Erkennung von Qualitätsproblemen oder Anomalien. Hierbei sind nicht nur präzise Kameras, sondern auch algorithmische Fähigkeiten entscheidend, um die erfassten Daten sinnvoll zu interpretieren.\\nBildverarbeitungssysteme nutzen digitale Sensoren in Industriekameras mit spezieller Optik zur Bilderfassung. Eine Kombination aus Hardware und Software verarbeitet, analysiert und misst verschiedene Merkmale, um eine Entscheidung zu treffen. Als automatische optische Inspektion ermöglicht Computer Vision schnelle, reproduzierbare und umfassende Qualitätssicherung von Produkten, unabhängig von der Phase (Eingang-, Zwischen- oder Endkontrolle). Dies gewährleistet eine kontinuierliche Überwachung der Produktionsprozesse zur frühzeitigen Fehlererkennung und Behebung rund um die Uhr.\\nEinsatzbereiche und Vorteile der industriellen Bildverarbeitung\\nAnwendungen der industriellen Bildverarbeitung\\nDie industrielle Bildverarbeitung bietet vielseitige Anwendungen in verschiedenen Bereichen wie der industriellen Fertigung, Landwirtschaft, Medizintechnik, Einzelhandel, Fernerkundung, Automotive oder der Medienbranche. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 1, '_split_overlap': [{'doc_id': '4986bcb305c392d4b3c141155bc543c5', 'range': (0, 835)}, {'doc_id': '9f7a7bdf37fefdb7f39be6d2360008fb', 'range': (1079, 1754)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f37eaebb4d9f27c15cd82cf265cc7212'}>,\n",
      "                     <Document: {'content': 'Als automatische optische Inspektion ermöglicht Computer Vision schnelle, reproduzierbare und umfassende Qualitätssicherung von Produkten, unabhängig von der Phase (Eingang-, Zwischen- oder Endkontrolle). Dies gewährleistet eine kontinuierliche Überwachung der Produktionsprozesse zur frühzeitigen Fehlererkennung und Behebung rund um die Uhr.\\nEinsatzbereiche und Vorteile der industriellen Bildverarbeitung\\nAnwendungen der industriellen Bildverarbeitung\\nDie industrielle Bildverarbeitung bietet vielseitige Anwendungen in verschiedenen Bereichen wie der industriellen Fertigung, Landwirtschaft, Medizintechnik, Einzelhandel, Fernerkundung, Automotive oder der Medienbranche. Überall dort, wo visuelle Analysen oder Entscheidungen erforderlich sind, können Computer Vision Methoden eingesetzt werden.\\nFertigungsindustrie\\nIn der Fertigung ermöglicht diese Technologie eine präzise Inspektion zur Defekterkennung und die Einhaltung von Qualitätsstandards und ermöglicht einen höheren Automatisierungsgrad.\\nRobotik\\nRoboter können mithilfe von Bildverarbeitungssystemen präzise Aufgaben wie Montage und Inspektion durchführen, was die Effizienz und Genauigkeit der Produktionslinien erhöht. Analyse der visuellen Daten erhöht die Sicherheit bei der Interaktion von Robotern mit Menschen, da sie Hindernisse besser erkennen und darauf reagieren können.\\nEinzelhandel\\nIm Einzelhandel\\xa0 unterstützen Computer Vision Methoden die Identifikation und Rückverfolgbarkeit von Produkten in der Lieferkette. Außerdem kann durch die personalisierten Angebote mithilfe der Bildverarbeitung die Kundenerfahrung verbessert werden.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 2, '_split_overlap': [{'doc_id': 'f37eaebb4d9f27c15cd82cf265cc7212', 'range': (0, 675)}, {'doc_id': 'cc72fcc6023025ac6c51407b1f25e1ea', 'range': (1187, 1610)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '9f7a7bdf37fefdb7f39be6d2360008fb'}>,\n",
      "                     <Document: {'content': 'Analyse der visuellen Daten erhöht die Sicherheit bei der Interaktion von Robotern mit Menschen, da sie Hindernisse besser erkennen und darauf reagieren können.\\nEinzelhandel\\nIm Einzelhandel\\xa0 unterstützen Computer Vision Methoden die Identifikation und Rückverfolgbarkeit von Produkten in der Lieferkette. Außerdem kann durch die personalisierten Angebote mithilfe der Bildverarbeitung die Kundenerfahrung verbessert werden.\\nMedizin\\nIn der medizinischen Bildverarbeitung können Ärzte bei der Diagnose und Überwachung von Krankheiten\\xa0 durch eine automatische Analyse von Röntgenbildern oder CT-Scans unterstützt werden.\\nLandwirtschaft\\nIn der Landwirtschaft können Technologien der Bildverarbeitung genutzt werden, um Pflanzenwachstum zu überwachen, Unkraut zu bekämpfen oder Ernten zu optimieren.\\nLebensmittelindustrie\\nDurch den Einsatz von Bildverarbeitung in der Lebensmittelproduktion werden Lebensmittel auf Verunreinigungen, Größe und Qualität inspiziert, um sicherzustellen, dass sie den Qualitätsstandards entsprechen.\\nDiese Auswahl von Beispielen verdeutlicht, wie industrielle Bildverarbeitung in vielfältigen Branchen und Anwendungen die Effizienz, Genauigkeit und Zuverlässigkeit verbessern kann, was zu gesteigerter Produktivität und Qualitätssicherung führt.\\n\\nHerausforderungen und Lösungen in der industriellen Bildverarbeitung\\nNeben den beeindruckenden Möglichkeiten, die industrielle Bildverarbeitung bietet, gibt es einige Herausforderungen, die auf dem Weg zur erfolgreichen Nutzung eines solchen Systems überwunden werden müssen. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 3, '_split_overlap': [{'doc_id': '9f7a7bdf37fefdb7f39be6d2360008fb', 'range': (0, 423)}, {'doc_id': '1c840d00264f181c14fbcda8868dac38', 'range': (1024, 1546)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'cc72fcc6023025ac6c51407b1f25e1ea'}>,\n",
      "                     <Document: {'content': 'Diese Auswahl von Beispielen verdeutlicht, wie industrielle Bildverarbeitung in vielfältigen Branchen und Anwendungen die Effizienz, Genauigkeit und Zuverlässigkeit verbessern kann, was zu gesteigerter Produktivität und Qualitätssicherung führt.\\n\\nHerausforderungen und Lösungen in der industriellen Bildverarbeitung\\nNeben den beeindruckenden Möglichkeiten, die industrielle Bildverarbeitung bietet, gibt es einige Herausforderungen, die auf dem Weg zur erfolgreichen Nutzung eines solchen Systems überwunden werden müssen. Dazu zählen unter anderem:\\nFehlende Trainingsdaten\\nUm effektive Computer-Vision-Modelle zu erstellen, sind ausreichende, vielfältige Bilder erforderlich, die reale Bedingungen und Szenarien widerspiegeln. Insbesondere Bilder von seltenen Ereignissen oder Defekten, die in den Trainingsdaten begrenzt vertreten sind, sind von entscheidender Bedeutung. Generative KI kann hierbei durch die Anreicherung von Datensätzen mit generierten Bildern helfen.\\nAuswahl geeigneter Bildverarbeitungsalgorithmen\\nDie Auswahl der Algorithmen hängt von den spezifischen Anforderungen und Herausforderungen des jeweiligen Anwendungsfalls ab. Es ist wichtig, maßgeschneiderte Lösungen zu entwickeln, die die Besonderheiten der Industrie und Umgebung berücksichtigen.\\nBeleuchtungsbedingungen\\nSchwankende Lichtverhältnisse können die Bildqualität beeinträchtigen und das Erscheinungsbild desselben Objektes verändern, was sich negativ auf die Leistung des Systems auswirken kann.\\nAnpassungsfähigkeit\\nDas System soll flexibel sein, um in sich verändernden Umgebungen kontinuierlich gute Ergebnisse zu liefern.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 4, '_split_overlap': [{'doc_id': 'cc72fcc6023025ac6c51407b1f25e1ea', 'range': (0, 522)}, {'doc_id': '159724f0fb8c2c5635690f64037a4fae', 'range': (1146, 1609)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '1c840d00264f181c14fbcda8868dac38'}>,\n",
      "                     <Document: {'content': 'Es ist wichtig, maßgeschneiderte Lösungen zu entwickeln, die die Besonderheiten der Industrie und Umgebung berücksichtigen.\\nBeleuchtungsbedingungen\\nSchwankende Lichtverhältnisse können die Bildqualität beeinträchtigen und das Erscheinungsbild desselben Objektes verändern, was sich negativ auf die Leistung des Systems auswirken kann.\\nAnpassungsfähigkeit\\nDas System soll flexibel sein, um in sich verändernden Umgebungen kontinuierlich gute Ergebnisse zu liefern.\\nIntegration\\nDie Integration eines Bildverarbeitungssystems in bestehende Produktionsprozesse kann\\xa0 einige Zeit und Fachwissen in den Bereichen Computer Vision und relevanten Produktionsprozessen in\\xa0 Anspruch nehmen.\\nDie Bewältigung dieser Herausforderungen erfordert sorgfältige Planung, den Einsatz fortschrittlicher Technologien und Expertise in Computer Vision und Bildverarbeitung.\\nZukunftstrends und Entwicklungen\\nDurch die ständige Suche nach effizienteren und fortschrittlicheren Lösungen, hat die industrielle Bildverarbeitung in den letzten Jahren einen großen Aufschwung erlebt. Einige der vielversprechendsten Innovationen im Bereich Computer Vision sind:\\nKünstliche Intelligenz (KI) und Deep Learning\\nDie KI- und Deep Learning Methoden im Kontext der Bildverarbeitung ermöglichen das Verständnis der komplexen visuellen Daten mit höherer Präzision und Effizienz. KI-Modelle sind in der Lage, feinste Details zu erkennen und bieten eine hohe Anpassungsfähigkeit, was in der schnelllebigen Produktionsumgebung entscheidend ist.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 5, '_split_overlap': [{'doc_id': '1c840d00264f181c14fbcda8868dac38', 'range': (0, 463)}, {'doc_id': '3957979179295c6877cc9226970dff29', 'range': (1053, 1501)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '159724f0fb8c2c5635690f64037a4fae'}>,\n",
      "                     <Document: {'content': 'Einige der vielversprechendsten Innovationen im Bereich Computer Vision sind:\\nKünstliche Intelligenz (KI) und Deep Learning\\nDie KI- und Deep Learning Methoden im Kontext der Bildverarbeitung ermöglichen das Verständnis der komplexen visuellen Daten mit höherer Präzision und Effizienz. KI-Modelle sind in der Lage, feinste Details zu erkennen und bieten eine hohe Anpassungsfähigkeit, was in der schnelllebigen Produktionsumgebung entscheidend ist.\\n3D-Bildverarbeitung\\nDie 3D-Bildverarbeitung ermöglicht eine präzise Vermessung und Inspektion von Objekten in drei Dimensionen, was in Bereichen wie Robotik, Montage von Teilen oder der Qualitätssicherung von großer Bedeutung ist.\\nInternet of Things (IoT) Integration\\nEine Kombination von Bildverarbeitung und IoT ermöglicht eine verbesserte Zusammenarbeit der Maschinen und Anlagen, was zu umfassenderen Datenanalysen und einer verbesserten Produktionsüberwachung führt.\\nAugmented Reality (AR)\\nAR bietet die Möglichkeit, visuelle Informationen in Echtzeit über beispielsweise AR-Brillen bereitzustellen, was die Art und Weise verändert, wie Menschen mit visuellen Informationen interagieren. Durch die visuelle Anleitungen direkt im Sichtfeld können viele Aufgaben wie Qualitätskontrolle, Inspektion oder Schulungen präziser und effektiver durchgeführt werden.\\nDiese Trends zeigen deutlich, dass die Zukunft der industriellen Bildverarbeitung sehr vielversprechend aussieht. Der Einsatz von Künstlicher Intelligenz und Deep Learning ermöglicht fortschrittliche Bilderkennungsfunktionen, durch die komplexe Inspektionen und Analysen durchgeführt werden können. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 6, '_split_overlap': [{'doc_id': '159724f0fb8c2c5635690f64037a4fae', 'range': (0, 448)}, {'doc_id': '5eb4bd09404842264fba2c6c2776c2fe', 'range': (1142, 1609)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '3957979179295c6877cc9226970dff29'}>,\n",
      "                     <Document: {'content': 'Durch die visuelle Anleitungen direkt im Sichtfeld können viele Aufgaben wie Qualitätskontrolle, Inspektion oder Schulungen präziser und effektiver durchgeführt werden.\\nDiese Trends zeigen deutlich, dass die Zukunft der industriellen Bildverarbeitung sehr vielversprechend aussieht. Der Einsatz von Künstlicher Intelligenz und Deep Learning ermöglicht fortschrittliche Bilderkennungsfunktionen, durch die komplexe Inspektionen und Analysen durchgeführt werden können. Die Integration von 3D-Bildverarbeitung eröffnet neue Möglichkeiten für die präzise Vermessung und Inspektion von Objekten. Intelligente Kamerasysteme, die mit eingebetteten Analysefunktionen ausgestattet sind, werden die Echtzeitüberwachung und -steuerung von Produktionsprozessen weiter vorantreiben.\\nVorteile der Industriellen Bildverarbeitung für Unternehmen\\nDer Einsatz der industriellen Bildverarbeitung bringt zahlreiche Vorteile mit sich. Durch präzise Inspektionen und Qualitätskontrollen wird die Produktqualität erhöht, was wiederum die Kundenzufriedenheit steigert. Gleichzeitig ermöglicht die Technologie eine verbesserte Effizienz in der Produktion, da Prozesse automatisiert und optimiert werden können. Dies führt zu einer Senkung der Produktionskosten und einer Minimierung menschlicher Fehler bei der Qualitätskontrolle.\\n\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 7, '_split_overlap': [{'doc_id': '3957979179295c6877cc9226970dff29', 'range': (0, 467)}, {'doc_id': 'aae1a3e60e5793dd7cb670492a706f95', 'range': (771, 1307)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5eb4bd09404842264fba2c6c2776c2fe'}>,\n",
      "                     <Document: {'content': 'Vorteile der Industriellen Bildverarbeitung für Unternehmen\\nDer Einsatz der industriellen Bildverarbeitung bringt zahlreiche Vorteile mit sich. Durch präzise Inspektionen und Qualitätskontrollen wird die Produktqualität erhöht, was wiederum die Kundenzufriedenheit steigert. Gleichzeitig ermöglicht die Technologie eine verbesserte Effizienz in der Produktion, da Prozesse automatisiert und optimiert werden können. Dies führt zu einer Senkung der Produktionskosten und einer Minimierung menschlicher Fehler bei der Qualitätskontrolle.\\n\\nstrategisches Ziel\\nAnwendungen industrieller Bildverarbeitung\\n\\nQualitätskontrolle und -sicherung\\n\\nDefekterkennung, Maßkontrolle und Oberflächeninspektion\\nSortierung basierend auf Qualitätskriterien\\nIdentifizierung von Unregelmäßigkeiten in Produktionsprozessen\\n\\nRobotik\\n\\nBildverarbeitung ermöglicht Robotern die Wahrnehmung ihrer Umgebung, was in der Robotik für präzise Bewegungen, Montageaufgaben und Kollisionsvermeidung wichtig ist\\n\\nProzessautomatisierung\\n\\nMontagepräzision und Effizienz\\nReduktion menschlicher Fehler\\nsenkt Produktionskosten durch automatisierte Linienüberwachung\\n\\nInspektion in Echtzeit\\n\\nEchtzeitüberwachung\\nSicherheitsrisiken erkennen\\nschnelle Reaktion bei einem Ausnahmefall\\n\\nOptimierte Fertigung\\n\\nEngpässe identifizieren\\nEffizienz steigern\\nRessourcen optimieren\\nprädiktive Wartung von Fertigungsmaschinen\\n\\nDatenanalyse und Verbesserung\\n\\nProduktionsdaten nutzen\\nErkenntnisse gewinnen\\nkontinuierliche Prozessoptimierung\\n\\nInnovationsförderung\\n\\nEntwicklung neuer Bildverarbeitungsalgorithmen\\nIntegration von KI und maschinellem Lernen\\nImplementierung neuer Technologien\\nAnwendung von Bildverarbeitung in neuen Branchen\\n\\nDiese Tabelle zeigt nur einige Beispiele und die genannten Anwendungen sind nicht abschließend. Die industrielle Bildverarbeitung kann in vielen weiteren Bereichen eingesetzt werden, um verschiedene strategische Ziele zu erreichen.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 8, '_split_overlap': [{'doc_id': '5eb4bd09404842264fba2c6c2776c2fe', 'range': (0, 536)}, {'doc_id': '9289b58d6dc3d1ed6f3b5e8868c1cfd3', 'range': (537, 1909)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'aae1a3e60e5793dd7cb670492a706f95'}>,\n",
      "                     <Document: {'content': 'strategisches Ziel\\nAnwendungen industrieller Bildverarbeitung\\n\\nQualitätskontrolle und -sicherung\\n\\nDefekterkennung, Maßkontrolle und Oberflächeninspektion\\nSortierung basierend auf Qualitätskriterien\\nIdentifizierung von Unregelmäßigkeiten in Produktionsprozessen\\n\\nRobotik\\n\\nBildverarbeitung ermöglicht Robotern die Wahrnehmung ihrer Umgebung, was in der Robotik für präzise Bewegungen, Montageaufgaben und Kollisionsvermeidung wichtig ist\\n\\nProzessautomatisierung\\n\\nMontagepräzision und Effizienz\\nReduktion menschlicher Fehler\\nsenkt Produktionskosten durch automatisierte Linienüberwachung\\n\\nInspektion in Echtzeit\\n\\nEchtzeitüberwachung\\nSicherheitsrisiken erkennen\\nschnelle Reaktion bei einem Ausnahmefall\\n\\nOptimierte Fertigung\\n\\nEngpässe identifizieren\\nEffizienz steigern\\nRessourcen optimieren\\nprädiktive Wartung von Fertigungsmaschinen\\n\\nDatenanalyse und Verbesserung\\n\\nProduktionsdaten nutzen\\nErkenntnisse gewinnen\\nkontinuierliche Prozessoptimierung\\n\\nInnovationsförderung\\n\\nEntwicklung neuer Bildverarbeitungsalgorithmen\\nIntegration von KI und maschinellem Lernen\\nImplementierung neuer Technologien\\nAnwendung von Bildverarbeitung in neuen Branchen\\n\\nDiese Tabelle zeigt nur einige Beispiele und die genannten Anwendungen sind nicht abschließend. Die industrielle Bildverarbeitung kann in vielen weiteren Bereichen eingesetzt werden, um verschiedene strategische Ziele zu erreichen.\\nFazit\\nDie industrielle Bildverarbeitung hat sich zu einem unverzichtbaren Werkzeug für Unternehmen in verschiedenen Branchen entwickelt. Ihre Fähigkeit, präzise Inspektionen durchzuführen, Produktionsprozesse zu optimieren und die Produktqualität zu steigern, macht sie zu einer treibenden Kraft hinter der Innovation in der Fertigung im Zeitalter der Industrie 4.0. Für Entwickler:innen eröffnet sie spannende Möglichkeiten, fortschrittliche Algorithmen und Technologien zu erforschen und zu implementieren. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 9, '_split_overlap': [{'doc_id': 'aae1a3e60e5793dd7cb670492a706f95', 'range': (0, 1372)}, {'doc_id': 'cbbca5769c24b82800611c86ad18682f', 'range': (1373, 1881)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '9289b58d6dc3d1ed6f3b5e8868c1cfd3'}>,\n",
      "                     <Document: {'content': 'Fazit\\nDie industrielle Bildverarbeitung hat sich zu einem unverzichtbaren Werkzeug für Unternehmen in verschiedenen Branchen entwickelt. Ihre Fähigkeit, präzise Inspektionen durchzuführen, Produktionsprozesse zu optimieren und die Produktqualität zu steigern, macht sie zu einer treibenden Kraft hinter der Innovation in der Fertigung im Zeitalter der Industrie 4.0. Für Entwickler:innen eröffnet sie spannende Möglichkeiten, fortschrittliche Algorithmen und Technologien zu erforschen und zu implementieren. In einer Zeit, in der Wettbewerb und Effizienz von großer Bedeutung sind, ist die industrielle Bildverarbeitung zweifellos ein Schlüssel zur Steigerung des Erfolgs und der Nachhaltigkeit von Unternehmen.\\nMit Technologien wie KI und 3D-Bildverarbeitung stehen die Zeichen auf weiteres Wachstum und Innovation. Unternehmen, die in diese Technologie investieren, sind auf dem besten Weg, in der Wettbewerbslandschaft an vorderster Front zu stehen.\\n\\nWenn Sie interessiert, wie Sie die industrielle Bildverarbeitung für sich nutzen können, schauen Sie gerne hier vorbei:\\n\\nComputer Vision\\n\\nShare:\\n\\nJasmin\\t\\t\\t\\t\\t\\t\\t\\t\\tSchmidt\\n\\nSina\\t\\t\\t\\t\\t\\t\\t\\t\\tBuchmüller\\n\\nKamilla\\t\\t\\t\\t\\t\\t\\t\\t\\tMohr\\n\\nYaren Sahin\\n\\nTechnical Sales Engineer\\n\\nHallo! 👋Wie können wir Sie unterstützen?\\n\\nAnrufen\\n\\nE-Mail senden\\n\\nUnverbindliches Erstgespräch\\n\\nKontakt aufnehmen\\n\\nWie können wir Sie unterstützen?\\n\\nYaren Sahin\\n\\nTechnical Sales Engineer\\n\\nAnrufen\\n\\nE-Mail senden', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/industrielle-bildverarbeitung-grundlagen-anwendungen-und-vorteile/', 'authors': ['Jasmin Schmidt', 'Sina Buchmüller', 'Kamilla Mohr'], 'date': '19.10.2023', 'title': 'Industrielle Bildverarbeitung: Grundlagen, Anwendungen und Vorteile', '_split_id': 10, '_split_overlap': [{'doc_id': '9289b58d6dc3d1ed6f3b5e8868c1cfd3', 'range': (0, 508)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'cbbca5769c24b82800611c86ad18682f'}>,\n",
      "                     <Document: {'content': 'Accurate forecasting of electricity consumption is greatly beneficial to companies aiming to achieve efficient and optimized cost management. The key lies in understanding and interpreting respective time series data – a collection of energy consumption measurements recorded at evenly spaced intervals. Analyses and forecasting of time series offer valuable insights into past patterns, trends, periodic fluctuations, and future developments of electricity usage. These insights empower informed decisions regarding resource management.\\n\\nIn this context, statistical and algorithmic approaches are used to ground forecasts on historical data. In recent years, numerous forecasting models have been developed, each leveraging distinct assumptions about the underlying patterns in time series data. Depending on these patterns, the resultant models are suitable for specific applications.\\nIn this blog post, we will take a closer look at a modular regression model called Prophet as a promising model for time series analysis. The investigated time series of energy consumption shows regular seasonalities, and huge trend changes due to external factors or holiday effects. Throughout this blog post, we will detail the process of applying the Prophet model to such data and ascertain its efficacy.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 0, '_split_overlap': [{'doc_id': 'c4243fafbbb2a2368b95e8dd53a5e18f', 'range': (888, 1297)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'd483d9b7893c2d161e95588eb5125510'}>,\n",
      "                     <Document: {'content': 'In this blog post, we will take a closer look at a modular regression model called Prophet as a promising model for time series analysis. The investigated time series of energy consumption shows regular seasonalities, and huge trend changes due to external factors or holiday effects. Throughout this blog post, we will detail the process of applying the Prophet model to such data and ascertain its efficacy.\\nThe objective is to develop an implementation that can be applied to a wide range of different energy consumption data. Thus, we will also emphasize an evaluation strategy that is helpful to evaluate multiple time series. This approach facilitates the development of promising performance conditions for Prophet.\\nDisclaimer:\\nThe content of the blog post assumes familiarity with machine learning concepts, and readers are advised to have a solid understanding of time series concepts for optimal comprehension.\\n\\nWhat is Prophet?Use case: Electricity consumption forecasts for multiple monitoring stationsProphet’s Hyperparameter TuningProblems faced with Prophet’s Hyperparameter TuningAlternative evaluation strategy using Prophet for time series analysisAnalysis of error statistics and plotsExperiences using Prophet as a forecasting model for electricity consumption\\nWhat is Prophet?\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 1, '_split_overlap': [{'doc_id': 'd483d9b7893c2d161e95588eb5125510', 'range': (0, 409)}, {'doc_id': '33e6991d17e5b94fc7398c9c088694b1', 'range': (723, 1297)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'c4243fafbbb2a2368b95e8dd53a5e18f'}>,\n",
      "                     <Document: {'content': 'Disclaimer:\\nThe content of the blog post assumes familiarity with machine learning concepts, and readers are advised to have a solid understanding of time series concepts for optimal comprehension.\\n\\nWhat is Prophet?Use case: Electricity consumption forecasts for multiple monitoring stationsProphet’s Hyperparameter TuningProblems faced with Prophet’s Hyperparameter TuningAlternative evaluation strategy using Prophet for time series analysisAnalysis of error statistics and plotsExperiences using Prophet as a forecasting model for electricity consumption\\nWhat is Prophet?\\nConstructing time series forecasting requires a sophisticated set of methods to capture the complex patterns of time-dependent data. In 2017, researchers from Facebook presented their open-source project named Prophet, a framework tailored for modeling time series in Python or R. in their paper “Forecasting at Scale“. It stands out for its user-friendly simplicity and is purpose-built to deliver precise time-series predictions. The intuitively interpretable parameters make it easy to use and understand, even by non-technical analysts.\\nDerived from typical patterns in characteristically known business time series, it decomposes the time series into three distinct components:\\n\\nThe trend component covers the general course of the time series, i.e. the non-periodic fluctuations. It captures how the values increase, decrease, or remain constant over time.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 2, '_split_overlap': [{'doc_id': 'c4243fafbbb2a2368b95e8dd53a5e18f', 'range': (0, 574)}, {'doc_id': '62561a54a42d9caeabd2e202be22a4c0', 'range': (1007, 1437)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '33e6991d17e5b94fc7398c9c088694b1'}>,\n",
      "                     <Document: {'content': 'The intuitively interpretable parameters make it easy to use and understand, even by non-technical analysts.\\nDerived from typical patterns in characteristically known business time series, it decomposes the time series into three distinct components:\\n\\nThe trend component covers the general course of the time series, i.e. the non-periodic fluctuations. It captures how the values increase, decrease, or remain constant over time.\\nThe seasonal component detects recurring seasonal patterns, such as daily, weekly, or yearly cycles.\\nThe holiday effects component takes important holidays or events that could affect the time series into account.\\n\\nProphet is an additive model that considers the sum of these components plus a normally distributed error term. Several other features of Prophet, like efficient and fast training, easy tweaking of hyperparameters, and robust handling of missing records or outliers, make Prophet an appealing time series modeling framework – especially if the application of several time series recorded by multiple different monitoring stations is required. The documentation of Prophet can be found here.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 3, '_split_overlap': [{'doc_id': '33e6991d17e5b94fc7398c9c088694b1', 'range': (0, 430)}, {'doc_id': '7edea2c23eb0084f9985b3bbd4e7352a', 'range': (758, 1136)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '62561a54a42d9caeabd2e202be22a4c0'}>,\n",
      "                     <Document: {'content': 'Several other features of Prophet, like efficient and fast training, easy tweaking of hyperparameters, and robust handling of missing records or outliers, make Prophet an appealing time series modeling framework – especially if the application of several time series recorded by multiple different monitoring stations is required. The documentation of Prophet can be found here.\\nUse case: Electricity consumption forecasts for multiple monitoring stations\\nIn the given scenario, we have measurements available from several measuring points denoted as MM, all within the same time period within the identical time period 0,1,…,T0,1,…,T . Each measuring point mm from the set MM is represented by a time series xm(t),m∈M,t∈{0,1,…,T}x_m(t), m \\\\in M, t \\\\in \\\\{0,1,…,T\\\\}. The goal is to predict future measured values for each time series using the prophet model, denoted as ym(t)y_m(t) aiming to get as close as possible to ym(t)≈xm(t)y_m(t) \\\\approx x_m(t) for t>Tt>T, m∈Mm \\\\in M.\\nThe primary aim is to determine a model configuration, which involves model parameters denoted as from a set of potential parameters represented by Ω\\\\Omega. This configuration should incorporate appropriately selected seasonal patterns, holiday effects, and other hyperparameters, aiming to minimize the discrepancy between ym(t)y_m(t) and xm(t)x_m(t) for ω∈Ω\\\\omega \\\\in \\\\Omega. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 4, '_split_overlap': [{'doc_id': '62561a54a42d9caeabd2e202be22a4c0', 'range': (0, 378)}, {'doc_id': 'f9afcb100a276ac6427657e68c6a5963', 'range': (766, 1353)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '7edea2c23eb0084f9985b3bbd4e7352a'}>,\n",
      "                     <Document: {'content': 'The goal is to predict future measured values for each time series using the prophet model, denoted as ym(t)y_m(t) aiming to get as close as possible to ym(t)≈xm(t)y_m(t) \\\\approx x_m(t) for t>Tt>T, m∈Mm \\\\in M.\\nThe primary aim is to determine a model configuration, which involves model parameters denoted as from a set of potential parameters represented by Ω\\\\Omega. This configuration should incorporate appropriately selected seasonal patterns, holiday effects, and other hyperparameters, aiming to minimize the discrepancy between ym(t)y_m(t) and xm(t)x_m(t) for ω∈Ω\\\\omega \\\\in \\\\Omega. The forecasts of Prophet can show variations in their predicted values for a specific time series based on a used parameter setting. The model is trained on a part of the time series, the so-called training data. After training the model, the difference between unseen values and their predicted counterparts is considered to compute various error statistics. This part of the time series is called validation data. Each error metric quantifies the accuracy of the forecast performance and provides ideas on which parameter setting works best.\\nProphet’s Hyperparameter Tuning\\nProphet offers cross-validation functionalities to quickly and easily find the best working forecast model across various hyperparameters. It utilizes the so-called simulated historical forecast. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 5, '_split_overlap': [{'doc_id': '7edea2c23eb0084f9985b3bbd4e7352a', 'range': (0, 587)}, {'doc_id': 'c0adc74cc34fadc58eee9402ca7c0739', 'range': (948, 1359)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f9afcb100a276ac6427657e68c6a5963'}>,\n",
      "                     <Document: {'content': 'This part of the time series is called validation data. Each error metric quantifies the accuracy of the forecast performance and provides ideas on which parameter setting works best.\\nProphet’s Hyperparameter Tuning\\nProphet offers cross-validation functionalities to quickly and easily find the best working forecast model across various hyperparameters. It utilizes the so-called simulated historical forecast. The simulated historical forecast is based on a rolling origin evaluation procedure for assessing the quantitative performance of time series forecasts.\\nFor this purpose, kk cut-off points are determined while ensuring that the forecast remains within the historical data. A model is fitted up to a certain cut-off point. Subsequently, predicted values are compared to actual values within the chosen horizon. Iterating across all cut-off points and calculating the average of all computed error metrics, a comprehensive understanding of the forecast performance over time is attained.\\nProblems faced with Prophet’s Hyperparameter Tuning\\nIn our application case, we need to deal with numerous time series xm,m∈Mx_m, m \\\\in M. Our goal is to identify a parameter setting ˆω∈Ω\\\\hat\\\\omega \\\\in \\\\Omega for a single Prophet model that fits all these time series as best as possible, e.g. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 6, '_split_overlap': [{'doc_id': 'f9afcb100a276ac6427657e68c6a5963', 'range': (0, 411)}, {'doc_id': 'ce16103b88829af08cc09e1276400fc9', 'range': (822, 1291)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'c0adc74cc34fadc58eee9402ca7c0739'}>,\n",
      "                     <Document: {'content': 'Iterating across all cut-off points and calculating the average of all computed error metrics, a comprehensive understanding of the forecast performance over time is attained.\\nProblems faced with Prophet’s Hyperparameter Tuning\\nIn our application case, we need to deal with numerous time series xm,m∈Mx_m, m \\\\in M. Our goal is to identify a parameter setting ˆω∈Ω\\\\hat\\\\omega \\\\in \\\\Omega for a single Prophet model that fits all these time series as best as possible, e.g. this model with parameter settings ˆω\\\\hat\\\\omega ensures a reasonable forecast performance for all these time series recorded by the measurement points MM. We assume that the time series of the measurement points MM represent the unseen target data in their characteristics.\\nDue to high manual analysis efforts, individually evaluating each time series using Prophet’s cross-validation is an inefficient method. In addition, Prophet’s cross-validation neglects the effect of the training dataset’s size to which the model is fitted. This plays a crucial role in avoiding overfitting and also addresses the question of how much data must be recorded before running into a cold-start problem.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 7, '_split_overlap': [{'doc_id': 'c0adc74cc34fadc58eee9402ca7c0739', 'range': (0, 469)}, {'doc_id': 'cb3a3db5a12b92416a3dcfcc524cbd85', 'range': (744, 1159)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ce16103b88829af08cc09e1276400fc9'}>,\n",
      "                     <Document: {'content': 'Due to high manual analysis efforts, individually evaluating each time series using Prophet’s cross-validation is an inefficient method. In addition, Prophet’s cross-validation neglects the effect of the training dataset’s size to which the model is fitted. This plays a crucial role in avoiding overfitting and also addresses the question of how much data must be recorded before running into a cold-start problem.\\nAlternative evaluation strategy using Prophet for time series analysis\\nAn alternative approach would be to extend the cross-validation by leveraging similar observed patterns of all time series. For this purpose, observations are collected in advance through a deep data analysis, concerning holiday effects, seasonalities, and trend changes at certain changepoints. Also, the amount of historical data on which the model is fitted should be considered.\\nAnalogously to Grid Search, the cross-validation loop involves all combinations of collected values for the different observed criteria on different selected cut-off points. Pursuing this evaluation strategy results in k∗|M|∗|Ω|k* |M| *|\\\\Omega| experiments where |Ω||\\\\Omega| denotes the number of all different parameter combinations, and |M||M| is the number of all measurement points. A reduction of the number of experiments is achieved, by first starting to cross-validate single criteria. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 8, '_split_overlap': [{'doc_id': 'ce16103b88829af08cc09e1276400fc9', 'range': (0, 415)}, {'doc_id': '6d5c1fe3ba899d6cb3e18b0031547918', 'range': (870, 1363)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'cb3a3db5a12b92416a3dcfcc524cbd85'}>,\n",
      "                     <Document: {'content': 'Analogously to Grid Search, the cross-validation loop involves all combinations of collected values for the different observed criteria on different selected cut-off points. Pursuing this evaluation strategy results in k∗|M|∗|Ω|k* |M| *|\\\\Omega| experiments where |Ω||\\\\Omega| denotes the number of all different parameter combinations, and |M||M| is the number of all measurement points. A reduction of the number of experiments is achieved, by first starting to cross-validate single criteria. After figuring out appropriate criteria values, a final down-sized cross-validation loop can be implemented. Each experiment resembles different error statistics.\\n\\nThe figure depicts an illustration of the explained cross-validation strategy. Each distinct time series xm1,xm1x_{m1}, x_{m1} and xm3x_{m3} with m1,m2,m3∈Mm1, m2, m3 \\\\in M is evaluated on different cut off points k1,k2k_1, k_2 and k3k_3, each subjected to various parameter settings 1,2,…,n1, 2, \\\\ldots , n and differing sizes of training data.\\nIn the next step, computed error statistics provide the foundation for determining a suitable parameter setting. Further, it reveals in-depth findings about the present time series. It is important to consider an error statistic like the mean average percentage error to ensure comparability between the forecast performances of different time series. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 9, '_split_overlap': [{'doc_id': 'cb3a3db5a12b92416a3dcfcc524cbd85', 'range': (0, 493)}, {'doc_id': 'b4e8eb96a4234244dc7beb52af19ae3f', 'range': (1004, 1355)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '6d5c1fe3ba899d6cb3e18b0031547918'}>,\n",
      "                     <Document: {'content': 'In the next step, computed error statistics provide the foundation for determining a suitable parameter setting. Further, it reveals in-depth findings about the present time series. It is important to consider an error statistic like the mean average percentage error to ensure comparability between the forecast performances of different time series. In addition, a baseline should also be established that is trained at each cut-off point. Without much implementation effort, Prophet’s default setting can be used for this purpose.\\nAnalysis of error statistics and plots\\nAnalyzing the produced error statistics and forecast plots, we can deduce the optimal parameter setting. And even more important, the analysis can be tailored to desired needs. In our described application case, we are interested in a parameter setting that fits all time series well. This entails a comprehensive assessment of averaged error metrics for the considered parameter setups. Thus, the average of error metrics across all cut-off points and each time series is an initial insightful indicator. The following table shows an example of this calculation.\\n\\nDelving into the averaged performances across different cut-off points might uncover unnoticed weaknesses within certain time intervals. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 10, '_split_overlap': [{'doc_id': '6d5c1fe3ba899d6cb3e18b0031547918', 'range': (0, 351)}, {'doc_id': 'e3bf47b0b8a9fccf2f4032cfdb71774b', 'range': (858, 1274)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'b4e8eb96a4234244dc7beb52af19ae3f'}>,\n",
      "                     <Document: {'content': 'This entails a comprehensive assessment of averaged error metrics for the considered parameter setups. Thus, the average of error metrics across all cut-off points and each time series is an initial insightful indicator. The following table shows an example of this calculation.\\n\\nDelving into the averaged performances across different cut-off points might uncover unnoticed weaknesses within certain time intervals. Looking at the averaged performances for individual time series might clarify questions like what makes successful prediction difficult on these data.\\nBefore choosing a certain parameter setting, an individual examination in this particular setting for each time series is essential as well.\\nExperiences using Prophet as a forecasting model for electricity consumption\\nDespite computational costs to generate the error statistics for all different combinations of parameters, it is a fast method to develop a sense of what works effectively for forecasting. Furthermore, it reveals any potential issues. Overall it strengthens the understanding of the patterns and characteristics in the time series analysis. The verification by reviewing other parameter settings involving other factors like the training data size, seasonalities, and holiday effects also provides certainty that various options have been thoroughly explored.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 11, '_split_overlap': [{'doc_id': 'b4e8eb96a4234244dc7beb52af19ae3f', 'range': (0, 416)}, {'doc_id': 'd426ba2938b8bb1ea1fc2b28bbc48b4d', 'range': (975, 1345)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'e3bf47b0b8a9fccf2f4032cfdb71774b'}>,\n",
      "                     <Document: {'content': 'Furthermore, it reveals any potential issues. Overall it strengthens the understanding of the patterns and characteristics in the time series analysis. The verification by reviewing other parameter settings involving other factors like the training data size, seasonalities, and holiday effects also provides certainty that various options have been thoroughly explored.\\nWe experienced that Prophet’s default parameter setting already performs remarkably well on several time series. So it represents a worthy initiation for prototyping. We further noted that the inherited seasonalities capture underlying fluctuations well. No adaptation for the seasonality effects was required. Moreover, we observed that the inclusion of holidays can be highly beneficial if a global pattern is observed across all available time series.\\nWhile it may yield satisfactory results for many time series, it should be noted that it will not achieve the best possible forecasts for every individual time series. Each time series has its own characteristics, possesses outliers, and might be affected by individual external factors. It needs to be acknowledged that a global evaluation over several time series – even stemming from the same domain – does not replace a dedicated analysis for a single time series.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 12, '_split_overlap': [{'doc_id': 'e3bf47b0b8a9fccf2f4032cfdb71774b', 'range': (0, 370)}, {'doc_id': '8d149ff0bd7361632e7c875f719ae27f', 'range': (826, 1294)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'd426ba2938b8bb1ea1fc2b28bbc48b4d'}>,\n",
      "                     <Document: {'content': 'While it may yield satisfactory results for many time series, it should be noted that it will not achieve the best possible forecasts for every individual time series. Each time series has its own characteristics, possesses outliers, and might be affected by individual external factors. It needs to be acknowledged that a global evaluation over several time series – even stemming from the same domain – does not replace a dedicated analysis for a single time series.\\nOverall, Prophet’s ease of interpretation and the relatively small number of adjustments to its default hyperparameters contribute positively to its appeal and make it a strong choice for forecast applications in the electricity consumption context.', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching'], 'date': '26.09.2023', 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', '_split_id': 13, '_split_overlap': [{'doc_id': 'd426ba2938b8bb1ea1fc2b28bbc48b4d', 'range': (0, 468)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '8d149ff0bd7361632e7c875f719ae27f'}>,\n",
      "                     <Document: {'content': 'Machine Learning was long considered a difficult field where you had to employ a team of specialists to build good and useful models. In recent times, new services want to break this paradigm and make Machine Learning accessible for everyone by deciding on implementation details automatically. Of course, among others, the three largest cloud providers – Microsoft, Amazon, and Google – offer such AutoML services. They claim that one can train and deploy a Machine Learning service without being an expert in the field. In addition, this is supposed to be possible in a low- or no-code environment, that is, making Machine Learning available for users without great programming experience.\\nIn this article, I want to test this claim and provide an overview of the capabilities of different cloud providers. While I know a fair bit about Machine Learning I want to test the three services acting like I had no relevant experience in the field. I want to find out if AutoML services can actually lead to a democratization of Machine Learning. And will ML specialists then become obsolete? Let’s find out!\\n\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 0, '_split_overlap': [{'doc_id': '24d7c63d7975bd12ba5e0c26190213da', 'range': (809, 1105)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '7644afd3a9922457f54ea561957a7ac0'}>,\n",
      "                     <Document: {'content': 'While I know a fair bit about Machine Learning I want to test the three services acting like I had no relevant experience in the field. I want to find out if AutoML services can actually lead to a democratization of Machine Learning. And will ML specialists then become obsolete? Let’s find out!\\n\\nComparison of the AutoML ServicesA tabular comparison of the three large AutoML servicesIn PracticeThe InterfaceImporting and Preparing the Data for the AutoML ServiceModel Training and EvaluationDeployment and Querying the ModelMonitoring and RetrainingConclusion\\nComparison of the AutoML Services\\nAll three service providers offer a similar set of features. They all have an AutoML service for the most common ML problems and a way to run model training and inference within their systems in a no-code environment. The data types they support are also almost the same: All three support classification and regression tasks on tabular data as well as predictions on time series, image classification, and natural language problems such as text classification and entity extraction. Vertex AI and SageMaker also support tasks on videos such as action recognition and object tracking.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 1, '_split_overlap': [{'doc_id': '7644afd3a9922457f54ea561957a7ac0', 'range': (0, 296)}, {'doc_id': 'bcff9cbfab5076f9688cdad7d5475fac', 'range': (814, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '24d7c63d7975bd12ba5e0c26190213da'}>,\n",
      "                     <Document: {'content': 'The data types they support are also almost the same: All three support classification and regression tasks on tabular data as well as predictions on time series, image classification, and natural language problems such as text classification and entity extraction. Vertex AI and SageMaker also support tasks on videos such as action recognition and object tracking.\\nStill, there are some differences in the actual implementation of the features and how the services are integrated into the rest of the cloud environment. Also, how much work can actually be done in the GUI before you have to dive into the code? Before I describe how these differences affect using the service, let’s take a look at a higher-level comparison of the providers.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 2, '_split_overlap': [{'doc_id': '24d7c63d7975bd12ba5e0c26190213da', 'range': (0, 366)}, {'doc_id': '6481f66bb63ab1c897eb1ae240e7a266', 'range': (367, 743)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'bcff9cbfab5076f9688cdad7d5475fac'}>,\n",
      "                     <Document: {'content': 'Still, there are some differences in the actual implementation of the features and how the services are integrated into the rest of the cloud environment. Also, how much work can actually be done in the GUI before you have to dive into the code? Before I describe how these differences affect using the service, let’s take a look at a higher-level comparison of the providers.\\nA tabular comparison of the three large AutoML services\\n\\nDimension\\nAWS SageMaker\\nAzure AutoML\\nGCP Vertex AI\\n\\nSupport for Data Sources\\nFiles on S3, Athena, Redshift, Snowflake, Databricks, EMR and many third-party providers\\nAzure Blob Storage, Azure File Share, Azure Data Lake\\nCloud Storage, BigQuery\\n\\nData Import\\nData Upload/Preparation needs to be done manually in respective service, explicit exporting to S3\\nUpload within GUI when not using existing data\\nUpload within GUI when not using existing data\\n\\nComplexity of AutoML Model Training\\nBasic settings & sensible defaults available in GUI, a few advanced settings possible.\\nAuto-generated Notebook available for very detailed manual tweaking\\nBasic settings available, GUI provides more possibilities for advanced configuration than the other two services. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 3, '_split_overlap': [{'doc_id': 'bcff9cbfab5076f9688cdad7d5475fac', 'range': (0, 376)}, {'doc_id': '4509b875b1e1351d80e70a9bc54f4bef', 'range': (377, 1188)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '6481f66bb63ab1c897eb1ae240e7a266'}>,\n",
      "                     <Document: {'content': 'A tabular comparison of the three large AutoML services\\n\\nDimension\\nAWS SageMaker\\nAzure AutoML\\nGCP Vertex AI\\n\\nSupport for Data Sources\\nFiles on S3, Athena, Redshift, Snowflake, Databricks, EMR and many third-party providers\\nAzure Blob Storage, Azure File Share, Azure Data Lake\\nCloud Storage, BigQuery\\n\\nData Import\\nData Upload/Preparation needs to be done manually in respective service, explicit exporting to S3\\nUpload within GUI when not using existing data\\nUpload within GUI when not using existing data\\n\\nComplexity of AutoML Model Training\\nBasic settings & sensible defaults available in GUI, a few advanced settings possible.\\nAuto-generated Notebook available for very detailed manual tweaking\\nBasic settings available, GUI provides more possibilities for advanced configuration than the other two services. Only service with the ability to select cluster/compute type for training\\nSimple AutoML GUI only has basic settings.\\nVertex AI Pipelines provide more configuration but more complexity.\\n\\nModel Deployment\\nReal-Time/Batch Deployment with configurable instance type, configurable sampling of inputs/outputs. Traffic split possible via Code.\\nReal-Time/Batch Deployment with configurable instance type. Multiple models per endpoint with traffic split possible in GUI.\\nReal-Time/Batch Deployment with configurable instance type, configurable feature attribution, and model monitoring jobs. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 4, '_split_overlap': [{'doc_id': '6481f66bb63ab1c897eb1ae240e7a266', 'range': (0, 811)}, {'doc_id': '576d23e77842a46bb06d1dcd11a5387c', 'range': (929, 1394)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '4509b875b1e1351d80e70a9bc54f4bef'}>,\n",
      "                     <Document: {'content': 'Vertex AI Pipelines provide more configuration but more complexity.\\n\\nModel Deployment\\nReal-Time/Batch Deployment with configurable instance type, configurable sampling of inputs/outputs. Traffic split possible via Code.\\nReal-Time/Batch Deployment with configurable instance type. Multiple models per endpoint with traffic split possible in GUI.\\nReal-Time/Batch Deployment with configurable instance type, configurable feature attribution, and model monitoring jobs. Multiple models per endpoint with traffic split possible in GUI.\\n\\nModel Monitoring\\nMonitoring job needs to be written and scheduled via notebooks (low-code solution)\\nPublic Preview for Data drift, Prediction drift, Data quality and Feature attribution drift monitoring.\\nModel monitoring can be enabled via GUI to include data drift and prediction drift. Automatic retraining based on alerts can be enabled as well.\\n\\nIntegration in own application (Endpoint/local model)\\nREST calls to endpoint with Sagemaker library.\\nModel available for download in a respective format of the algorithm, no common download format\\nSample code for REST does not require additional libraries.\\nModel download contains sample code to run the model locally or as custom code on Azure\\nRPC call to Google’s endpoint in their library.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 5, '_split_overlap': [{'doc_id': '4509b875b1e1351d80e70a9bc54f4bef', 'range': (0, 465)}, {'doc_id': '326796910b2fa31e99ed531174fd5db7', 'range': (882, 1274)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '576d23e77842a46bb06d1dcd11a5387c'}>,\n",
      "                     <Document: {'content': 'Integration in own application (Endpoint/local model)\\nREST calls to endpoint with Sagemaker library.\\nModel available for download in a respective format of the algorithm, no common download format\\nSample code for REST does not require additional libraries.\\nModel download contains sample code to run the model locally or as custom code on Azure\\nRPC call to Google’s endpoint in their library.\\nModel download contains TensorFlow Package\\n\\nVersioning\\nModel registry available, via GUI or API\\nModel registry available\\nModel registry available, access via GUI or BigQuery\\n\\nCI/CD\\nPossible with Pipelines\\nPossible with Pipelines\\nPossible with Pipelines\\n\\nAvailability of pre-trained models\\nFoundation models for CV and NLP, also pre-trained models and LLM prompts for specific tasks\\nNLP models for various applications, partly from Huggingface. Also OpenAI Whisper for speech recognition\\nLarge selection of ML models for all kinds of problems. Huggingface models, Stable Diffusion, ImageNet, GluonCV\\n\\nData Quality\\nMany possibilities for manual analysis and fixing data quality problems\\nAutomatic analysis and fixing of simple problems, notifications and warnings if the data quality seems to be too bad\\nNo explicit checks for data quality, no explicit null handling for classification. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 6, '_split_overlap': [{'doc_id': '576d23e77842a46bb06d1dcd11a5387c', 'range': (0, 392)}, {'doc_id': 'f3478e5a4e88705c707ea2f43836c6c', 'range': (837, 1277)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '326796910b2fa31e99ed531174fd5db7'}>,\n",
      "                     <Document: {'content': 'Also OpenAI Whisper for speech recognition\\nLarge selection of ML models for all kinds of problems. Huggingface models, Stable Diffusion, ImageNet, GluonCV\\n\\nData Quality\\nMany possibilities for manual analysis and fixing data quality problems\\nAutomatic analysis and fixing of simple problems, notifications and warnings if the data quality seems to be too bad\\nNo explicit checks for data quality, no explicit null handling for classification. Null values in prediction tasks are imputed from surrounding values\\n\\nCost structure & transparency\\nHourly prices for everything depending on compute instance\\nHourly prices for everything depending on compute instance\\nSome AutoML prices fixed, everything else depends on the selected compute instance\\n\\nIn Practice\\nNow let’s see how this theoretical capability measures up in practice. I want to run an actual ML task on each of the services to compare my experience with them. For this I have decided to use the well-known Titanic Dataset which offers several advantages for this task:\\n\\nIt is rather small, allowing for quick training and evaluation times.\\nThere is no 1:1 relationship between the features and the prediction target. This means that we do not have to expect a rather boring result where all services return 100% accuracy.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 7, '_split_overlap': [{'doc_id': '326796910b2fa31e99ed531174fd5db7', 'range': (0, 440)}, {'doc_id': '6abffced08fb0be3c03d86b915713a09', 'range': (917, 1278)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f3478e5a4e88705c707ea2f43836c6c'}>,\n",
      "                     <Document: {'content': 'For this I have decided to use the well-known Titanic Dataset which offers several advantages for this task:\\n\\nIt is rather small, allowing for quick training and evaluation times.\\nThere is no 1:1 relationship between the features and the prediction target. This means that we do not have to expect a rather boring result where all services return 100% accuracy.\\nMany people already published their results with this dataset. From them, we can still infer a reasonable baseline for our expectations of the services.\\n\\nWith this dataset as a proxy for a real ML problem, I could see the different services in action. Now I can describe my experience of how well they actually work instead of only working with the providers’ documentation. So let’s go through an AutoML workflow with the three providers.\\nThe Interface\\nFrom the start, the user interface reflects the respective philosophy of the three AutoML services.\\nAWS SageMaker’s tabbed user interface is based on JupyterLab with a seamless transition between GUI-based tools and Jupyter Notebooks. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 8, '_split_overlap': [{'doc_id': 'f3478e5a4e88705c707ea2f43836c6c', 'range': (0, 361)}, {'doc_id': 'a41c50fb7b49fa2049bfbe37cca621f0', 'range': (614, 1050)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '6abffced08fb0be3c03d86b915713a09'}>,\n",
      "                     <Document: {'content': 'Now I can describe my experience of how well they actually work instead of only working with the providers’ documentation. So let’s go through an AutoML workflow with the three providers.\\nThe Interface\\nFrom the start, the user interface reflects the respective philosophy of the three AutoML services.\\nAWS SageMaker’s tabbed user interface is based on JupyterLab with a seamless transition between GUI-based tools and Jupyter Notebooks. SageMaker appears to be the most code-oriented provider of the three: While there is reasonable capability to run basic functions without having to write any code, even slightly advanced configuration needs to be done in code such as Jupyter Notebooks. Fortunately, SageMaker also provides most of the required boilerplate code in Notebook templates.\\nOn the contrary, Google’s Vertex AI provides a very simple GUI with friendly illustrations for their AutoML product. For the most part, everything that can be configured is available upfront, there are a few hidden submenus. The possibilities to switch from GUI to code are limited, you seem to be supposed to stay in the GUI.\\nMicrosoft’s Machine Learning Studio offers a compromise between the two. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 9, '_split_overlap': [{'doc_id': '6abffced08fb0be3c03d86b915713a09', 'range': (0, 436)}, {'doc_id': '6a52c099ad26b2516f6bf1ba1275cd5b', 'range': (788, 1187)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a41c50fb7b49fa2049bfbe37cca621f0'}>,\n",
      "                     <Document: {'content': 'On the contrary, Google’s Vertex AI provides a very simple GUI with friendly illustrations for their AutoML product. For the most part, everything that can be configured is available upfront, there are a few hidden submenus. The possibilities to switch from GUI to code are limited, you seem to be supposed to stay in the GUI.\\nMicrosoft’s Machine Learning Studio offers a compromise between the two. The GUI offers more possibilities for configuration in submenus or already during the regular workflows. The interface is unobtrusive and mostly designed for a low-code workflow. Still, VS Code is available as an IDE for running Jupyter Notebooks.\\nImporting and Preparing the Data for the AutoML Service\\nAt Vertex AI, the import is very easy using the provided GUI, either by uploading data directly which will be stored in Google Cloud Storage, providing an index file of the training data, or pointing to a BigQuery view or table. There is no workflow for further modifications of the data such as imputing missing values or balancing classes. Despite of this, I assume that some of this is automatically done in the background of the AutoML flow. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 10, '_split_overlap': [{'doc_id': 'a41c50fb7b49fa2049bfbe37cca621f0', 'range': (0, 399)}, {'doc_id': '4739d2b1dc80738a19fa36ae0372bc91', 'range': (648, 1149)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '6a52c099ad26b2516f6bf1ba1275cd5b'}>,\n",
      "                     <Document: {'content': 'Importing and Preparing the Data for the AutoML Service\\nAt Vertex AI, the import is very easy using the provided GUI, either by uploading data directly which will be stored in Google Cloud Storage, providing an index file of the training data, or pointing to a BigQuery view or table. There is no workflow for further modifications of the data such as imputing missing values or balancing classes. Despite of this, I assume that some of this is automatically done in the background of the AutoML flow. Simple statistics on the distribution of each feature are available in the GUI which suffice for superficial manual checks. Vertex AI hides further processing of the data from the user if that happens.\\nIn the Azure ML Studio, you can import data from the Azure Blob Storage or from Azure Delta Lake. After the import, Azure offers detailed introspections on the data with graphical representations, missing values, and some calculated statistics such as the standard deviation or quantiles for numeric values. Azure ML Studio has a feature named “Data Guardrails“ in the model training workflow where typical issues with the data are addressed during the training process. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 11, '_split_overlap': [{'doc_id': '6a52c099ad26b2516f6bf1ba1275cd5b', 'range': (0, 501)}, {'doc_id': 'a89d1b2ef4c06dbb8d177b6ac85dd42', 'range': (802, 1174)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '4739d2b1dc80738a19fa36ae0372bc91'}>,\n",
      "                     <Document: {'content': 'After the import, Azure offers detailed introspections on the data with graphical representations, missing values, and some calculated statistics such as the standard deviation or quantiles for numeric values. Azure ML Studio has a feature named “Data Guardrails“ in the model training workflow where typical issues with the data are addressed during the training process. These include imputing null values, and checking for high cardinality features and unbalanced classes.\\nAn import workflow in AWS SageMaker Studio\\nThe data import in AWS SageMaker has a slightly higher complexity than with the other providers because it is not designed for one-off imports but for reusability. Still, it works quite well as a no-code solution, using a graph-like interface to describe the data flows. One great advantage is that SageMaker offers the largest variety of data sources. They range from Amazon products such as S3, Athena, or Redshift to Databricks and Snowflake. Even a large variety of third-party import tools such as Google Ads, DataDog, or Salesforce is offered.\\nWhile there is no automatic check for potential issues with the data such as checking for null values or a warning for unbalanced class distributions, it is possible to add such steps manually. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 12, '_split_overlap': [{'doc_id': '4739d2b1dc80738a19fa36ae0372bc91', 'range': (0, 372)}, {'doc_id': 'e64e557529ec719d5b731c95700ad5ca', 'range': (965, 1262)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a89d1b2ef4c06dbb8d177b6ac85dd42'}>,\n",
      "                     <Document: {'content': 'Even a large variety of third-party import tools such as Google Ads, DataDog, or Salesforce is offered.\\nWhile there is no automatic check for potential issues with the data such as checking for null values or a warning for unbalanced class distributions, it is possible to add such steps manually. Other data transformations such as grouping and outlier detection can also be included. Additionally, one can add data analyses to the import flow. All this allows for creating complex data imports within a simple GUI. The disadvantage is that you have to know how to work with (messy) data, so you have to have some ML experience to get a useful result out of it.\\nOne advantage of Vertex AI and Azure ML is that data sources are refreshed automatically when the underlying data changes. While the data import flows at AWS SageMaker offer the greatest flexibility, they export the data again in a specific location and the flow needs to be rerun when the data changes. This also means that the data sets are not as well integrated with the rest of the process. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 13, '_split_overlap': [{'doc_id': 'a89d1b2ef4c06dbb8d177b6ac85dd42', 'range': (0, 297)}, {'doc_id': '181bdc300f378624be42aa6dc86b054a', 'range': (786, 1058)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'e64e557529ec719d5b731c95700ad5ca'}>,\n",
      "                     <Document: {'content': 'While the data import flows at AWS SageMaker offer the greatest flexibility, they export the data again in a specific location and the flow needs to be rerun when the data changes. This also means that the data sets are not as well integrated with the rest of the process. Instead during the training, you point the data towards the export location on S3 instead of the dataset.\\nModel Training and Evaluation\\nAll three services again have the same basic feature set. This includes selecting the data and some basic parameters such as the target metric and a training time limit. After the training you get at least one model together with some of its performance metrics: The F1 score, a confusion matrix, or a diagram with the ROC, to name a few. But again there are differences, especially regarding the extent to which the user can customize the process.\\nThe training of a new model in SageMaker ML Studio is easier than the import: With the data made available by the data flow, SageMaker is able to automatically infer the problem type, train model candidates and optimize hyperparameters. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 14, '_split_overlap': [{'doc_id': 'e64e557529ec719d5b731c95700ad5ca', 'range': (0, 272)}, {'doc_id': '60d02d29c873dc8e52d1cca2f0c8c22b', 'range': (748, 1094)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '181bdc300f378624be42aa6dc86b054a'}>,\n",
      "                     <Document: {'content': 'But again there are differences, especially regarding the extent to which the user can customize the process.\\nThe training of a new model in SageMaker ML Studio is easier than the import: With the data made available by the data flow, SageMaker is able to automatically infer the problem type, train model candidates and optimize hyperparameters. For the trained models some basic metrics such as accuracy, the ROC or the F1 score are available. While I would have hoped for more details on the model performance it should be enough to assess whether the model is suitable for the job. One bonus for experienced developers is that notebooks with boilerplate code for data exploration and model candidate generation are automatically made available. They still need to be adapted but appear to be a good starting point for further research.\\nThe AutoML in Azure process is comfortable to use and makes a more detailed configuration possible than the other two services while still keeping the process straightforward. For example, you can limit the training to certain model categories and configure for each feature how missing values should be imputed. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 15, '_split_overlap': [{'doc_id': '181bdc300f378624be42aa6dc86b054a', 'range': (0, 346)}, {'doc_id': 'abbcd486773bab9bfbbbaa1eee8c5bef', 'range': (749, 1152)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '60d02d29c873dc8e52d1cca2f0c8c22b'}>,\n",
      "                     <Document: {'content': 'They still need to be adapted but appear to be a good starting point for further research.\\nThe AutoML in Azure process is comfortable to use and makes a more detailed configuration possible than the other two services while still keeping the process straightforward. For example, you can limit the training to certain model categories and configure for each feature how missing values should be imputed. It is possible to manually define how the training/validation/test split is done and even add a second dataset purely as test data which may be very useful.\\nFeaturization configuration in AzureML\\nAs mentioned before, after the training Azure shows some information about the decisions that were made to prepare the input data: How the validation split was performed, whether the classes were balanced, missing features had to be imputed and how, features with a too high cardinality were discovered. This section named “Data Guardrails“ helped a lot to increase my trust in the result of the training.\\nFor the best resulting model, Azure also creates a dashboard with model metrics and charts such as the ROC. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 16, '_split_overlap': [{'doc_id': '60d02d29c873dc8e52d1cca2f0c8c22b', 'range': (0, 403)}, {'doc_id': '4e93a1a1226b071e25c3afacb054b316', 'range': (561, 1113)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'abbcd486773bab9bfbbbaa1eee8c5bef'}>,\n",
      "                     <Document: {'content': 'Featurization configuration in AzureML\\nAs mentioned before, after the training Azure shows some information about the decisions that were made to prepare the input data: How the validation split was performed, whether the classes were balanced, missing features had to be imputed and how, features with a too high cardinality were discovered. This section named “Data Guardrails“ helped a lot to increase my trust in the result of the training.\\nFor the best resulting model, Azure also creates a dashboard with model metrics and charts such as the ROC. In contrast to the other providers, this dashboard can be freely modified, charts can be added or removed as needed. There are also detailed explanations for the feature importance within the model. Most of these features are probably not relevant for someone without ML experience but they also help experienced ML practitioners to ascertain the training quality.\\nTraining a model with the Vertex AutoML interface is also very simple. Again, it is well structured and provides all the information needed to quickly start the training. There are some configuration possibilities such as modifying the data split between training, validation, and test data. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 17, '_split_overlap': [{'doc_id': 'abbcd486773bab9bfbbbaa1eee8c5bef', 'range': (0, 552)}, {'doc_id': 'f82227c24cd042564b0cf65f9ac5e893', 'range': (752, 1209)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '4e93a1a1226b071e25c3afacb054b316'}>,\n",
      "                     <Document: {'content': 'Most of these features are probably not relevant for someone without ML experience but they also help experienced ML practitioners to ascertain the training quality.\\nTraining a model with the Vertex AutoML interface is also very simple. Again, it is well structured and provides all the information needed to quickly start the training. There are some configuration possibilities such as modifying the data split between training, validation, and test data. Despite this are only very few possibilities to influence the process. One notable distinction between the other two services is that Google’s AutoML service does not let you decide on the compute instance the training runs on. Instead, there is a fee that is only dependent on the duration of the training, again configurable in the GUI.\\nModel Evaluation in Google’s Vertex AutoML Service\\nWhen the training has finished, only the best model remains visible to the user, and the model evaluation again only has a few statistics and graphs such as the ROC. Since this service is intended for developers with little ML experience this may be sufficient.\\nRegarding the resulting prediction accuracy, I could not find a significant difference between the providers. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 18, '_split_overlap': [{'doc_id': '4e93a1a1226b071e25c3afacb054b316', 'range': (0, 457)}, {'doc_id': 'b69ed50a4ed9822b48ee448ea08196b1', 'range': (797, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f82227c24cd042564b0cf65f9ac5e893'}>,\n",
      "                     <Document: {'content': 'Model Evaluation in Google’s Vertex AutoML Service\\nWhen the training has finished, only the best model remains visible to the user, and the model evaluation again only has a few statistics and graphs such as the ROC. Since this service is intended for developers with little ML experience this may be sufficient.\\nRegarding the resulting prediction accuracy, I could not find a significant difference between the providers. The result from Azure AutoML, a large model ensemble, showed the best performance. Still, this may also be caused by random factors such as the training/test data split. In my opinion, the differences were not large enough to imply fundamental performance differences between the services. A detailed comparison of the performance of the services with multiple ML problems may lead to a finer differentiation. Still, I believe that the differences will not be that significant.\\nDeployment and Querying the Model\\nWith the resulting model there are two ways we can make predictions with it: Deploy it directly with the respective provider’s tools or download and run it on our own. Of course, the providers want us to use their services but all three offer a model download with varying difficulty. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 19, '_split_overlap': [{'doc_id': 'f82227c24cd042564b0cf65f9ac5e893', 'range': (0, 422)}, {'doc_id': '55c85afbcc22932215f2efb8b1ca1663', 'range': (901, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'b69ed50a4ed9822b48ee448ea08196b1'}>,\n",
      "                     <Document: {'content': 'Deployment and Querying the Model\\nWith the resulting model there are two ways we can make predictions with it: Deploy it directly with the respective provider’s tools or download and run it on our own. Of course, the providers want us to use their services but all three offer a model download with varying difficulty. One possibility to deploy a model yourself would be by using BentoML as your MLOps tool.\\nVertex AI’s trained model can either be downloaded as a TensorFlow package or deployed to an endpoint. Deploying to an endpoint is mostly very simple, although the current example code is inconsistent with the library and you have to make some fixes for the example to work. With the fixed code it is rather easy to make a request. The endpoint uses a gRPC call with a payload encoded in Protobuf format, so you are dependent on Google’s libraries if you want to include this service in your own code. This may induce unnecessary bloat in smaller Python applications.\\nAn advantage of Vertex AI is that it is very simple to deploy multiple models to the same endpoint with a customizable traffic split. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 20, '_split_overlap': [{'doc_id': 'b69ed50a4ed9822b48ee448ea08196b1', 'range': (0, 318)}, {'doc_id': 'b7fa87f8a1201a2860d40ad473e89ef2', 'range': (740, 1109)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '55c85afbcc22932215f2efb8b1ca1663'}>,\n",
      "                     <Document: {'content': 'The endpoint uses a gRPC call with a payload encoded in Protobuf format, so you are dependent on Google’s libraries if you want to include this service in your own code. This may induce unnecessary bloat in smaller Python applications.\\nAn advantage of Vertex AI is that it is very simple to deploy multiple models to the same endpoint with a customizable traffic split. This makes A/B testing or staggered updates very comfortable. Contrary to the training the endpoint can be configured to run on a certain compute instance so that it can be scaled according to your needs. It is also possible to enable model monitoring during endpoint creation. This allows you to catch data drift or prediction drift which may occur over time. By default the monitoring sends a warning mail but it is possible to include additional warning channels to enable automated reactions such as model retraining.\\nThe deployment in AWS SageMaker itself is quite simple as well. The important decision again is which compute instance should be used, depending on the model size and expected load on the endpoint. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 21, '_split_overlap': [{'doc_id': '55c85afbcc22932215f2efb8b1ca1663', 'range': (0, 369)}, {'doc_id': '305a8c7d143e290e5bee4cf5ce71919c', 'range': (731, 1089)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'b7fa87f8a1201a2860d40ad473e89ef2'}>,\n",
      "                     <Document: {'content': 'By default the monitoring sends a warning mail but it is possible to include additional warning channels to enable automated reactions such as model retraining.\\nThe deployment in AWS SageMaker itself is quite simple as well. The important decision again is which compute instance should be used, depending on the model size and expected load on the endpoint. There are two types of endpoints: A real-time endpoint is a REST interface which expects and returns CSV data. On the other hand, a batch endpoint is configured with an input and output directory in S3. The provided sample code allowed me to query the endpoint with minimal effort although I consider it less than ideal that I have to use the Sagemaker Python library even for a simple request.\\nAzure ML Studio offers the best way for both use cases, whether you want to run it locally or use an endpoint: Azure provides a model download which includes a Python file intended to be run on their servers if you want to run a custom inference script. While the script can be run locally it requires Python 3.8 and is not compatible with current Python versions. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 22, '_split_overlap': [{'doc_id': 'b7fa87f8a1201a2860d40ad473e89ef2', 'range': (0, 358)}, {'doc_id': '46ee7f9f4c5a33f4d3d569f224313644', 'range': (754, 1118)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '305a8c7d143e290e5bee4cf5ce71919c'}>,\n",
      "                     <Document: {'content': 'Azure ML Studio offers the best way for both use cases, whether you want to run it locally or use an endpoint: Azure provides a model download which includes a Python file intended to be run on their servers if you want to run a custom inference script. While the script can be run locally it requires Python 3.8 and is not compatible with current Python versions. The example code for calling the endpoint is simpler. Azure also provides a REST endpoint, and the example code calls it without requiring packages outside of the Python standard library. Within the example code the data structures also make multiple predictions per request very comfortable to implement.\\nMonitoring and Retraining\\nSince input data may change over time it is important to ensure that predictions remain accurate. We have multiple points where we can check a drift over time, such as distributions of the input data, feature attribution for the prediction, or the distribution of the predictions. Often these changes can be alleviated by retraining the model. All three platforms put this firmly outside of their no-code interface with only the monitoring being configurable in the GUI. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 23, '_split_overlap': [{'doc_id': '305a8c7d143e290e5bee4cf5ce71919c', 'range': (0, 364)}, {'doc_id': '26a5a78ac49e86680a0e4defbebc35dd', 'range': (795, 1167)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '46ee7f9f4c5a33f4d3d569f224313644'}>,\n",
      "                     <Document: {'content': 'We have multiple points where we can check a drift over time, such as distributions of the input data, feature attribution for the prediction, or the distribution of the predictions. Often these changes can be alleviated by retraining the model. All three platforms put this firmly outside of their no-code interface with only the monitoring being configurable in the GUI. Reacting to potential alerts and automatically triggering a retraining pipeline needs to be done in code. All three providers offer example code in their knowledge bases which is helpful here.\\nOne notable mention goes to Vertex AI, the only service with a GUI for data drift or model drift detection. This step also needs to be configured in code for the other two services. Automatic reactions to the alert channels still need to be coded but we have at least e-mail monitoring and the other available channels from the Google Cloud Monitoring service built-in.\\nConclusion\\nGoogle’s Vertex AI, Amazon’s AWS SageMaker, and Microsoft’s Azure ML Studio all provide a solid platform for AutoML applications. Still, there are some differences between the services. I believe they are mostly only interesting for organizations that do not yet have an established ML infrastructure. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 24, '_split_overlap': [{'doc_id': '46ee7f9f4c5a33f4d3d569f224313644', 'range': (0, 372)}, {'doc_id': 'e1948e59b5908591e9cb0dd6f7aa4274', 'range': (748, 1248)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '26a5a78ac49e86680a0e4defbebc35dd'}>,\n",
      "                     <Document: {'content': 'Automatic reactions to the alert channels still need to be coded but we have at least e-mail monitoring and the other available channels from the Google Cloud Monitoring service built-in.\\nConclusion\\nGoogle’s Vertex AI, Amazon’s AWS SageMaker, and Microsoft’s Azure ML Studio all provide a solid platform for AutoML applications. Still, there are some differences between the services. I believe they are mostly only interesting for organizations that do not yet have an established ML infrastructure. For those who are already customers of a certain provider, it probably makes the most sense to just stay with their respective provider, migration costs overshadow the possible benefits of using a different service.\\nOf course, the availability of AutoML services is not limited to the three major cloud providers. Many other companies offer AutoML services. There are also toolkits such as auto-sklearn to run an AutoML pipeline on your own. Still, with many companies already using the cloud it makes sense for them to also use the toolset available there.\\nVertex AI provides a very comfortable starting point for new AutoML applications. The interface is friendly and easy to use, although the set of advanced features is rather limited. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 25, '_split_overlap': [{'doc_id': '26a5a78ac49e86680a0e4defbebc35dd', 'range': (0, 500)}, {'doc_id': 'fd4d86009e33da376b4e9010359364e9', 'range': (859, 1240)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'e1948e59b5908591e9cb0dd6f7aa4274'}>,\n",
      "                     <Document: {'content': 'There are also toolkits such as auto-sklearn to run an AutoML pipeline on your own. Still, with many companies already using the cloud it makes sense for them to also use the toolset available there.\\nVertex AI provides a very comfortable starting point for new AutoML applications. The interface is friendly and easy to use, although the set of advanced features is rather limited. The service works well for initial evaluations of which predictions may be possible on given data.\\nAWS SageMaker has a steeper learning curve in the beginning but with it more features are available. Especially for data analysis and preparation, there are more tools available but they add complexity. So if you have a good understanding of data preparation, arguably the most important part of Machine Learning, SageMaker can take away some of the work for you. Beginners may have difficulties navigating what SageMaker needs to produce good results.\\nAzure ML Studio offers a compromise: It has a lot of built-in features and takes away some work but still explains what it does. It also offers most possibilities to tweak some of the neuralgic settings. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 26, '_split_overlap': [{'doc_id': 'e1948e59b5908591e9cb0dd6f7aa4274', 'range': (0, 381)}, {'doc_id': 'fb69d8c7e21b9a77de9e1700d95cda27', 'range': (684, 1137)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'fd4d86009e33da376b4e9010359364e9'}>,\n",
      "                     <Document: {'content': 'So if you have a good understanding of data preparation, arguably the most important part of Machine Learning, SageMaker can take away some of the work for you. Beginners may have difficulties navigating what SageMaker needs to produce good results.\\nAzure ML Studio offers a compromise: It has a lot of built-in features and takes away some work but still explains what it does. It also offers most possibilities to tweak some of the neuralgic settings. You are encouraged to write code yourself and the available analysis tools require some understanding of ML. Still, even without it, you can work with the service just fine.\\nSo, do these three services live up to their promise of the democratization of Machine Learning? In my opinion, they can help with it but bring their own liabilities. Especially in critical applications we need to understand how and why a system acts like it does. Although some of the services make attempts at explainability, experts are still needed. Their knowledge makes it possible to assess how an ML system actually makes its predictions. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 27, '_split_overlap': [{'doc_id': 'fd4d86009e33da376b4e9010359364e9', 'range': (0, 453)}, {'doc_id': 'ed131c23ed953e728ac84e0685e5ec6f', 'range': (725, 1074)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'fb69d8c7e21b9a77de9e1700d95cda27'}>,\n",
      "                     <Document: {'content': 'In my opinion, they can help with it but bring their own liabilities. Especially in critical applications we need to understand how and why a system acts like it does. Although some of the services make attempts at explainability, experts are still needed. Their knowledge makes it possible to assess how an ML system actually makes its predictions. The better a service hides how it works and how its decisions are made, the easier it is for non-experts but also the less trust a company can put into their AutoML system.\\nFor experts, AutoML services may be very helpful to run one-off predictions that do not need to be integrated into a larger system. Additionally, one important use case may be to create a baseline against which to measure future development. In the\\xa0MLOps Lifecycle, they can therefore serve as a starting point for the development of a more sustainable model. But still, these systems provide no support channels and explanations that laypersons can understand. Therefore businesses that want to rely on Machine Learning systems will still rely on human experts to design them.', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/self-service-ai-for-everyone-a-comparison-of-automl-services/', 'authors': ['Jonas Böer'], 'date': '27.10.2023', 'title': 'Self-Service AI for everyone? A comparison of AutoML services', '_split_id': 28, '_split_overlap': [{'doc_id': 'fb69d8c7e21b9a77de9e1700d95cda27', 'range': (0, 349)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ed131c23ed953e728ac84e0685e5ec6f'}>],\n",
      "    'node_id': 'document_store',\n",
      "    'params': {},\n",
      "    'root_node': 'File'}\n"
     ]
    }
   ],
   "source": [
    "# Print all documents that have been created\n",
    "pp.pprint(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (Snippet) Count: 185\n"
     ]
    }
   ],
   "source": [
    "print(\"Document (Snippet) Count:\", len(document_store.get_all_documents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question Answering : Query PIpeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from haystack.nodes import EmbeddingRetriever, FARMReader, BM25Retriever\n",
    "from haystack import Pipeline\n",
    "from haystack.utils import print_answers\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"embedding\": {\"type\": \"dense_vector\", \"dims\": 384},\n",
    "            \"authors\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"keyword\"},\n",
    "            \"date\": {\n",
    "                \"type\":   \"date\",\n",
    "                \"format\": \"dd.MM.yyyy\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Connect documentstore\n",
    "document_store = ElasticsearchDocumentStore(host=\"172.17.0.1\", index=\"blogs_clean1\", port=9200, custom_mapping=mapping)\n",
    "\n",
    "# Define nodes\n",
    "retriever = EmbeddingRetriever(\n",
    "        embedding_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        document_store=document_store,\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "query_pipe = Pipeline()\n",
    "query_pipe.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])    # Searches for relevant `documents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17b89c7947e49a5ad3cfb09716afd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Overall, Prophet’s ease of interpretation and the relatively small number of adjustments to its default hyperparameters contribute positively to its appeal and make it a strong choice for forecast applications in the electricity consumption context.\n",
      "\n",
      "1. Iterating across all cut-off points and calculating the average of all computed error metrics, a comprehensive understanding of the forecast performance over time is attained.\n",
      "Problems faced with Prophet’s Hyperparameter Tuning\n",
      "In our application case, we need to deal with numerous time series xm,m∈Mx_m, m \\in M. Our goal is to identify a parameter setting ˆω∈Ω\\hat\\omega \\in \\Omega for a single Prophet model that fits all these time series as best as possible, e.g. this model with parameter settings ˆω\\hat\\omega ensures a reasonable forecast performance for all these time series recorded by the measurement points MM. We assume that the time series of the measurement points MM represent the unseen target data in their characteristics.\n",
      "Due to high manual analysis efforts, individually evaluating each time series using Prophet’s cross-validation is an inefficient method. In addition, Prophet’s cross-validation neglects the effect of the training dataset’s size to which the model is fitted. This plays a crucial role in avoiding overfitting and also addresses the question of how much data must be recorded before running into a cold-start problem.\n",
      "\n",
      "\n",
      "2. Prophet’s Hyperparameter Tuning\n",
      "Prophet offers cross-validation functionalities to quickly and easily find the best working forecast model across various hyperparameters. It utilizes the so-called simulated historical forecast. The simulated historical forecast is based on a rolling origin evaluation procedure for assessing the quantitative performance of time series forecasts.\n",
      "For this purpose, kk cut-off points are determined while ensuring that the forecast remains within the historical data. A model is fitted up to a certain cut-off point. Subsequently, predicted values are compared to actual values within the chosen horizon. Iterating across all cut-off points and calculating the average of all computed error metrics, a comprehensive understanding of the forecast performance over time is attained.\n",
      "Problems faced with Prophet’s Hyperparameter Tuning\n",
      "In our application case, we need to deal with numerous time series xm,m∈Mx_m, m \\in M. Our goal is to identify a parameter setting ˆω∈Ω\\hat\\omega \\in \\Omega for a single Prophet model that fits all these time series as best as possible, e.g. this model with parameter settings ˆω\\hat\\omega ensures a reasonable forecast performance for all these time series recorded by the measurement points MM. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = query_pipe.run(\n",
    "    query=\"Tell me about Prophet’s Hyperparameter Tuning?\", params={\"Retriever\": {\"top_k\": 3}}\n",
    ")\n",
    "\n",
    "# print_answers(prediction, details=\"all\")\n",
    "for idx, doc in enumerate(retrieved_docs[\"documents\"]):\n",
    "    print(f\"{idx}. \" + doc.content + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do better - Integrating GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack.nodes import PromptModel, PromptNode\n",
    "\n",
    "load_dotenv(\"./.env\")\n",
    "\n",
    "api_key = os.environ.get(\"AZURE_API_KEY\")\n",
    "deployment_name = os.environ.get(\"AZURE_DEPLOYMENT_NAME\")\n",
    "base_url = os.environ.get(\"AZURE_BASE_URL\")\n",
    "\n",
    "# Init Model - Connects to Azure\n",
    "azure_model = PromptModel(\n",
    "    model_name_or_path=\"gpt-35-turbo\",\n",
    "    api_key=api_key,\n",
    "    model_kwargs={\n",
    "        \"azure_deployment_name\": deployment_name,\n",
    "        \"azure_base_url\": base_url,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Init PromptNode\n",
    "prompt_node = PromptNode(model_name_or_path=azure_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Haystack by deepset is an open-source framework that simplifies the development of scalable and efficient question-answering systems.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Test PromptNode\n",
    "\n",
    "# Construct Message\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant\"}]\n",
    "messages.append({\"role\": \"user\", \"content\": \"Tell me 1 sentence about haystack by deepset?\"})\n",
    "\n",
    "# Call PromptNode -> Calls OpenAI/Azure API\n",
    "result = prompt_node(messages)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(index=\"blogs_clean1\", custom_mapping=mapping)\n",
    "\n",
    "# Create nodes\n",
    "retriever = EmbeddingRetriever(\n",
    "    embedding_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    document_store=document_store,\n",
    ")\n",
    "\n",
    "\n",
    "# PromptTemplate adds additional context to PromptNode\n",
    "qa_prompt = PromptTemplate(\n",
    "    prompt=\"\"\"Given the context, provide a short consise answer to the question.\n",
    "                Context: {join(documents)}; \n",
    "                Question: {query}; \n",
    "                Answer:\"\"\",\n",
    "    output_parser=AnswerParser(),\n",
    ")\n",
    "\n",
    "# Combine Azure Model with Prompt\n",
    "prompt_node = PromptNode(\n",
    "    model_name_or_path=azure_model,\n",
    "    default_prompt_template=qa_prompt\n",
    ")\n",
    "\n",
    "\n",
    "# Create Pipeline\n",
    "inovex_query_pipe = Pipeline()\n",
    "inovex_query_pipe.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "inovex_query_pipe.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d0edb9f4d84e90bc6c6fcd1da849c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: Tell me about Prophet’s Hyperparameter Tuning?'\n",
      "'Answers:'\n",
      "[   {   'answer': 'Prophet offers cross-validation functionalities to quickly '\n",
      "                  'and easily find the best working forecast model across '\n",
      "                  'various hyperparameters. It utilizes the simulated '\n",
      "                  'historical forecast, which is based on a rolling origin '\n",
      "                  'evaluation procedure for assessing the quantitative '\n",
      "                  'performance of time series forecasts. The goal is to '\n",
      "                  'identify a parameter setting for a single Prophet model '\n",
      "                  'that fits all time series recorded by the measurement '\n",
      "                  'points as best as possible.'}]\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "\n",
    "output = inovex_query_pipe.run(query=\"Tell me about Prophet’s Hyperparameter Tuning?\", params={\"Retriever\": {\"top_k\": 3}})\n",
    "# print(output[\"answers\"][0].answer)\n",
    "print_answers(output, details=\"minimum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with Reader model: (We could skip the Reader model altogether, as its functionality is replaced by gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot validate index for custom mappings. Skipping index validation.\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import EmbeddingRetriever, FARMReader, BM25Retriever\n",
    "from haystack import Pipeline\n",
    "from haystack.utils import print_answers\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"embedding\": {\"type\": \"dense_vector\", \"dims\": 384},\n",
    "            \"authors\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"keyword\"},\n",
    "            \"date\": {\n",
    "                \"type\":   \"date\",\n",
    "                \"format\": \"dd.MM.yyyy\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Connect documentstore\n",
    "document_store = ElasticsearchDocumentStore(index=\"blogs_clean1\", custom_mapping=mapping)\n",
    "\n",
    "# Define nodes\n",
    "retriever = EmbeddingRetriever(\n",
    "        embedding_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        document_store=document_store,\n",
    ")\n",
    "\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=False)\n",
    "\n",
    "# Define pipeline\n",
    "query_pipe = Pipeline()\n",
    "query_pipe.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])    # Searches for relevant `documents`\n",
    "query_pipe.add_node(component=reader, name=\"Reader\", inputs=[\"Retriever\"])      # Extract top answers from retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e4e50813e84e1bab636b10a90ce4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:06<00:00,  6.26s/ Batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: Tell me about Prophet’s Hyperparameter Tuning?'\n",
      "'Answers:'\n",
      "[   <Answer {'answer': 'Problems faced with Prophet’s Hyperparameter TuningAlternative evaluation strategy using Prophet for time series analysisAnalysis of error statistics and plotsExperiences using Prophet as a forecasting model for electricity consumption\\nWhat is Prophet?\\nConstructing time series forecasting requires a sophisticated set of methods to capture the complex patterns of time-dependent data. In 2017, researchers from Facebook presented their open-source project named Prophet, a framework tailored for modeling time series in Python or R. in their paper “Forecasting at Scale“. It stands out for its user-friendly simplicity', 'type': 'extractive', 'score': 0.3024429380893707, 'context': 'gProblems faced with Prophet’s Hyperparameter TuningAlternative evaluation strategy using Prophet for time series analysisAnalysis of error statistics and plotsExperiences using Prophet as a forecasting model for electricity consumption\\nWhat is Prophet?\\nConstructing time series forecasting requires a sophisticated set of methods to capture the complex patterns of time-dependent data. In 2017, researchers from Facebook presented their open-source project named Prophet, a framework tailored for modeling time series in Python or R. in their paper “Forecasting at Scale“. It stands out for its user-friendly simplicity', 'offsets_in_document': [{'start': 635, 'end': 1254}], 'offsets_in_context': [{'start': 1, 'end': 620}], 'document_ids': ['da63156ea86f8f0fc4426870b80c640b'], 'meta': {'date': '26.09.2023', '_split_id': 1, 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', 'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching']}}>,\n",
      "    <Answer {'answer': 'ease of interpretation and the relatively small number of adjustments', 'type': 'extractive', 'score': 0.14190012216567993, 'context': 'Overall, Prophet’s ease of interpretation and the relatively small number of adjustments to its default hyperparameters contribute positively to its a', 'offsets_in_document': [{'start': 19, 'end': 88}], 'offsets_in_context': [{'start': 19, 'end': 88}], 'document_ids': ['7baeea47e52ebc8a167118ea4122b789'], 'meta': {'date': '26.09.2023', '_split_id': 9, 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', 'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching']}}>,\n",
      "    <Answer {'answer': 'Problems', 'type': 'extractive', 'score': 0.136042520403862, 'context': 'nsive understanding of the forecast performance over time is attained.\\nProblems faced with Prophet’s Hyperparameter Tuning\\nIn our application case, we', 'offsets_in_document': [{'start': 814, 'end': 822}], 'offsets_in_context': [{'start': 71, 'end': 79}], 'document_ids': ['210a0c3d05001274a896eb55a367fa99'], 'meta': {'date': '26.09.2023', '_split_id': 4, 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', 'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching']}}>,\n",
      "    <Answer {'answer': 'user-friendly simplicity', 'type': 'extractive', 'score': 0.03298056870698929, 'context': '. in their paper “Forecasting at Scale“. It stands out for its user-friendly simplicity and is purpose-built to deliver precise time-series prediction', 'offsets_in_document': [{'start': 1230, 'end': 1254}], 'offsets_in_context': [{'start': 63, 'end': 87}], 'document_ids': ['da63156ea86f8f0fc4426870b80c640b'], 'meta': {'date': '26.09.2023', '_split_id': 1, 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', 'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching']}}>,\n",
      "    <Answer {'answer': 'easy tweaking of hyperparameters, and robust handling of missing records or outliers', 'type': 'extractive', 'score': 0.029191885143518448, 'context': 'ike efficient and fast training, easy tweaking of hyperparameters, and robust handling of missing records or outliers, make Prophet an appealing time ', 'offsets_in_document': [{'start': 718, 'end': 802}], 'offsets_in_context': [{'start': 33, 'end': 117}], 'document_ids': ['ba8d7ae577db8e4d99dd89e4152c96b9'], 'meta': {'date': '26.09.2023', '_split_id': 2, 'title': 'Voltage and Variables – Exploring Forecasting for Electricity Consumption through Time Series Analysis with the Prophet Model', 'url': 'https://www.inovex.de/de/blog/voltage-and-variables-exploring-forecasting-for-electricity-consumption-through-time-series-analysis-with-the-prophet-model/', 'authors': ['Marie-Kristin Wirsching']}}>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = query_pipe.run(\n",
    "    query=\"Tell me about Prophet’s Hyperparameter Tuning?\", params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    ")\n",
    "\n",
    "print_answers(prediction, details=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: Tell me about Prophet’s Hyperparameter Tuning?'\n",
      "'Answers:'\n",
      "[   {   'answer': 'Problems faced with Prophet’s Hyperparameter '\n",
      "                  'TuningAlternative evaluation strategy using Prophet for '\n",
      "                  'time series analysisAnalysis of error statistics and '\n",
      "                  'plotsExperiences using Prophet as a forecasting model for '\n",
      "                  'electricity consumption\\n'\n",
      "                  'What is Prophet?\\n'\n",
      "                  'Constructing time series forecasting requires a '\n",
      "                  'sophisticated set of methods to capture the complex '\n",
      "                  'patterns of time-dependent data. In 2017, researchers from '\n",
      "                  'Facebook presented their open-source project named Prophet, '\n",
      "                  'a framework tailored for modeling time series in Python or '\n",
      "                  'R. in their paper “Forecasting at Scale“. It stands out for '\n",
      "                  'its user-friendly simplicity',\n",
      "        'context': 'gProblems faced with Prophet’s Hyperparameter '\n",
      "                   'TuningAlternative evaluation strategy using Prophet for '\n",
      "                   'time series analysisAnalysis of error statistics and '\n",
      "                   'plotsExperiences using Prophet as a forecasting model for '\n",
      "                   'electricity consumption\\n'\n",
      "                   'What is Prophet?\\n'\n",
      "                   'Constructing time series forecasting requires a '\n",
      "                   'sophisticated set of methods to capture the complex '\n",
      "                   'patterns of time-dependent data. In 2017, researchers from '\n",
      "                   'Facebook presented their open-source project named '\n",
      "                   'Prophet, a framework tailored for modeling time series in '\n",
      "                   'Python or R. in their paper “Forecasting at Scale“. It '\n",
      "                   'stands out for its user-friendly simplicity'},\n",
      "    {   'answer': 'ease of interpretation and the relatively small number of '\n",
      "                  'adjustments',\n",
      "        'context': 'Overall, Prophet’s ease of interpretation and the '\n",
      "                   'relatively small number of adjustments to its default '\n",
      "                   'hyperparameters contribute positively to its a'},\n",
      "    {   'answer': 'Problems',\n",
      "        'context': 'nsive understanding of the forecast performance over time '\n",
      "                   'is attained.\\n'\n",
      "                   'Problems faced with Prophet’s Hyperparameter Tuning\\n'\n",
      "                   'In our application case, we'},\n",
      "    {   'answer': 'user-friendly simplicity',\n",
      "        'context': '. in their paper “Forecasting at Scale“. It stands out for '\n",
      "                   'its user-friendly simplicity and is purpose-built to '\n",
      "                   'deliver precise time-series prediction'},\n",
      "    {   'answer': 'easy tweaking of hyperparameters, and robust handling of '\n",
      "                  'missing records or outliers',\n",
      "        'context': 'ike efficient and fast training, easy tweaking of '\n",
      "                   'hyperparameters, and robust handling of missing records or '\n",
      "                   'outliers, make Prophet an appealing time '}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"minimum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversations : Introducting Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Agent's Tools\n",
    "\n",
    "- inovex_query_pipeline (from before)\n",
    "- game_query_pipeline (Pipeline accesses 'Game of Thrones' database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PromptTemplate & Define Pipeline\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser\n",
    "\n",
    "# Init database\n",
    "document_store = ElasticsearchDocumentStore(index=\"blogs_clean1\", custom_mapping=mapping)\n",
    "\n",
    "# Create nodes\n",
    "# Create PromptTemplate with additinal context send PromptModel\n",
    "qa_prompt = PromptTemplate(\n",
    "    prompt=\"\"\"Given the context, answer the question in 1 or 2 sentences.\n",
    "                Context: {join(documents)}; \n",
    "                Question: {query}; \n",
    "                Answer:\"\"\",\n",
    "    output_parser=AnswerParser(),\n",
    ")\n",
    "\n",
    "# Combine PromptModel & PromptTemplate\n",
    "prompt_node = PromptNode(\n",
    "    model_name_or_path=azure_model,\n",
    "    default_prompt_template=qa_prompt\n",
    ")\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\",\n",
    "    document_store=document_store,\n",
    ")\n",
    "\n",
    "# Create Pipeline\n",
    "game_prompt_pipeline = Pipeline()\n",
    "game_prompt_pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "game_prompt_pipeline.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Retriever\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.agents.base import Tool\n",
    "from haystack.agents.conversational import ConversationalAgent\n",
    "from haystack.agents.memory import ConversationSummaryMemory\n",
    "\n",
    "inovex_blog_crawler_tool = Tool(\n",
    "    name=\"inovex_blog_crawler\",\n",
    "    pipeline_or_node=inovex_query_pipe,\n",
    "    description=\"useful for when you need to find content from the inovex blog\", # agent uses this for its decision!\n",
    "    output_variable=\"answers\",\n",
    ")\n",
    "\n",
    "got_qa_tool = Tool(\n",
    "    name=\"games_of_thrones_QA\",\n",
    "    pipeline_or_node=game_prompt_pipeline,\n",
    "    description=\"useful for when you need to answer questions about games of thrones\",\n",
    "    output_variable=\"answers\",\n",
    ")\n",
    "\n",
    "tools = [inovex_blog_crawler_tool, got_qa_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conversational_agent_prompt_node = PromptNode(\n",
    "    model_name_or_path=azure_model,\n",
    "    max_length=256,\n",
    "    top_k=2,\n",
    "    stop_words=[\"Observation:\"], # react framework\n",
    "    model_kwargs={\"temperature\": 0.5, \"top_p\": 0.9}\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(conversational_agent_prompt_node, summary_frequency=2)\n",
    "\n",
    "zero_shot_agent_template = PromptTemplate(\"deepset/zero-shot-react\")\n",
    "\n",
    "agent = ConversationalAgent(\n",
    "    prompt_node=conversational_agent_prompt_node, prompt_template=zero_shot_agent_template, tools=tools, memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_crawl = agent.run(\"What can you tell me about prophets hyptertuning ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(res_crawl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Prophet's hyperparameter tuning involves utilizing cross-validation functionalities to find the best working forecast model across variousFinal Answer: Prophet's hyperparameter tuning involves utilizing cross-validation functionalities to find the best working forecast model across various hyperparameters. hyperparameters.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_crawl['answers'][0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_got = agent.run(\"Who is the Son of Eddard?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Robb Stark.Final Answer: Robb Stark.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_got['answers'][0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
