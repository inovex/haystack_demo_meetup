{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LLM applications with **Haystack**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haystack Concepts we will cover:\n",
    "\n",
    "- Nodes\n",
    "- Pipelines\n",
    "- (Agents)\n",
    "- (Document-Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creating our Knowledge-Base : Indexing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cgill/miniconda/envs/meetup/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/cgill/miniconda/envs/meetup/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/cgill/miniconda/envs/meetup/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/cgill/miniconda/envs/meetup/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "haystack, version 1.24.1\n"
     ]
    }
   ],
   "source": [
    "!haystack --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgill/miniconda/envs/meetup/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/cgill/miniconda/envs/meetup/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/cgill/miniconda/envs/meetup/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/cgill/miniconda/envs/meetup/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/cgill/miniconda/envs/meetup/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Cannot validate index for custom mappings. Skipping index validation.\n",
      "Converting files: 100%|██████████| 183/183 [00:01<00:00, 166.41it/s]\n",
      "Preprocessing:   0%|          | 0/183 [00:00<?, ?docs/s]We found one or more sentences whose split count is higher than the split length.\n",
      "Preprocessing: 100%|██████████| 183/183 [00:01<00:00, 154.72docs/s]\n",
      "Batches: 100%|██████████| 50/50 [00:35<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled documentstore\n"
     ]
    }
   ],
   "source": [
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import Crawler, EmbeddingRetriever\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from helper_functions.preprocessor import CustomPreProcessor\n",
    "\n",
    "# Init documentstore with custom mapping\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"embedding\": {\"type\": \"dense_vector\", \"dims\": 384},\n",
    "            \"authors\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"keyword\"},\n",
    "            \"date\": {\n",
    "                \"type\":   \"date\",\n",
    "                \"format\": \"dd.MM.yyyy\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(index=\"blogs_clean1\", custom_mapping=mapping)\n",
    "\n",
    "# Define nodes\n",
    "crawler = Crawler(\n",
    "    urls=[\"https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/\"],   # Websites to crawl\n",
    "    filter_urls=[\"https://www.inovex.de/de/blog/\"],\n",
    "    crawler_depth=1,    # How many links to follow\n",
    "    output_dir=\"data/blogs_clean1\",  # The directory to store the crawled files, not very important, we don't use the files in this example\n",
    ")\n",
    "\n",
    "preprocessor = CustomPreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=True,\n",
    "    split_by=\"word\",\n",
    "    split_length=200,\n",
    "    split_respect_sentence_boundary=True,\n",
    "    split_overlap=50,\n",
    ")\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "        embedding_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        document_store=document_store,\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_node(component=crawler, name=\"crawler\", inputs=['File'])\n",
    "indexing_pipeline.add_node(component=preprocessor, name=\"preprocessor\", inputs=['crawler'])\n",
    "indexing_pipeline.add_node(component=retriever, name=\"EmbeddingRetriever\", inputs=[\"preprocessor\"])\n",
    "indexing_pipeline.add_node(component=document_store, name=\"document_store\", inputs=['EmbeddingRetriever'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/\n",
      "Ignore https://www.inovex.de/de/blog/author/tnguyen/\n",
      "Clean https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/\n",
      "Clean https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/\n",
      "Clean https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/\n",
      "Ignore https://www.inovex.de/de/blog/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 4/4 [00:00<00:00, 63.92docs/s]\n",
      "Batches: 100%|██████████| 4/4 [00:03<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "docs = indexing_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'documents': [   <Document: {'content': 'This article will elaborate a method for generating abstractive perspective dialogue summarization. Unlike regular dialogue summarization, perspective summarizations aim to outline the point of view of each participant within a dialogue. This work provides an approach to fit datasets intended for regular dialogue summarization to the task of perspective summarizations. It furthermore presents an architecture that can be a solid foundation for this task.\\n\\nIntroductionDefining summarizationMonologue summarizationDialogue summarizationPerspective dialogue summarizationEstablished dialogue summarization methodsData pre-processingDialogSum datasetAcquiring perspective summary annotationsCleaning and correcting the labelsAssigning the labels to the corresponding speakerArchitectureMulti-head encoderTrainingLoss functionSetupResultsDiscussion and future workChallengesFuture workConclusion\\nIntroduction\\nFor centuries humans have been living in a society where conversations are the quintessence of information exchange. In today’s age, this form of communication has been evolving for generations and has become an essential part of what defines our current society. We can therefore assume that it will keep evolving and holding its role as human society continues to grow. While dialogues between humans are a core interaction in our daily life, they not only provide information, result in new insights for all participants and outsiders, but also fulfill our social needs. Hence, conversing between people has many different traits. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 0, '_split_overlap': [{'doc_id': 'e83e81a302c38c522dd948cfb6ab1f99', 'range': (1172, 1541)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '47648771beabbceba1710614e68b700'}>,\n",
      "                     <Document: {'content': 'We can therefore assume that it will keep evolving and holding its role as human society continues to grow. While dialogues between humans are a core interaction in our daily life, they not only provide information, result in new insights for all participants and outsiders, but also fulfill our social needs. Hence, conversing between people has many different traits. These traits can define how getting information across makes the experience more enjoyable, which can hold its amount of valuable information.\\nAlthough relatively young, the research in dialogue summarization has been thriving over the past few years. Some literature has followed various approaches to building automated dialogue summarizers which returned promising results. Most of them are trained on the SAMSum corpus, a dataset containing chat messenger conversations, or corpora such as the AMI business meeting corpus, which includes spoken dialogues in a particular domain such as business meetings. However, both do not reflect the general tone of humans conversing daily. The SAMSum corpus comes closer to dialogues that would be held in our daily life, but they are still chat conversation nonetheless. Past works have generally trained on dialogues that do not reflect our everyday chitchat.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 1, '_split_overlap': [{'doc_id': '47648771beabbceba1710614e68b700', 'range': (0, 369)}, {'doc_id': '5a2ff2c22d2ebee76077bcb15770512f', 'range': (747, 1274)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'e83e81a302c38c522dd948cfb6ab1f99'}>,\n",
      "                     <Document: {'content': 'Most of them are trained on the SAMSum corpus, a dataset containing chat messenger conversations, or corpora such as the AMI business meeting corpus, which includes spoken dialogues in a particular domain such as business meetings. However, both do not reflect the general tone of humans conversing daily. The SAMSum corpus comes closer to dialogues that would be held in our daily life, but they are still chat conversation nonetheless. Past works have generally trained on dialogues that do not reflect our everyday chitchat.\\nIn summer 2021, the DialogSum corpus was released along with its challenge. The dialogues in this dataset are spoken, and about daily topics such as holiday travels, bachelor parties, and so on. At the time of this writing, this is the closest a corpus gets to spoken daily life dialogues and provides a novel challenge for the domain of dialogue summarization. This is crucial as it strongly resembles the dialogues we hold in everyday life and thus can be used more generally. That way, we have access to a large-scale dataset on which no previous work has trained a model. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 2, '_split_overlap': [{'doc_id': 'e83e81a302c38c522dd948cfb6ab1f99', 'range': (0, 527)}, {'doc_id': '45239d6f3bf2af72df989e46fd48e7e', 'range': (723, 1103)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5a2ff2c22d2ebee76077bcb15770512f'}>,\n",
      "                     <Document: {'content': 'At the time of this writing, this is the closest a corpus gets to spoken daily life dialogues and provides a novel challenge for the domain of dialogue summarization. This is crucial as it strongly resembles the dialogues we hold in everyday life and thus can be used more generally. That way, we have access to a large-scale dataset on which no previous work has trained a model. Although past architectures, trained with the SAMSum corpus, have prevailed quite well in general dialogues, there has been no research in summarizing the positions of each participant.\\nDefining summarization\\nMonologue summarization\\nSummarizing according to Merriam Webster, is the action of reducing a given text into a concise and shorter version of it, the summary. In particular, this summary must cover the main points succinctly and should be comprehensive. There is no strict rule about what the process of summarization must look like as it often depends on the original text, its length, and its messages. Therefore summarizing can be done arbitrarily as long as it meets the properties defined above. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 3, '_split_overlap': [{'doc_id': '5a2ff2c22d2ebee76077bcb15770512f', 'range': (0, 380)}, {'doc_id': '7b55c1417ee6e414502a6d338103a7b6', 'range': (750, 1091)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '45239d6f3bf2af72df989e46fd48e7e'}>,\n",
      "                     <Document: {'content': 'In particular, this summary must cover the main points succinctly and should be comprehensive. There is no strict rule about what the process of summarization must look like as it often depends on the original text, its length, and its messages. Therefore summarizing can be done arbitrarily as long as it meets the properties defined above. These properties generalize the task of summarization well enough for dialogue summarization to be not coherently different from general text summarization when it comes to the final results. Merely the process of creating such a summary is inherently more challenging. Translating this task into a problem would look like the following:\\nS = fM(D)\\nwhere S is the output summary, fM\\xa0is the function for summarizing, and D\\xa0is the input document to be summarized. While S is the target to be computed and D an input variable that cannot be controlled, fM remains to be optimized and properly engineered to generate good summaries. Constructing the function fM is the research of text summarization which has shown great results with the help of Deep Learning methods.\\nDialogue summarization\\nMany guidelines and techniques exist for summarizing text in general. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 4, '_split_overlap': [{'doc_id': '45239d6f3bf2af72df989e46fd48e7e', 'range': (0, 341)}, {'doc_id': 'd5a3bff72a67fc08af56e1976f3491cd', 'range': (803, 1199)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '7b55c1417ee6e414502a6d338103a7b6'}>,\n",
      "                     <Document: {'content': 'While S is the target to be computed and D an input variable that cannot be controlled, fM remains to be optimized and properly engineered to generate good summaries. Constructing the function fM is the research of text summarization which has shown great results with the help of Deep Learning methods.\\nDialogue summarization\\nMany guidelines and techniques exist for summarizing text in general. The conceptual process of creating dialogue summaries remains the same as its results. Therefore a formula similar to the one we defined for monologue summarization could be used. However, based on the source dialogues, this process cannot be as easily simplified as it has been barely the case for text summarization. Using therefore fM again would not make much sense here. The summarization function needs to be specialized in summarizing dialogues.\\nS = fD(D)\\nfD denotes the function for summarizing dialogues. When keeping the core differences between monologues and dialogues in focus, it becomes evident that monologue summaries align stylistically very well with their source text as both texts follow a narrative style or an observer-style of text. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 5, '_split_overlap': [{'doc_id': '7b55c1417ee6e414502a6d338103a7b6', 'range': (0, 396)}, {'doc_id': '1190d263180e4b7c3e57040394c930ca', 'range': (773, 1153)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'd5a3bff72a67fc08af56e1976f3491cd'}>,\n",
      "                     <Document: {'content': 'The summarization function needs to be specialized in summarizing dialogues.\\nS = fD(D)\\nfD denotes the function for summarizing dialogues. When keeping the core differences between monologues and dialogues in focus, it becomes evident that monologue summaries align stylistically very well with their source text as both texts follow a narrative style or an observer-style of text. This is not the case for dialogue summarizations, as conversations are transcribed with direct speeches between at least two parties, which does not align with the outcoming abstractive summarizations in terms of linguistic style. Therefore, the input D has to be processed differently from fM as the style for output S will differ a lot from D. Aside from this high-level observation, dialogues are inherently much different from normal documents or monologues as already covered. These differences make it more difficult to reuse fM but do not have a large influence on the overall concept like above mentioned textual style. Finding and optimizing a function fD has been growing as a research field over the past years.\\nPerspective dialogue summarization\\nWe consider perspective dialogue summarization to be a derivative of dialogue summarization related to it. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 6, '_split_overlap': [{'doc_id': 'd5a3bff72a67fc08af56e1976f3491cd', 'range': (0, 380)}, {'doc_id': 'c553c779dd18ee4659e3f925b10cd7e', 'range': (863, 1245)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '1190d263180e4b7c3e57040394c930ca'}>,\n",
      "                     <Document: {'content': 'These differences make it more difficult to reuse fM but do not have a large influence on the overall concept like above mentioned textual style. Finding and optimizing a function fD has been growing as a research field over the past years.\\nPerspective dialogue summarization\\nWe consider perspective dialogue summarization to be a derivative of dialogue summarization related to it. The premise is similar to dialogue summarization as it deals with the same input type. In this case, it is the output that is different. In perspective dialogue summarization, we receive more than one output, i.e., one summary for each dialogue speaker. Assume we have such function fP that accomplishes that, we can say that this problem follows this equation:\\nSP = fP(D)\\nSP = (s1, s2, …, sk)\\nWhere SP is the collection of all generated summaries. si, where i ∈ (1, …, k), denotes a separate summarized view of the i-th person in dialogue D. D is a history of utterances from k person. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 7, '_split_overlap': [{'doc_id': '1190d263180e4b7c3e57040394c930ca', 'range': (0, 382)}, {'doc_id': '836e32516993531a241842324a5fcae0', 'range': (637, 969)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'c553c779dd18ee4659e3f925b10cd7e'}>,\n",
      "                     <Document: {'content': 'Assume we have such function fP that accomplishes that, we can say that this problem follows this equation:\\nSP = fP(D)\\nSP = (s1, s2, …, sk)\\nWhere SP is the collection of all generated summaries. si, where i ∈ (1, …, k), denotes a separate summarized view of the i-th person in dialogue D. D is a history of utterances from k person. In this article, we describe our approach for finding a function fP\\nEstablished dialogue summarization methods\\nThanks to the strong foundation the literature on document summarization has delivered, researchers could leverage these results as a foundation for potential architecture summarizing dialogues. Hence, research in automated dialogue summarization has shown promising results over the past years. All the works we have analyzed in this thesis deliver single outputs and abstractive summaries. We have not found any research on automated dialogue summarizers delivering multiple outputs or abstractive summaries of each speaker’s view and position. Nonetheless, the existing work on dialogue summarization we have found still shows great potential. It thus can be further utilized as a starting point for our goal of achieving automated abstractive perspective dialogue summarization.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 8, '_split_overlap': [{'doc_id': 'c553c779dd18ee4659e3f925b10cd7e', 'range': (0, 332)}, {'doc_id': 'c041e7723f87c5b593e69eb922bef5b3', 'range': (836, 1226)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '836e32516993531a241842324a5fcae0'}>,\n",
      "                     <Document: {'content': 'We have not found any research on automated dialogue summarizers delivering multiple outputs or abstractive summaries of each speaker’s view and position. Nonetheless, the existing work on dialogue summarization we have found still shows great potential. It thus can be further utilized as a starting point for our goal of achieving automated abstractive perspective dialogue summarization.\\nWe investigated three architectures that have shown promising results for dialogue summarization and also claimed state-of-the-art performance at the time of their writing.\\nControllable Abstractive Dialogue Summarization with Sketch Supervision\\nWe refer to this literature as CODS. It generates summarization by constructing so call sketch summarizations before. The authors put lots of emphasis on controllability, as this approach allows the user to define how many sentences the model should generate for summaries. The work can be found on Github.\\nCoreference-Aware Dialogue Summarization\\nThis works leveraged the information coreferences can yield. Given the sentence\\nBill is going home. He just came from work.\\nwe immediately know that the pronoun ‚He‘ refers to the person named ‚Bill‘.  The authors describe these occurrences as co-references and they provide connection to previous sentences and subjects which can benefit the performance for the model. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 9, '_split_overlap': [{'doc_id': '836e32516993531a241842324a5fcae0', 'range': (0, 390)}, {'doc_id': '1cd114e5a9267e8f5818235b150af853', 'range': (943, 1353)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'c041e7723f87c5b593e69eb922bef5b3'}>,\n",
      "                     <Document: {'content': 'Coreference-Aware Dialogue Summarization\\nThis works leveraged the information coreferences can yield. Given the sentence\\nBill is going home. He just came from work.\\nwe immediately know that the pronoun ‚He‘ refers to the person named ‚Bill‘.  The authors describe these occurrences as co-references and they provide connection to previous sentences and subjects which can benefit the performance for the model. Their work can be found here.\\nMulti-View Sequence-to-Sequence Models with Conversational Structure\\nEach participant in a conversation may have an intent. These intents can be detected in the utterances the participant gives. Moreover, dialogues can reach different stages where the topic but also the dynamic between the utterances can change. The authors of this work analyzed dialogues and defined different views from which the stages of each dialogue can be seen. With these multiple views, the architecture is capable of extracting more relevant information from the dialogue. You can find the published work here.\\nData pre-processing\\nDialogSum dataset\\nWith the growing interest and success in the research of dialogue summarization, there were already dialogue datasets. Most existing research used the AMI meeting corpus, which is considered to be small-scale, or the SAMSum dataset, which contains written dialogues. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 10, '_split_overlap': [{'doc_id': 'c041e7723f87c5b593e69eb922bef5b3', 'range': (0, 410)}, {'doc_id': '5cd0fa57b469ccadbc9dc9c8ec40310e', 'range': (993, 1335)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '1cd114e5a9267e8f5818235b150af853'}>,\n",
      "                     <Document: {'content': 'You can find the published work here.\\nData pre-processing\\nDialogSum dataset\\nWith the growing interest and success in the research of dialogue summarization, there were already dialogue datasets. Most existing research used the AMI meeting corpus, which is considered to be small-scale, or the SAMSum dataset, which contains written dialogues. These characteristics bring relevant differences to monologues. With the motivation to provide a corpus that contains spoken dialogue with general topics for them to be closer to our daily life conversations, the authors proposed the DialogSum corpus in May 2021.\\nThe dialogues originated from Dailydialog, MuTual, and DREAM. Dailydialog contains over 13 thousand conversations. Those dialogues were extracted from websites for practicing the English language. MuTual and DREAM are 6,000 and 9,000 transcripted spoken dialogues originating from English listening exam material. The authors complemented the dataset with additional exchanges from speaking practice websites for English learners. Given the origins of these samples, the DialogSum consists mainly of conversations about topics that are present in real life, for instance, business meetings, restaurant reservations, or banking services. However, their origins stem from different sources. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 11, '_split_overlap': [{'doc_id': '1cd114e5a9267e8f5818235b150af853', 'range': (0, 342)}, {'doc_id': '1d07e67ea24c60210d09acf8a3932fa5', 'range': (921, 1295)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5cd0fa57b469ccadbc9dc9c8ec40310e'}>,\n",
      "                     <Document: {'content': 'The authors complemented the dataset with additional exchanges from speaking practice websites for English learners. Given the origins of these samples, the DialogSum consists mainly of conversations about topics that are present in real life, for instance, business meetings, restaurant reservations, or banking services. However, their origins stem from different sources. Since these conversations are intended to help English learners to practice the language, they have clear communication patterns and intents while being of reasonable length.\\nIt was necessary to clean and pre-process the data as they all have a different origin. Non-English characters were omitted, typos and grammatical errors were corrected, and, based on text similarity, duplicates were removed as well. Continuous utterances had to be merged into one longer statement for each conversation. Furthermore, definite names of the speakers were dropped and substituted with tags, i.e., #Person1# and #Person2#. Accumulating the samples and pre-processing them resulted in a corpus of 13,460 dialogues. The authors decided to split the data into a training set with 12,460, a validation set with 500, and a test set with equally many samples as the validation set.\\nAfter that, the dialogues needed to be annotated. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 12, '_split_overlap': [{'doc_id': '5cd0fa57b469ccadbc9dc9c8ec40310e', 'range': (0, 374)}, {'doc_id': 'e3b716465bc09b50fa1662550f511033', 'range': (987, 1289)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '1d07e67ea24c60210d09acf8a3932fa5'}>,\n",
      "                     <Document: {'content': 'Accumulating the samples and pre-processing them resulted in a corpus of 13,460 dialogues. The authors decided to split the data into a training set with 12,460, a validation set with 500, and a test set with equally many samples as the validation set.\\nAfter that, the dialogues needed to be annotated. To ensure the high quality of the annotations, criteria must be met for each annotated summary. It should:\\n\\nconvey the most salient information,\\nbe no longer than 20% of the original conversation length,\\npreserve important named entities within the conversation,\\nbe phrased from an observer’s perspective, and\\nbe phrased in formal language.\\n\\nAt first glance, the third object might contradict the fact that the speaker’s identities are not annotated in the dialogue. However, named entities and co-reference might occur during the speech, thus revealing the identity of a speaker. This name should be considered in the annotation and might be an essential factor in the information or semantic comprehension in the summary. If no name is mentioned in the dialogue, the previously defined tags should be used instead in the label. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 13, '_split_overlap': [{'doc_id': '1d07e67ea24c60210d09acf8a3932fa5', 'range': (0, 302)}, {'doc_id': 'cffa73298242e59ea0958df926528fbd', 'range': (770, 1132)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'e3b716465bc09b50fa1662550f511033'}>,\n",
      "                     <Document: {'content': 'However, named entities and co-reference might occur during the speech, thus revealing the identity of a speaker. This name should be considered in the annotation and might be an essential factor in the information or semantic comprehension in the summary. If no name is mentioned in the dialogue, the previously defined tags should be used instead in the label. Annotators with degrees in English Linguistics or Applied Linguistics were hired to write the summaries for the DialogSum corpus. We also refer to the annotated summaries as gold labels. On top of the criteria, those annotators were required to give heed to a set of aspects.\\nTense Consistency: The summaries should observe the conversation as if they were held in\\xa0present time and thus use proper tense for events before and after the dialogue.\\nDiscourse Relation: Summarized events can hold relevant discourse and causal relations. The summary should preserve these relations when present.\\nEmotions: Compared to monologues with a neutral position, such as newspaper and academic articles, social conversations are often set with emotions. Important emotions related to the events of the conversation should also be explicitly described in the gold label.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 14, '_split_overlap': [{'doc_id': 'e3b716465bc09b50fa1662550f511033', 'range': (0, 362)}, {'doc_id': '92c0d45ab533014a5bda6bf56917797b', 'range': (809, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'cffa73298242e59ea0958df926528fbd'}>,\n",
      "                     <Document: {'content': 'Discourse Relation: Summarized events can hold relevant discourse and causal relations. The summary should preserve these relations when present.\\nEmotions: Compared to monologues with a neutral position, such as newspaper and academic articles, social conversations are often set with emotions. Important emotions related to the events of the conversation should also be explicitly described in the gold label.\\nIntent Identification: The summary should describe the outcomes of the dialogue and the speakers‘ intents when identifiable.\\nIn addition to these quality criteria, the labels underwent extra quality control. By using cross-validation between different annotators twice, the annotations were checked until they met the requirements. In case of insufficient quality, the annotators were asked to re-annotate the respective dialogue. The authors paid extra attention to the test set and let it get annotated three times by three different annotators. Then they compared these summaries by calculating pair-wise ROUGE scores. As a result, the annotators might have used different linguistic styles but still overlapped largely in the logical order and primary content. An additional jury was hired to perform a human evaluation on the DialogSum data. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 15, '_split_overlap': [{'doc_id': 'cffa73298242e59ea0958df926528fbd', 'range': (0, 410)}, {'doc_id': 'fc71db57845c6db7f45a5d9bbb74ad7f', 'range': (842, 1257)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '92c0d45ab533014a5bda6bf56917797b'}>,\n",
      "                     <Document: {'content': 'The authors paid extra attention to the test set and let it get annotated three times by three different annotators. Then they compared these summaries by calculating pair-wise ROUGE scores. As a result, the annotators might have used different linguistic styles but still overlapped largely in the logical order and primary content. An additional jury was hired to perform a human evaluation on the DialogSum data. They were faced with 50 randomly chosen dialogues and their respective summaries from the test set and had to give a rating from one to five, with five being the highest possible score.\\nAcquiring perspective summary annotations\\nIn this section, we explain how we preprocess the data for further steps in particular how we prepare the labels so that they can be used for perspective dialogue summarization.\\nSince the dialogues and labels are all in English, English grammar can be leveraged to split the summaries. Most sentences usually have at least a subject in combination with a verb. There can be other segments as well, such as time, adverbs, locations, or sub-sentences which, again, follow the same rule. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 16, '_split_overlap': [{'doc_id': '92c0d45ab533014a5bda6bf56917797b', 'range': (0, 415)}, {'doc_id': '6034d8a85bfc40956d4fe56b6efd9a83', 'range': (822, 1128)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'fc71db57845c6db7f45a5d9bbb74ad7f'}>,\n",
      "                     <Document: {'content': 'Since the dialogues and labels are all in English, English grammar can be leveraged to split the summaries. Most sentences usually have at least a subject in combination with a verb. There can be other segments as well, such as time, adverbs, locations, or sub-sentences which, again, follow the same rule. With the help of a part of speech (POS) tagger, we were able to classify each segment of every sentence in each summary.\\nWe used the constituency parser with ELMo embeddings as it has shown good evaluation results. It was trained on the Penn Treebank corpus, which is also a guide to understanding the POS tagger’s output. The sentences were output in a tree-like structure, with the token S, denoting the part of speech ‚Sentence‘ as a root node. This structure helps us to split the sentences accordingly. We first start by extracting the sub-sentences. Often sentences can consist of multiple other nested sentences, which we refer to as sub-sentences. It is important to note that sub-sentences appear in many different forms and might be whole sentences. The constituency parser does a decent job of detecting those, yet it is not entirely accurate. Therefore extra heuristics were necessary. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 17, '_split_overlap': [{'doc_id': 'fc71db57845c6db7f45a5d9bbb74ad7f', 'range': (0, 306)}, {'doc_id': 'a4292ef8eb2d436ecd365661b4dd2fa2', 'range': (863, 1204)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '6034d8a85bfc40956d4fe56b6efd9a83'}>,\n",
      "                     <Document: {'content': 'Often sentences can consist of multiple other nested sentences, which we refer to as sub-sentences. It is important to note that sub-sentences appear in many different forms and might be whole sentences. The constituency parser does a decent job of detecting those, yet it is not entirely accurate. Therefore extra heuristics were necessary. To find the sub-sentences, we took every part labeled as Sentence (S) except for the root, i.e., the complete sentence itself.\\nAdditionally, we looked for Coordinating Conjunctions (CC) as their primary function is to connect two sentences. The POS that appears after the conjunction will be considered a sentence. This approach results in sub-sentences that seem to be evident as such. However, there are other indications of sub-sentences except for conjunctions. Due to some inconsistencies in the results of the constituency parser, it is still possible for some of the extracted sentences, to begin with ‚and‘ which is relatively uncommon in English speeches. We wanted the sentences to be independent as necessary and therefore omit ‚and‘ as a part of the sentence. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 18, '_split_overlap': [{'doc_id': '6034d8a85bfc40956d4fe56b6efd9a83', 'range': (0, 341)}, {'doc_id': 'f082b41843a8332271a2c1357d0df69a', 'range': (808, 1113)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a4292ef8eb2d436ecd365661b4dd2fa2'}>,\n",
      "                     <Document: {'content': 'Due to some inconsistencies in the results of the constituency parser, it is still possible for some of the extracted sentences, to begin with ‚and‘ which is relatively uncommon in English speeches. We wanted the sentences to be independent as necessary and therefore omit ‚and‘ as a part of the sentence. Splitting these sentences results in a more extensive set of sentences that all follow the same rules of English grammar to be a complete sentence. We use these extracted sentences for further processing.\\nGrammatically, it is possible for subordinate clauses to be standalone sentences. Therefore we extract certain subordinate clauses from each subsentence we have got at this point. The POS parser is capable of detecting subordinate clauses and tags them with ‚SBAR‘. For clauses, it is also necessary to only extract all segments that make it possible for the clauses to be able to stand as single sentences. For example, the sentence\\n(S I can’t believe (SBAR that John went without me.))\\ncontains the tags S and SBAR. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 19, '_split_overlap': [{'doc_id': 'a4292ef8eb2d436ecd365661b4dd2fa2', 'range': (0, 305)}, {'doc_id': '3baae8f3871026414ed02e921305811d', 'range': (691, 1028)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f082b41843a8332271a2c1357d0df69a'}>,\n",
      "                     <Document: {'content': 'The POS parser is capable of detecting subordinate clauses and tags them with ‚SBAR‘. For clauses, it is also necessary to only extract all segments that make it possible for the clauses to be able to stand as single sentences. For example, the sentence\\n(S I can’t believe (SBAR that John went without me.))\\ncontains the tags S and SBAR. It is evident that the whole sentence can be without a doubt classified with S. The segment covering the fact, that John went without the speaker is a subordinate clause that starts with ‚that‘. Extracting the clause as it is would result in\\nthat John went without me.\\nwhich is not a sentence that can stand alone. Removing the relative pronoun would make it a real sentence and does not affect the meaning, even if it was still connected with the original sentence:\\nJohn went without me.\\n(S I can’t believe (SBAR John went without me.))\\nIt was therefore necessary to define a set of what we call dependent prepositions. These prepositions are conjunctions such as the one in the previous example ‚that‘ which functioned as a relative pronoun. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 20, '_split_overlap': [{'doc_id': 'f082b41843a8332271a2c1357d0df69a', 'range': (0, 337)}, {'doc_id': 'f78d4d97f3d073c20e7226e6c727b099', 'range': (653, 1081)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '3baae8f3871026414ed02e921305811d'}>,\n",
      "                     <Document: {'content': 'Removing the relative pronoun would make it a real sentence and does not affect the meaning, even if it was still connected with the original sentence:\\nJohn went without me.\\n(S I can’t believe (SBAR John went without me.))\\nIt was therefore necessary to define a set of what we call dependent prepositions. These prepositions are conjunctions such as the one in the previous example ‚that‘ which functioned as a relative pronoun. The dependent prepositions cannot be removed from the clause, unlike in the previous example, as this would alter the meaning of the clause. Moreover, these prepositions often refer to another segment of the same sentence which is also reflected in their meaning. We created a set of dependent prepositions based on the explored data:\\nif, though, before, although, beside, besides, despite, during, unless, until, via, upon, unlike, like, with, within, without, because\\nWe are aware that there could be many more words that would fall in this category, however, this set should be large enough to cover most of the subordinal clauses and diving deeper into this problem is out of the scope of this thesis.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 21, '_split_overlap': [{'doc_id': '3baae8f3871026414ed02e921305811d', 'range': (0, 428)}, {'doc_id': 'cd882dcb26e74aaa4868f2fb7c469d9', 'range': (693, 1134)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f78d4d97f3d073c20e7226e6c727b099'}>,\n",
      "                     <Document: {'content': 'We created a set of dependent prepositions based on the explored data:\\nif, though, before, although, beside, besides, despite, during, unless, until, via, upon, unlike, like, with, within, without, because\\nWe are aware that there could be many more words that would fall in this category, however, this set should be large enough to cover most of the subordinal clauses and diving deeper into this problem is out of the scope of this thesis.\\nBy now, all subordinate clauses that have been detected by the constituency parser have been gathered. However, there are still other cases where one could find such a clause. In general, every sentence has at least a subject combined with a verb. Therefore, it would suffice to find segments that fulfill this criterion. Subjects are usually referred to as either nouns (NN, NP, NNP) or personal pronouns (PP). Thus, we can easily detect potential clauses by finding children in the constituency tree that are either a noun or a pronoun. Those are the starting segments of the clause. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 22, '_split_overlap': [{'doc_id': 'f78d4d97f3d073c20e7226e6c727b099', 'range': (0, 441)}, {'doc_id': '7aee4fc658e25ee5f367a2ff52f47225', 'range': (690, 1027)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'cd882dcb26e74aaa4868f2fb7c469d9'}>,\n",
      "                     <Document: {'content': 'Therefore, it would suffice to find segments that fulfill this criterion. Subjects are usually referred to as either nouns (NN, NP, NNP) or personal pronouns (PP). Thus, we can easily detect potential clauses by finding children in the constituency tree that are either a noun or a pronoun. Those are the starting segments of the clause. Consider the following extract of a tagged summary:\\n(S\\n(NP (NNP Doctor) (NNP Hawkins))\\n(VP\\n(VP\\n(VBZ advises)\\n(NP (PRP him))\\n(S\\n(VP\\n(TO to)\\n(VP (VB have) (NP (CD one)) (NP (DT every) (NN year))))))\\n(. .)\\n…\\nThe segment Doctor Hawkins is the subject labeled NP and marks the beginning of the candidate clause. After that, it is still necessary to determine how many subsequent segments need to be added to the potential clause. Whenever another conjunction like and or another clause gets classified as SBAR, one can consider that until this point, the clause in question can be used in a sentence and added to the previously extracted sentences. Analogously, when the next tagged segment right from the candidate clause is not labeled with SBAR it is not a new subordinate clause. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 23, '_split_overlap': [{'doc_id': 'cd882dcb26e74aaa4868f2fb7c469d9', 'range': (0, 337)}, {'doc_id': '2321ac0db69a5b52d8f2116f3bd9e8e1', 'range': (763, 1116)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '7aee4fc658e25ee5f367a2ff52f47225'}>,\n",
      "                     <Document: {'content': 'Whenever another conjunction like and or another clause gets classified as SBAR, one can consider that until this point, the clause in question can be used in a sentence and added to the previously extracted sentences. Analogously, when the next tagged segment right from the candidate clause is not labeled with SBAR it is not a new subordinate clause. This is also the case whenever adverbs (ADVP), adjectives (JJ, JJR, JJS), verbs (VP, VBP), and other pronouns are the next right segment as they were usually a grammatical object when the subject was found in a previous part.\\nIn the extract above, we already detected a subject, Doctor Hawkins. Thus, the clause starts with „Doctor Hawkins …“. Sentences are read from left to right in the English language, and we can therefore flatten the constituency tree as follows:\\n(NP (NNP Doctor) (NNP Hawkins)) (VP (VP (VBZ advises) (NP (PRP him)) …\\nIt is now evident that the next segment is not labeled with SBAR or S but with VP. That means the next segments are not a new clause and therefore belong to the previous segment, i.e.', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 24, '_split_overlap': [{'doc_id': '7aee4fc658e25ee5f367a2ff52f47225', 'range': (0, 353)}, {'doc_id': 'a91ede2a3b248f747e2b387f6248e89c', 'range': (698, 1077)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '2321ac0db69a5b52d8f2116f3bd9e8e1'}>,\n",
      "                     <Document: {'content': 'Sentences are read from left to right in the English language, and we can therefore flatten the constituency tree as follows:\\n(NP (NNP Doctor) (NNP Hawkins)) (VP (VP (VBZ advises) (NP (PRP him)) …\\nIt is now evident that the next segment is not labeled with SBAR or S but with VP. That means the next segments are not a new clause and therefore belong to the previous segment, i.e., it is part of the clause we have built so far for this example. Therefore we concatenate the segment to our current clause:\\nDoctor Hawkins advises him to have one every year.\\nConsider another tagged extract of a summary:\\n(NP ($ #) (NN Person1) (NNS #))\\n(VP (VBZ ’s) (ADJP (JJ angry)))\\n(SBAR\\n(IN because)\\n(S\\n(NP ($ #) (NNP Person2) (NN #))\\n…\\nIn this example, at the highest level of the parsed tree, we have got the labels NP, VP, SBAR. By following our approach, we get the subordinate clause\\n#Person1#’s angry.\\nThe subsequent segments that appear after the one labeled VP are processed independently as separate clauses because the next segment is labeled SBAR.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 25, '_split_overlap': [{'doc_id': '2321ac0db69a5b52d8f2116f3bd9e8e1', 'range': (0, 379)}, {'doc_id': 'bae5745b1573a8bc230600be11316988', 'range': (557, 1044)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a91ede2a3b248f747e2b387f6248e89c'}>,\n",
      "                     <Document: {'content': 'Consider another tagged extract of a summary:\\n(NP ($ #) (NN Person1) (NNS #))\\n(VP (VBZ ’s) (ADJP (JJ angry)))\\n(SBAR\\n(IN because)\\n(S\\n(NP ($ #) (NNP Person2) (NN #))\\n…\\nIn this example, at the highest level of the parsed tree, we have got the labels NP, VP, SBAR. By following our approach, we get the subordinate clause\\n#Person1#’s angry.\\nThe subsequent segments that appear after the one labeled VP are processed independently as separate clauses because the next segment is labeled SBAR.\\nThese clauses are standalone sentences that will be used as summaries for every person after further data cleaning, preprocessing, and assignment.\\nCleaning and correcting the labels\\nAs mentioned earlier, the constituency parser does not work completely accurately and we also consider that our approach for splitting the labels has its flaws. During the process of creating the new annotations, we found several cases where we had to simply hardcode the proper summaries. There were cases where the sentence was cut off or not properly structured. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 26, '_split_overlap': [{'doc_id': 'a91ede2a3b248f747e2b387f6248e89c', 'range': (0, 487)}, {'doc_id': '249e8f579ddcb5a61814bd8b5972df7e', 'range': (635, 1035)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'bae5745b1573a8bc230600be11316988'}>,\n",
      "                     <Document: {'content': 'Cleaning and correcting the labels\\nAs mentioned earlier, the constituency parser does not work completely accurately and we also consider that our approach for splitting the labels has its flaws. During the process of creating the new annotations, we found several cases where we had to simply hardcode the proper summaries. There were cases where the sentence was cut off or not properly structured. It was also necessary to remove the whitespaces which were inserted by the POS tagger, as suffixes such as ‚ll or ’s or special characters like hyphens (-) or dots (.) were also classified separately. For the suffixes, we simply removed the whitespace in front of them. In the case of hyphens, whitespaces before and after them had to be omitted. Dots were completely erased as they are also often part of titles such as Dr or Ms, denote the end of a sentence, or act as the decimal point in numbers like in the following example:\\nShe has a GPA 3.92.\\nFor this particular sentence, our approach even split it into two separate sentences. This was caused by the POS model constructing the constituency tree as the following one:\\n(S she has a GPA 3. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 27, '_split_overlap': [{'doc_id': 'bae5745b1573a8bc230600be11316988', 'range': (0, 400)}, {'doc_id': 'ec6b2e4ae3ca4968615319bbf8e7a070', 'range': (748, 1147)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '249e8f579ddcb5a61814bd8b5972df7e'}>,\n",
      "                     <Document: {'content': 'Dots were completely erased as they are also often part of titles such as Dr or Ms, denote the end of a sentence, or act as the decimal point in numbers like in the following example:\\nShe has a GPA 3.92.\\nFor this particular sentence, our approach even split it into two separate sentences. This was caused by the POS model constructing the constituency tree as the following one:\\n(S she has a GPA 3. (S 92.))\\nThis was one sample where we had to manually correct it to a proper summary, too. These dots can cause problems when getting treated like the regular end of sentence tokens since for those, it would make sense to keep whitespace after the dot, but not for decimal numbers. We manually inserted them at the end of each sentence again. There were also cases where single dots were classified as a sentence. We removed these entries from our annotation set thus resulting in a set of summaries that were split into single, shorter sentences.\\nAssigning the labels to the corresponding speaker\\nWith the subordinate clauses extracted as independent sentences, the next step was to assign them to \\\\textit{Person1} and \\\\textit{Person2} accordingly.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 28, '_split_overlap': [{'doc_id': '249e8f579ddcb5a61814bd8b5972df7e', 'range': (0, 399)}, {'doc_id': 'ee4dff1c438cc1be73d6693e93108f14', 'range': (743, 1149)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ec6b2e4ae3ca4968615319bbf8e7a070'}>,\n",
      "                     <Document: {'content': 'There were also cases where single dots were classified as a sentence. We removed these entries from our annotation set thus resulting in a set of summaries that were split into single, shorter sentences.\\nAssigning the labels to the corresponding speaker\\nWith the subordinate clauses extracted as independent sentences, the next step was to assign them to \\\\textit{Person1} and \\\\textit{Person2} accordingly.\\nAs mentioned in the section for acquiring the labels, our sentences always contain a subject. These subjects can be either\\n\\n„#Person1#“ or „#Person2#“,\\na name,\\nor a personal pronoun\\n\\nIn the former two cases, it is trivial how to assign the sentence properly. Personal pronouns are used as a coreference and there imply a reference to the previous sentence. Since the sentences are in chronological order, i.e., the order when they appear has not been altered in the previous process, we assign sentences with a pronoun to the person the previous sentence has been assigned to. Assigning sentences where the grammatical subject is a name is more complicated than in the earlier two cases.\\nBefore assigning all extracted clauses to the speakers, we used a Named Entitiy Recognition (NER) model based on ELMo embeddings. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 29, '_split_overlap': [{'doc_id': 'ec6b2e4ae3ca4968615319bbf8e7a070', 'range': (0, 406)}, {'doc_id': 'f908d9a44327ea35d3ac7e9c39d42e78', 'range': (816, 1224)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ee4dff1c438cc1be73d6693e93108f14'}>,\n",
      "                     <Document: {'content': ', the order when they appear has not been altered in the previous process, we assign sentences with a pronoun to the person the previous sentence has been assigned to. Assigning sentences where the grammatical subject is a name is more complicated than in the earlier two cases.\\nBefore assigning all extracted clauses to the speakers, we used a Named Entitiy Recognition (NER) model based on ELMo embeddings. We discovered that in our samples the token Person caused the model to output ambiguous, inconsistent classifications. Additionally, there are issues with occurrences of # as well. Therefore, before performing named entity recognition, it was necessary to substitute all occurrences of #Person1# and #Person2# to XYZ1 and XYZ2 respectively as this will guarantee that the NER model will not recognize these entities as Persons or Organization, i.e.,\\xa0label them with O. Afterwards, we executed NER on all sentences and converted all names that were found to only lower case characters and kept them in a set. Then we added xyz1 and xzy2 to the set as well. This set of all occurring names will be crucial for assigning the labels. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 30, '_split_overlap': [{'doc_id': 'ee4dff1c438cc1be73d6693e93108f14', 'range': (0, 408)}, {'doc_id': '4cd1c49cdbec6abe00937e5bee9e9fdc', 'range': (857, 1138)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f908d9a44327ea35d3ac7e9c39d42e78'}>,\n",
      "                     <Document: {'content': ',\\xa0label them with O. Afterwards, we executed NER on all sentences and converted all names that were found to only lower case characters and kept them in a set. Then we added xyz1 and xzy2 to the set as well. This set of all occurring names will be crucial for assigning the labels. Since all occurrences of #Person1# and #Person2# have been changed, we need to assign sentences with XYZ1 and XYZ2 to the speakers accordingly. It is quite common that names are mentioned in spoken conversations. We generalize the intention of this into three cases:\\n\\nIntroducing oneself\\nDirectly speaking to a person, for example:\\xa0Hey Daniel! Can you help me?\\nTalking about another party that is not part of the dialogue, for instance: Have you seen Sara’s dog?\\n\\nIf a speaker introduces themselves, the most used clauses are\\n„I am“, „I’m“, „name is“, „name’s“\\nFinding the name in the summary sentence in combination with one of these clauses automatically assigns the summary sentence to the speaker who said the clause. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 31, '_split_overlap': [{'doc_id': 'f908d9a44327ea35d3ac7e9c39d42e78', 'range': (0, 281)}, {'doc_id': 'ecd2182172d1bcde4cb0a61a870ea9e1', 'range': (643, 1003)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '4cd1c49cdbec6abe00937e5bee9e9fdc'}>,\n",
      "                     <Document: {'content': 'Talking about another party that is not part of the dialogue, for instance: Have you seen Sara’s dog?\\n\\nIf a speaker introduces themselves, the most used clauses are\\n„I am“, „I’m“, „name is“, „name’s“\\nFinding the name in the summary sentence in combination with one of these clauses automatically assigns the summary sentence to the speaker who said the clause. If, however, the name is mentioned in an utterance without an introductory clause, then that means that the speaker does not introduce themselves and the sentence gets therefore assigned to the other person. This is a rather generalized approach to solving this problem as there are some exceptional cases. For example,\\nHave you seen Sara’s dog?\\nclearly does not imply any form of introduction or directly speaking to the other person. In these cases, the speaker is talking about another party that is not present in this conversation. Another challenge is that it is difficult to catch all forms of introductions. In our method, both\\nHer name is Jessica.\\nand\\nThe name’s John.\\nimply that the speakers are introducing themselves although in the first example the speaker clearly introduces a third party. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 32, '_split_overlap': [{'doc_id': '4cd1c49cdbec6abe00937e5bee9e9fdc', 'range': (0, 360)}, {'doc_id': '44069b058cd54c5d77acab0b0898a2f8', 'range': (797, 1165)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ecd2182172d1bcde4cb0a61a870ea9e1'}>,\n",
      "                     <Document: {'content': 'In these cases, the speaker is talking about another party that is not present in this conversation. Another challenge is that it is difficult to catch all forms of introductions. In our method, both\\nHer name is Jessica.\\nand\\nThe name’s John.\\nimply that the speakers are introducing themselves although in the first example the speaker clearly introduces a third party. Introductions are often not clear in dialogues as it can be seen in the following example:\\n#Person1#: Who am I talking with?\\n#Person2#: This is Jane speaking.\\nCovering all forms of self-introduction is a major challenge and is out of scope for this article.\\nWe mentioned earlier that sentences with a pronoun will be assigned to the person that the previous sentence got assigned. The main exception here are the pronouns they and their. Sentences with subjects that were referred to with these pronouns were assigned to both parties. All sentences that could not be assigned by our methods were assigned to both speakers. After all labels were assigned, we changed the tokens XYZ1 and XYZ2 back to #Person1# and #Person2#.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 33, '_split_overlap': [{'doc_id': 'ecd2182172d1bcde4cb0a61a870ea9e1', 'range': (0, 368)}, {'doc_id': 'ddff458e141a9307e8305d5c44112507', 'range': (750, 1092)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '44069b058cd54c5d77acab0b0898a2f8'}>,\n",
      "                     <Document: {'content': 'The main exception here are the pronouns they and their. Sentences with subjects that were referred to with these pronouns were assigned to both parties. All sentences that could not be assigned by our methods were assigned to both speakers. After all labels were assigned, we changed the tokens XYZ1 and XYZ2 back to #Person1# and #Person2#.\\nThe previous sections covered the creation of our new DialogSum dataset which now contains summaries for each person in each dialogue. We simply add these new labels to the corresponding dialogue from which the sentences of the annotation originated. The following example gives an idea of what the labels look like:\\nsummaries: {\\n„Person1“: „#Person1# thinks the rent is expensive. #Person1 disagrees.“,\\n„Person2“: „#Person2# lists the advantages of the house Person1 wants to rent. #Person2# suggests sharing it to decrease the total amount of the rent. #Person2# tells #Person1# it helps to save money on fares, and #Person1#’ll think about it.\\n}Architecture\\nMulti-headed neural networks have an adequate backbone network that has learned the salient features of the input data. As the name suggests, multiple different output heads are attached at the end of this backbone. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 34, '_split_overlap': [{'doc_id': '44069b058cd54c5d77acab0b0898a2f8', 'range': (0, 342)}, {'doc_id': '5877061fd8805811b779ec0db94edb2a', 'range': (898, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ddff458e141a9307e8305d5c44112507'}>,\n",
      "                     <Document: {'content': '#Person2# tells #Person1# it helps to save money on fares, and #Person1#’ll think about it.\\n}Architecture\\nMulti-headed neural networks have an adequate backbone network that has learned the salient features of the input data. As the name suggests, multiple different output heads are attached at the end of this backbone. The salient information the backbone has been trained on is forwarded to each head while each head is trained on its task. The following figure shows an example from a multi-headed neural network with two heads.\\n\\nAdditionally, each head has its different task, either regression or classification. Thus, the neural network returns two different outputs.\\nWe leveraged the fact that a multi-headed neural network returns two different results as this is congruent with our goal to generate two distinct summaries for a single input dialogue. Therefore, we will plug in two heads to a dialogue summarization model. However, unlike the example from the previously shown image we are not training two completely different tasks since both outputs are of the same type of task, i.e., both outputs are abstractive summaries. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 35, '_split_overlap': [{'doc_id': 'ddff458e141a9307e8305d5c44112507', 'range': (0, 321)}, {'doc_id': '11c0ad1665504525586f461753181d20', 'range': (676, 1139)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5877061fd8805811b779ec0db94edb2a'}>,\n",
      "                     <Document: {'content': 'We leveraged the fact that a multi-headed neural network returns two different results as this is congruent with our goal to generate two distinct summaries for a single input dialogue. Therefore, we will plug in two heads to a dialogue summarization model. However, unlike the example from the previously shown image we are not training two completely different tasks since both outputs are of the same type of task, i.e., both outputs are abstractive summaries. We aimed for heads specifically trained on one single speaker and therefore only generated a summary for a single speaker. We modified the encoder of our baseline architecture by adding two additional heads. These two heads then lead back to one common decoder that generates the summaries for each speaker. From the point where the encoder splits into two heads, we passed each encoding separately to the decoder and used our annotations for each person for calculating the loss respectively.\\nMulti-head encoder\\nAs mentioned above, we only modified the encoder in order to use further encode the learned features within the context of the annotated summary of a single person. The following figure displays the architecture we have described.\\n\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 36, '_split_overlap': [{'doc_id': '5877061fd8805811b779ec0db94edb2a', 'range': (0, 463)}, {'doc_id': '6fe00a005a1f2d4c6d4c44e709c1beb6', 'range': (772, 1208)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '11c0ad1665504525586f461753181d20'}>,\n",
      "                     <Document: {'content': 'From the point where the encoder splits into two heads, we passed each encoding separately to the decoder and used our annotations for each person for calculating the loss respectively.\\nMulti-head encoder\\nAs mentioned above, we only modified the encoder in order to use further encode the learned features within the context of the annotated summary of a single person. The following figure displays the architecture we have described.\\n\\nEach copy is a hard copy of the very last encoder layer and, therefore, initialized with identical weights. We used the BART encoder that was trained in the works of CODS\\xa0 as the backbone for our encoder. Since both additional encoder heads are copied from the last layer of the backbone, they also share the same internal architecture as BART Layers, as shown here\\n\\nFurthermore, the encoding process can be then formulated as\\nH = EBART({x0, x1, …, xn})\\nHk = Ek(H),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\nwhere EBART describes the BART encoding of n tokens xi and Ek denotes the additional encoding process for the k-th head respectively as shown in the figure above. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 37, '_split_overlap': [{'doc_id': '11c0ad1665504525586f461753181d20', 'range': (0, 436)}, {'doc_id': '297c528e05971947b33a12b8c58f4848', 'range': (642, 1080)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '6fe00a005a1f2d4c6d4c44e709c1beb6'}>,\n",
      "                     <Document: {'content': 'Since both additional encoder heads are copied from the last layer of the backbone, they also share the same internal architecture as BART Layers, as shown here\\n\\nFurthermore, the encoding process can be then formulated as\\nH = EBART({x0, x1, …, xn})\\nHk = Ek(H),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\nwhere EBART describes the BART encoding of n tokens xi and Ek denotes the additional encoding process for the k-th head respectively as shown in the figure above. We only applied the idea of multi-headed neural networks in the encoder as we aimed to increase parameters as little as possible. We also do not want the model to learn anything different for the summary generation part as the style of outputs for regular dialogue summarization, and each summary of a single person should be similar. Thus, we left the decoder part as it is. Again, we used a BART decoder for fine-tuning from the works CODS which has been trained on the SAMSum datasets. The following equation completes the encoder-decoder process of our approach:\\nYk = DBART(Hk)\\nYk = (y0,k, …, ym,k),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\n\\nYkis the sequence of tokens yi,k for person k acquired from the decoder DBART. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 38, '_split_overlap': [{'doc_id': '6fe00a005a1f2d4c6d4c44e709c1beb6', 'range': (0, 438)}, {'doc_id': 'b705f8e514a3f127328414daea753d44', 'range': (815, 1137)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '297c528e05971947b33a12b8c58f4848'}>,\n",
      "                     <Document: {'content': 'Again, we used a BART decoder for fine-tuning from the works CODS which has been trained on the SAMSum datasets. The following equation completes the encoder-decoder process of our approach:\\nYk = DBART(Hk)\\nYk = (y0,k, …, ym,k),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\n\\nYkis the sequence of tokens yi,k for person k acquired from the decoder DBART. The decoder processed the encodings Hk from each of the k heads separately. In our environment, H1 and H2 as well as Y1 and Y2 were not computed concurrently but sequentially.\\nTraining\\nLoss function\\nSince we have two different outputs for the DialogSum dataset, conventional training and computation of the loss are not possible. The significant difference is that we receive two results from the neural network and have two labels for computing the loss. It is important to incorporate both outputs in the training process and to ensure that the outputs and the weights of both new encoder heads, given that the weight initialization is equal for all components, also differ from each other.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 39, '_split_overlap': [{'doc_id': '297c528e05971947b33a12b8c58f4848', 'range': (0, 322)}, {'doc_id': '433d4507782aed5e9e4a49c16e07df4c', 'range': (653, 1015)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'b705f8e514a3f127328414daea753d44'}>,\n",
      "                     <Document: {'content': 'The significant difference is that we receive two results from the neural network and have two labels for computing the loss. It is important to incorporate both outputs in the training process and to ensure that the outputs and the weights of both new encoder heads, given that the weight initialization is equal for all components, also differ from each other.\\nDuring training, we calculated the loss for each single encoder output and then used the maximum of both to punish the model for the worse performing head and thus making the learning process more challenging. We chose the Cross-Entropy loss function and obtained the following equations for the loss:\\nCE(Y, Ȳ) = –∑yi ·log ȳi\\nLk = CE(Yk, Ȳk}),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\nLE = max(L1, L2)\\nwhere CE(Y, Ȳ) is the Cross-Entropy loss function, Lk denotes the loss that the k-th encoder head causes. Note that Lk includes the output from the decoder instead of only the encoder head. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 40, '_split_overlap': [{'doc_id': 'b705f8e514a3f127328414daea753d44', 'range': (0, 362)}, {'doc_id': '193b00b5b855711ca96fde93155c27b1', 'range': (573, 928)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '433d4507782aed5e9e4a49c16e07df4c'}>,\n",
      "                     <Document: {'content': 'We chose the Cross-Entropy loss function and obtained the following equations for the loss:\\nCE(Y, Ȳ) = –∑yi ·log ȳi\\nLk = CE(Yk, Ȳk}),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\nLE = max(L1, L2)\\nwhere CE(Y, Ȳ) is the Cross-Entropy loss function, Lk denotes the loss that the k-th encoder head causes. Note that Lk includes the output from the decoder instead of only the encoder head. We then acquire the loss LE as described above with the label Ȳk for person k. We compared the similarity between the encoded outputs and multiplied them with a penalizing parameter γ, which acts as a weight for considering the similarity in the loss function. We sum the product with LE to penalize the learning process accordingly if the outputs are too similar.\\nS = mean(SIM(H1, H2))\\nL = LE + γS\\nSIM is the similarity function from which we additionally calculate the mean for the score S to be a scalar still representative of similarity. For SIM we chose cosine similarity. This computes the total loss L from which it is now possible to acquire the training gradients.\\nSetup\\nFor training, we used the weights from the pre-trained CODS architecture. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 41, '_split_overlap': [{'doc_id': '433d4507782aed5e9e4a49c16e07df4c', 'range': (0, 355)}, {'doc_id': '9b39b2ed5b0e78c4325029bec100c863', 'range': (721, 1110)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '193b00b5b855711ca96fde93155c27b1'}>,\n",
      "                     <Document: {'content': 'S = mean(SIM(H1, H2))\\nL = LE + γS\\nSIM is the similarity function from which we additionally calculate the mean for the score S to be a scalar still representative of similarity. For SIM we chose cosine similarity. This computes the total loss L from which it is now possible to acquire the training gradients.\\nSetup\\nFor training, we used the weights from the pre-trained CODS architecture. We left most of the parameters to the default, which its authors have set; for instance, we used learning rate 5e-5. We trained the model with AdamW and set our penalizing parameter γ to 0.8. Early stopping was implemented, yet, we set the patience parameter to a higher number since the task itself is somewhat more abstract. We wanted to observe the learning behavior, particularly the behavior of the validation metrics, in a longer training process. Therefore, we set patience to 100 and trained the model for 107 epochs in total where we also saved the checkpoints. For validation, we used the ROUGE-1 F1-score to measure the model’s performance on the validation set over time. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 42, '_split_overlap': [{'doc_id': '193b00b5b855711ca96fde93155c27b1', 'range': (0, 389)}, {'doc_id': '159809a76ce0e031a900a54e99edddf5', 'range': (717, 1073)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '9b39b2ed5b0e78c4325029bec100c863'}>,\n",
      "                     <Document: {'content': 'We wanted to observe the learning behavior, particularly the behavior of the validation metrics, in a longer training process. Therefore, we set patience to 100 and trained the model for 107 epochs in total where we also saved the checkpoints. For validation, we used the ROUGE-1 F1-score to measure the model’s performance on the validation set over time. We utilized the similarity score as an additional parameter since, especially at the beginning, the pre-trained model tends to generate general dialogue summarizations for each person, resulting in two identical outputs for each person.\\nResults\\nWe trained the architecture as described in the section above on our version of the DialogSum dataset. We kept track of the loss, validation metrics, and similarity scores during training. The model consistently minimized loss on both training and validation sets, resulting in converging loss curves that were approximating 0. However, the validation and similarity curves fluctuated as shown in the figure below.\\n\\nIt shows that the F1-score is not only fluctuating but also monotonically decreasing. This made it difficult to use conventional early stopping, which is why we looked for the optimal checkpoint in terms of F1 score and similarity. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 43, '_split_overlap': [{'doc_id': '9b39b2ed5b0e78c4325029bec100c863', 'range': (0, 356)}, {'doc_id': '3749912a8c41aabd4ccde4d10bc47cf0', 'range': (930, 1249)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '159809a76ce0e031a900a54e99edddf5'}>,\n",
      "                     <Document: {'content': 'However, the validation and similarity curves fluctuated as shown in the figure below.\\n\\nIt shows that the F1-score is not only fluctuating but also monotonically decreasing. This made it difficult to use conventional early stopping, which is why we looked for the optimal checkpoint in terms of F1 score and similarity. The similarity curve shows a behavior similar to the curve of the F1 score. In the early epochs, the validation metrics were relatively high, reaching an F1 score up to approximately 0.34. In contrast, the similarity was also very high, indicating that at this point, the summaries for Person1 and Person2 would be identical. After that, the similarity score and F1 score were constantly going down. Between epochs 40 and 60, the similarity of the outputs decreases even faster, and the F1-score is slightly increasing. We then chose the checkpoint that reached the highest F1 score and the checkpoint with the lowest similarity score, epoch 50. These three checkpoints were then tested on the test set of DialogSum. The following paragraphs show the generated summaries samples from each checkpoint.\\nHighest F1-Score (2 Epochs):\\n\\nPerson1: #Person2# cannot stand the noise in her room. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 44, '_split_overlap': [{'doc_id': '159809a76ce0e031a900a54e99edddf5', 'range': (0, 319)}, {'doc_id': 'c7c0a9279e0e4a5b57a4d4e053230125', 'range': (840, 1205)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '3749912a8c41aabd4ccde4d10bc47cf0'}>,\n",
      "                     <Document: {'content': 'We then chose the checkpoint that reached the highest F1 score and the checkpoint with the lowest similarity score, epoch 50. These three checkpoints were then tested on the test set of DialogSum. The following paragraphs show the generated summaries samples from each checkpoint.\\nHighest F1-Score (2 Epochs):\\n\\nPerson1: #Person2# cannot stand the noise in her room. She was woken up several times by the noise the baggage elevator made. They do not have any spare rooms today, but there will be some tomorrow.\\nPerson2: #Person2# cannot stand the noise in her room. She was woken up several times by the noise the baggage elevator made. They do not have any spare rooms today, but there will be some tomorrow.\\n50 Epochs:\\nPerson1: #Person1# will change #Person2#’s room for her as it is too noisy. #Person2# will wait till tomorrow as a tour company will be leaving tomorrow morning.\\nPerson2: #Person2# cannot stand anymore the room for her because it is too noisy. #Person1# cannot change the room for her because a tour company will be leaving tomorrow morning. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 45, '_split_overlap': [{'doc_id': '3749912a8c41aabd4ccde4d10bc47cf0', 'range': (0, 365)}, {'doc_id': '2028e61e71455efdcd06e6480aa2ec2c', 'range': (709, 1061)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'c7c0a9279e0e4a5b57a4d4e053230125'}>,\n",
      "                     <Document: {'content': '50 Epochs:\\nPerson1: #Person1# will change #Person2#’s room for her as it is too noisy. #Person2# will wait till tomorrow as a tour company will be leaving tomorrow morning.\\nPerson2: #Person2# cannot stand anymore the room for her because it is too noisy. #Person1# cannot change the room for her because a tour company will be leaving tomorrow morning. #Person2# will wait till tomorrow\\nLowest similarity score (106 Epochs):\\nPerson1: 0 what can i do for you 1 none 2 none 3 none 4 none 5 none 6 none 7 none 8 none 9 none 10 none\\nPerson2: 0 none 1 none 2 none 3 none 4 none 5 none 6 none 7 none 8 none 9 none 10 none\\nThe checkpoint reaching the highest F1 score has been trained for two epochs. Although it got a decent F1 score for ROUGE-1 it produced summaries for both persons, which were identical. This is also reflected in its similarity score. Its similarity score is close to 1, and in the produced summaries one can see that the generated summaries might be good candidates for a regular dialogue summarization but are not distinguishable from each other. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 46, '_split_overlap': [{'doc_id': 'c7c0a9279e0e4a5b57a4d4e053230125', 'range': (0, 352)}, {'doc_id': 'e88317148a43b47e8fd51bd455dec8a3', 'range': (694, 1063)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '2028e61e71455efdcd06e6480aa2ec2c'}>,\n",
      "                     <Document: {'content': 'Although it got a decent F1 score for ROUGE-1 it produced summaries for both persons, which were identical. This is also reflected in its similarity score. Its similarity score is close to 1, and in the produced summaries one can see that the generated summaries might be good candidates for a regular dialogue summarization but are not distinguishable from each other. The former aspect can be explained with the CODS backbone, which was trained for dialogue summarization.\\nThe model trained for 50 epochs seems to be the most promising model for perspective dialogue summarization. Although not accurate, the summaries from Person1 and Person2 are different from each other, and they do seem like a usable summary.\\xa0 The summary sentence for Person1\\n#Person1# will change #Person2#’s room for her as it is too noisy.\\nand the summary sentence for Person2\\n#Person2# cannot stand any more the room for her because it is too noisy.\\nboth represent the perspective or situation of each person, respectively. The next sentence for person1\\n#Person2# will wait till tomorrow as a tour company will be leaving tomorrow morning.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 47, '_split_overlap': [{'doc_id': '2028e61e71455efdcd06e6480aa2ec2c', 'range': (0, 369)}, {'doc_id': '21829ed5e151fe6041962976fc795389', 'range': (718, 1118)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'e88317148a43b47e8fd51bd455dec8a3'}>,\n",
      "                     <Document: {'content': 'The summary sentence for Person1\\n#Person1# will change #Person2#’s room for her as it is too noisy.\\nand the summary sentence for Person2\\n#Person2# cannot stand any more the room for her because it is too noisy.\\nboth represent the perspective or situation of each person, respectively. The next sentence for person1\\n#Person2# will wait till tomorrow as a tour company will be leaving tomorrow morning.\\nand the one for Person2\\n#Person1# can’t change the room for her because a tour company will be leaving tomorrow morning\\ntake the position of the other speaker again. However, the last summary sentence of Person2 reflects that person’s position again. On a semantic level, the summaries for both persons do contain the dialogue’s content. There are some minor flaws in the generated output, such as „cannot stand any more the room for her“ which is not grammatically correct. The clause „cannot stand any more“ was existent in the dialogue, and having it next to „the room“ did preserve the original meaning. Note that this example happens to be a more ideal case where our model’s performance was not too bad. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 48, '_split_overlap': [{'doc_id': 'e88317148a43b47e8fd51bd455dec8a3', 'range': (0, 400)}, {'doc_id': '3c6dcfb5e812f06f6a1a5fac86283db3', 'range': (739, 1110)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '21829ed5e151fe6041962976fc795389'}>,\n",
      "                     <Document: {'content': 'There are some minor flaws in the generated output, such as „cannot stand any more the room for her“ which is not grammatically correct. The clause „cannot stand any more“ was existent in the dialogue, and having it next to „the room“ did preserve the original meaning. Note that this example happens to be a more ideal case where our model’s performance was not too bad. Given that the similarity score is still high (higher than 0.8), the generated summaries for each person in many other dialogue samples still tend to be identical or nearly identical. In most outputs, the perspective of the other speaker is also summarized.\\nThe model with the lowest similarity score clearly generated the worst outputs. Since the backbone is based on CODS, the model overfit after training for 106 epochs and produced only the keyphrases and summary sketches, which are used in the underlying architecture.\\nThe model that trained for 50 epochs came the closest to perspective summarization in our experiments. It reached an F1-Score of 0.2294 and a similarity score of 0.89 on the test set of our version of the DialogSum dataset. Nonetheless, during training, the loss converged towards 0. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 49, '_split_overlap': [{'doc_id': '21829ed5e151fe6041962976fc795389', 'range': (0, 371)}, {'doc_id': 'ca9e5e408f5b2d528e13e90b48a85665', 'range': (710, 1180)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '3c6dcfb5e812f06f6a1a5fac86283db3'}>,\n",
      "                     <Document: {'content': 'Since the backbone is based on CODS, the model overfit after training for 106 epochs and produced only the keyphrases and summary sketches, which are used in the underlying architecture.\\nThe model that trained for 50 epochs came the closest to perspective summarization in our experiments. It reached an F1-Score of 0.2294 and a similarity score of 0.89 on the test set of our version of the DialogSum dataset. Nonetheless, during training, the loss converged towards 0. We assume that the architecture tried to learn embeddings that lie between the targets for Person1 and Person2, thus reducing the loss but increasing the F1 score. Individual results of this model, such as the one above, show that using a multi-head encoder attached to a single decoder might be a good foundation for perspective dialogue summarization. In our experiments, the results were not convincing enough to use our architecture for an accurate automated system for summarizing each speaker’s perspective. It instead provides a direction in which future work could achieve this. Many factors might have influenced the outcome of our work and approach. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 50, '_split_overlap': [{'doc_id': '3c6dcfb5e812f06f6a1a5fac86283db3', 'range': (0, 470)}, {'doc_id': 'd27208d7013c86528719d3809f0a1c0f', 'range': (635, 1130)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ca9e5e408f5b2d528e13e90b48a85665'}>,\n",
      "                     <Document: {'content': 'Individual results of this model, such as the one above, show that using a multi-head encoder attached to a single decoder might be a good foundation for perspective dialogue summarization. In our experiments, the results were not convincing enough to use our architecture for an accurate automated system for summarizing each speaker’s perspective. It instead provides a direction in which future work could achieve this. Many factors might have influenced the outcome of our work and approach. Solving them could provide great potential for our architecture to eventually generate precise and accurate summarizations for each person in a conversation that are distinctive from each other.\\nDiscussion and future work\\nChallenges\\nNo research exists for perspective dialogue summarization. This made it difficult to develop a viable architecture and required us to outline an approach from scratch. We stated that perspective dialogue summarization and regular dialogue summarization are related to each other. However, the equations we have defined are different from each other. Note that these equations are each very abstract definitions of each task. Due to the difference between these two equations, it is necessary to find a function fP, which is inherently different from function fD. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 51, '_split_overlap': [{'doc_id': 'ca9e5e408f5b2d528e13e90b48a85665', 'range': (0, 495)}, {'doc_id': '6f821c01f664cb3c8b6050ac45e7c522', 'range': (897, 1291)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'd27208d7013c86528719d3809f0a1c0f'}>,\n",
      "                     <Document: {'content': 'We stated that perspective dialogue summarization and regular dialogue summarization are related to each other. However, the equations we have defined are different from each other. Note that these equations are each very abstract definitions of each task. Due to the difference between these two equations, it is necessary to find a function fP, which is inherently different from function fD. This conceptual difference implies that the neural architecture for perspective dialogue summarization must differ from the one for regular dialogue summarization. Therefore, we had to accumulate the characteristics of such an architecture, for example, having multiple outputs, processing an input dialogue for summarization, or being a generative text model. We combined different concepts for each characteristic into one sequence-to-sequence architecture that generates distinct summaries for each person. Since this work is one of the first in perspective dialogue summarization, the combination of multi-headed neural networks in sequence-to-sequence architectures containing an encoder-decoder structure is a novelty we have not discovered in our literature research. Therefore, we could not define clear expectations regarding the performance of our model. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 52, '_split_overlap': [{'doc_id': 'd27208d7013c86528719d3809f0a1c0f', 'range': (0, 394)}, {'doc_id': '2763aab65aa71fad04ed48268a823b56', 'range': (756, 1259)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '6f821c01f664cb3c8b6050ac45e7c522'}>,\n",
      "                     <Document: {'content': 'We combined different concepts for each characteristic into one sequence-to-sequence architecture that generates distinct summaries for each person. Since this work is one of the first in perspective dialogue summarization, the combination of multi-headed neural networks in sequence-to-sequence architectures containing an encoder-decoder structure is a novelty we have not discovered in our literature research. Therefore, we could not define clear expectations regarding the performance of our model. We showed that overall the performance of our trained model is meager and between its ROUGE-1 F1 scores and the ones from previous work is a clear gap. Nonetheless, some predicted samples have shown potential, promising better results if further improvements are made.\\nMany possible factors might influence the performance of our approach. We assume that a multi-headed encoder is a decent starting point to building better architectures for generating summaries for each person. One reason why the performance of our model was not high could be that the architecture has not been able to distinguish between Person1 and Person2. Although both heads share the same common input dialogue, extracting the features for distinguishing between each speaker is still necessary. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 53, '_split_overlap': [{'doc_id': '6f821c01f664cb3c8b6050ac45e7c522', 'range': (0, 503)}, {'doc_id': '144dc2c34fc29617069bfd14a03d13e4', 'range': (844, 1275)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '2763aab65aa71fad04ed48268a823b56'}>,\n",
      "                     <Document: {'content': 'We assume that a multi-headed encoder is a decent starting point to building better architectures for generating summaries for each person. One reason why the performance of our model was not high could be that the architecture has not been able to distinguish between Person1 and Person2. Although both heads share the same common input dialogue, extracting the features for distinguishing between each speaker is still necessary. If this is not the case, the model might still try to summarize for all participants. The predictions from our best model have shown that some sentences which should be designated for the other speaker i are nevertheless part of the summary for speaker j, where i≠j.\\nOne possible solution would build the architecture around additionally differentiating between the persons. This could be done in various ways, such as splitting the dialogue into k sets for k speakers where each set Ui contains the utterances for speaker i and then passing these sets to the architecture. That would require the architecture to accept multiple inputs and to recover the dynamic conversational information flow, i.e.', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 54, '_split_overlap': [{'doc_id': '2763aab65aa71fad04ed48268a823b56', 'range': (0, 431)}, {'doc_id': '77a8910332748715039db36bf71c799f', 'range': (807, 1131)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '144dc2c34fc29617069bfd14a03d13e4'}>,\n",
      "                     <Document: {'content': 'This could be done in various ways, such as splitting the dialogue into k sets for k speakers where each set Ui contains the utterances for speaker i and then passing these sets to the architecture. That would require the architecture to accept multiple inputs and to recover the dynamic conversational information flow, i.e., utterance ui,t of person i at position index t relies on the information of a previous utterance uj,v of person j at position index v, where i≠j and t > v. Another idea is to add more encoding layers for each head to increase the complexity and therefore learn the necessary features to focus on the salient information important for one speaker. Inserting more encoding layers is not the only way to increase the model complexity. However, it is always important to keep in mind higher complexity comes with more parameters and a higher risk of overfitting. Another major problem in our model is the high similarity between the generated outputs. By incorporating the similarity score of the hidden states in training in a more sophisticated way, the model might produce more distinct summaries for each dialogue.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 55, '_split_overlap': [{'doc_id': '144dc2c34fc29617069bfd14a03d13e4', 'range': (0, 324)}, {'doc_id': '741779a9c2ac55a3ba280215ddfef3d2', 'range': (759, 1141)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '77a8910332748715039db36bf71c799f'}>,\n",
      "                     <Document: {'content': 'However, it is always important to keep in mind higher complexity comes with more parameters and a higher risk of overfitting. Another major problem in our model is the high similarity between the generated outputs. By incorporating the similarity score of the hidden states in training in a more sophisticated way, the model might produce more distinct summaries for each dialogue.\\nThe high similarity could also be related to the training data our model trained on. It is essential to mention that the lack of research in perspective dialogue summarization also comes with a limited selection of datasets. There were no corpora that contained the necessary annotations at all for this specific task. We had to create our solution for automatically creating perspective summary annotations, which required us to dive deeper into the linguistic level. This area of our work likely left some improvements to be desired. Sentences can follow a nested and very complex structure, making it quite challenging to come up with all necessary heuristics that can precisely split all annotations and assign them correctly to each person. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 56, '_split_overlap': [{'doc_id': '77a8910332748715039db36bf71c799f', 'range': (0, 382)}, {'doc_id': '85f916012daee6c4328c4317e79a941', 'range': (702, 1128)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '741779a9c2ac55a3ba280215ddfef3d2'}>,\n",
      "                     <Document: {'content': 'We had to create our solution for automatically creating perspective summary annotations, which required us to dive deeper into the linguistic level. This area of our work likely left some improvements to be desired. Sentences can follow a nested and very complex structure, making it quite challenging to come up with all necessary heuristics that can precisely split all annotations and assign them correctly to each person. For instance, our set of dependent prepositions will not cover all sentence conjunctions that either make one clause dependent on the other or connect two stand-alone sentences. Another example is utterances that introduce a person, which can be very ambiguous. There, the person might be either introducing themselves or another third party not necessarily partaking in the conversation. We also relied on machine learning models, which were able to tag the part of speeches of each original annotation. Although they have shown excellent results, they are not working perfectly. We found sentences that followed a very similar structure on which the POS tagger could not consistently make similar inferences. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 57, '_split_overlap': [{'doc_id': '741779a9c2ac55a3ba280215ddfef3d2', 'range': (0, 426)}, {'doc_id': 'ba9338d5d19603f91f35e4912bd1905c', 'range': (816, 1137)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '85f916012daee6c4328c4317e79a941'}>,\n",
      "                     <Document: {'content': 'We also relied on machine learning models, which were able to tag the part of speeches of each original annotation. Although they have shown excellent results, they are not working perfectly. We found sentences that followed a very similar structure on which the POS tagger could not consistently make similar inferences. These loopholes in our data pre-processing step might be the leading cause for a relatively high similarity score of around 0.778 which makes it difficult for our model to produce very distinctive summaries for each speaker. The gold labels we created are based on the references from DialogSum. Therefore, the quality of our gold labels is not as high as that of the DialogSum labels because the creation and evaluation process were not as polished. In addition, the annotations of DialogSum were written to summarize the whole dialogue. The semantic traits of this intention could still be found in our labels, which might also affect the quality of the model-generated summaries.\\nOn a high level, improvements can be made in the architecture and data creation process. However, in each of them, multiple areas can be improved and turn out to be relatively tricky. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 58, '_split_overlap': [{'doc_id': '85f916012daee6c4328c4317e79a941', 'range': (0, 321)}, {'doc_id': '150f90451c28dcf810c1e5402c5e1dc9', 'range': (861, 1188)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ba9338d5d19603f91f35e4912bd1905c'}>,\n",
      "                     <Document: {'content': 'The semantic traits of this intention could still be found in our labels, which might also affect the quality of the model-generated summaries.\\nOn a high level, improvements can be made in the architecture and data creation process. However, in each of them, multiple areas can be improved and turn out to be relatively tricky. Resolving all problem areas can lead to better results but would go beyond the scope of this thesis. We want to encourage future work for automated perspective summarization by listing these problem areas.\\nFuture work\\nAs we developed our methods, we identified problem areas and thus clarified the requirements for this task. Future work on perspective dialogue summarization can address these areas and needs to surpass the performance our model reached.\\nImproving the architecture: This does not necessarily mean increasing the model complexity. Since our architecture builds on the CODS model, which already has shown success and therefore has its degree of complexity, the depth of our architecture can consequently be considered deep. A high degree of complexity usually raises the number of parameters which slows down the training and requires more memory. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 59, '_split_overlap': [{'doc_id': 'ba9338d5d19603f91f35e4912bd1905c', 'range': (0, 327)}, {'doc_id': '83ab90514d2ff1f53f1536323f15c855', 'range': (876, 1191)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '150f90451c28dcf810c1e5402c5e1dc9'}>,\n",
      "                     <Document: {'content': 'Since our architecture builds on the CODS model, which already has shown success and therefore has its degree of complexity, the depth of our architecture can consequently be considered deep. A high degree of complexity usually raises the number of parameters which slows down the training and requires more memory. Then again, as explained earlier, adding more encoding layers could help the model distinguish every speaker and produce better summaries. In addition, multi-headed neural networks do not have to be the only solution for this task. There are many different architectural styles for designing a neural network. Therefore, it is necessary to identify the crucial requirements where we think that the distinction between each speaker is one of them.\\nExtending the data creation: This addresses the problem of high similarity between the labels we have created. The low degree of variance between the made references is very likely to be linked to the negative correlation of F1 and dissimilarity measurements in our model’s performance, i.e., the higher the F1 score, the more similar the generated summary pairs. Our heuristics and approach only scratched the surface of this problem area, potentially posing a whole work on its own. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 60, '_split_overlap': [{'doc_id': '150f90451c28dcf810c1e5402c5e1dc9', 'range': (0, 315)}, {'doc_id': '3e20d2fed82b8a7d75e44d7503534b39', 'range': (874, 1247)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '83ab90514d2ff1f53f1536323f15c855'}>,\n",
      "                     <Document: {'content': 'The low degree of variance between the made references is very likely to be linked to the negative correlation of F1 and dissimilarity measurements in our model’s performance, i.e., the higher the F1 score, the more similar the generated summary pairs. Our heuristics and approach only scratched the surface of this problem area, potentially posing a whole work on its own. When splitting the labels for perspective summaries, many linguistic and semantic features need to be considered. Extending and enhancing the proposed creation process would lead to fewer default steps, where a summary sentence is 1) well split and 2) assigned correctly to one person instead of being assigned to all persons.\\nCreating new data and annotations: Last but not least, we suggest that more data is always a beneficial resource for any deep learning task. Currently, there are no datasets available specifically for perspective dialogue summarization. While splitting the labels of regular summaries and assigning them to each speaker respectively, the semantic context is nonetheless different from summaries that are intended for a specific task. The labels of DialogSum are written in an observer style. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 61, '_split_overlap': [{'doc_id': '83ab90514d2ff1f53f1536323f15c855', 'range': (0, 373)}, {'doc_id': 'b1f8e4aaa0f71e6a19dd9005c7180bad', 'range': (842, 1192)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '3e20d2fed82b8a7d75e44d7503534b39'}>,\n",
      "                     <Document: {'content': 'Currently, there are no datasets available specifically for perspective dialogue summarization. While splitting the labels of regular summaries and assigning them to each speaker respectively, the semantic context is nonetheless different from summaries that are intended for a specific task. The labels of DialogSum are written in an observer style. However, this ‚observer‘ is to observe all parties in dialogue, so that the sentences are formed accordingly. These semantic and syntactic features will remain, even if the data pre-processing went smoothly, and still can influence the training process. Therefore, a dataset designated for this task with the same degree of quality assessment opens new promising paths for developing automated perspective dialogue summarizers.\\nWe are aware that there could be many more factors that affect the performance of our model. During this thesis’s creation, the aspects we just mentioned were the most prevalent we faced. Thus, we strongly emphasize those due to the fact that we experienced most obstacles caused by them.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 62, '_split_overlap': [{'doc_id': '3e20d2fed82b8a7d75e44d7503534b39', 'range': (0, 350)}, {'doc_id': '40242811711c22d51a361636e940f318', 'range': (605, 1067)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'b1f8e4aaa0f71e6a19dd9005c7180bad'}>,\n",
      "                     <Document: {'content': 'Therefore, a dataset designated for this task with the same degree of quality assessment opens new promising paths for developing automated perspective dialogue summarizers.\\nWe are aware that there could be many more factors that affect the performance of our model. During this thesis’s creation, the aspects we just mentioned were the most prevalent we faced. Thus, we strongly emphasize those due to the fact that we experienced most obstacles caused by them.\\nConclusion\\nOur contribution is an approach to building a neural network capable of generating summaries for each speaker in a dialogue, a method for creating reference summaries for perspective dialogue summarization, and an augmented set of reference labels for the DialogSum corpus. These labels contain summaries for each speaker gained from the original reference summary and can be used for training. Furthermore, this task of per-person dialogue summarization is new and has no literature record. With this work, we further refined the requirements and problem areas that frequently occur when building such a neural network.', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 63, '_split_overlap': [{'doc_id': 'b1f8e4aaa0f71e6a19dd9005c7180bad', 'range': (0, 462)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '40242811711c22d51a361636e940f318'}>,\n",
      "                     <Document: {'content': 'Willkommen zum zweiten Teil der Blogserie „Intelligentes Service-Ticket-System für die Wartung“! In diesem Teil stellen wir verschiedene Komponenten vor, die auf Methoden des maschinellen Lernens basieren und das Intelligenten Service-Ticket-Systems (ISTS) auf eine gewisse Art und Weise „intelligent“ machen. So werden Anlagenführer:innen wie auch Service-Techniker:innen bei der Bearbeitung von Instandhaltungsaufträgen unterstützt.\\nFalls Du den vorangegangenen Artikel verpasst hast, findest du hier die Einführung in den Use Case und das Lösungskonzept des ISTS.\\n\\nInfrastruktur für Machine Learning ServicesWelche ähnlichen Fehler traten in der Vergangenheit bereits auf?Clustering häufiger, ähnlicher BeschreibungenWelche:r Service-Techniker:in ist der/die Richtige?OutroLiteraturverzeichnis\\nInfrastruktur für Machine Learning Services\\n\\nDas ISTS setzt sich aus mehreren ML-Services zusammen, die miteinander interagieren und kommunizieren. Diese Services sind als Cloud-Run-Instanzen bereitgestellt. Alle Code-Versionen werden in Gitlab verwaltet und die aktuellste Version wird über eine CI/CD Pipeline in Google Cloud Run gepusht wo diese als Docker Container laufen. In Google Cloud Run laufen die Container bisher nicht durchgehend, sondern werden nach einer bestimmten Zeit, in der sie inaktiv sind, wieder herunter gefahren. Dadurch muss man nur für die tatsächliche Laufzeit bezahlen und spart Ressourcen. Dies ist allerdings nur während der Entwicklungszeit eine Option. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 0, '_split_overlap': [{'doc_id': '655e832817c51a203d5a51ba1b937295', 'range': (1005, 1483)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'bd846d1f28d00c9177ef09160f4ca4cf'}>,\n",
      "                     <Document: {'content': 'Alle Code-Versionen werden in Gitlab verwaltet und die aktuellste Version wird über eine CI/CD Pipeline in Google Cloud Run gepusht wo diese als Docker Container laufen. In Google Cloud Run laufen die Container bisher nicht durchgehend, sondern werden nach einer bestimmten Zeit, in der sie inaktiv sind, wieder herunter gefahren. Dadurch muss man nur für die tatsächliche Laufzeit bezahlen und spart Ressourcen. Dies ist allerdings nur während der Entwicklungszeit eine Option. Wenn das Projekt live geht und genutzt werden soll, würde diese Funktion deaktiviert werden, um zeitintensive Kaltstarts zu vermeiden.\\nDie persistente Datenspeicherung wird ebenfalls durch GCP verwaltet. Einerseits gibt es die Cloud SQL Services, wo sich PostgreSQL-Datenbanken für die Services befinden. Andererseits haben wir Cloud Storage Buckets, hier sind Rohdaten und ML-Modelle gespeichert.\\nStatt GCP per Hand zu konfigurieren, verwenden wir Terraform. Terraform ist ein Infrastructure-as-Code (IaC) Tool, mit dem man Konfigurationen in ein Skript schreiben kann. Terraform setzt dann unsere im Text beschriebene Configs um. Somit sind die Configs versionierbar, automatisierbar sowie selbst dokumentierend.\\nDie Infrastruktur für die Machine Learning Services ist in drei Bereiche aufgeteilt:\\nZunächst werden die Modelle trainiert. Hierzu haben wir einen Trainingsservice entwickelt, der regelmäßig von unserem Backend via einer REST-Schnittstelle getriggert wird. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 1, '_split_overlap': [{'doc_id': 'bd846d1f28d00c9177ef09160f4ca4cf', 'range': (0, 478)}, {'doc_id': '461a99f7eb9b5caa0b8317c748bcc354', 'range': (1050, 1450)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '655e832817c51a203d5a51ba1b937295'}>,\n",
      "                     <Document: {'content': 'Terraform setzt dann unsere im Text beschriebene Configs um. Somit sind die Configs versionierbar, automatisierbar sowie selbst dokumentierend.\\nDie Infrastruktur für die Machine Learning Services ist in drei Bereiche aufgeteilt:\\nZunächst werden die Modelle trainiert. Hierzu haben wir einen Trainingsservice entwickelt, der regelmäßig von unserem Backend via einer REST-Schnittstelle getriggert wird. Im Trainingsservice wird das Klassifikationsmodell anhand der aktuellen Daten aus der Datenbank trainiert. Das (auf Wikipedia-Daten vortrainierte) Smart-Search-Modell wird aus einem Google Cloud Storage Bucket geladen und dann ebenfalls auf den aktuellen Daten nachtrainiert.\\nZum Verwalten und Versionieren der Modelle verwenden wir MLFlow. Hier werden die Hyperparameter der Modelle geloggt, die Metriken der Modelle wie Accuracy und Precision werden gespeichert. Die Artefakte der Modelle werden in einem Google Cloud Storage Bucket gespeichert und die Verweise dazu ebenfalls von MLFlow verwaltet und gespeichert.\\nDie Daten von MLFlow sind in einer Postgres-Datenbank persistiert. Diese Datenbank ist in Google Cloud SQL gehostet.\\nDie besten trainierten Modelle werden dann zur Ausführung von unserem ISTS Backend geladen und dort bei Bedarf ausgeführt und aufgerufen.\\nWelche ähnlichen Fehler traten in der Vergangenheit bereits auf?\\nEine der Hauptaufgaben des intelligenten Ticketsystems ist die „Intelligente Suche“.\\xa0 ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 2, '_split_overlap': [{'doc_id': '655e832817c51a203d5a51ba1b937295', 'range': (0, 400)}, {'doc_id': '2dc38077a97df62104bd3a23257917a7', 'range': (1018, 1423)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '461a99f7eb9b5caa0b8317c748bcc354'}>,\n",
      "                     <Document: {'content': 'Die Daten von MLFlow sind in einer Postgres-Datenbank persistiert. Diese Datenbank ist in Google Cloud SQL gehostet.\\nDie besten trainierten Modelle werden dann zur Ausführung von unserem ISTS Backend geladen und dort bei Bedarf ausgeführt und aufgerufen.\\nWelche ähnlichen Fehler traten in der Vergangenheit bereits auf?\\nEine der Hauptaufgaben des intelligenten Ticketsystems ist die „Intelligente Suche“.\\xa0 Maschinenführer:innen, die ihr Problem in die Web App eingeben, sollen vorangegangene ähnliche Probleme vorgeschlagen werden. Wenn zum Beispiel eine LED-Lampe der Maschine nicht funktioniert, soll das ISTS in der Lage sein, ihnen ähnliche Probleme wie „Beleuchtung funktioniert nicht“ oder „Licht ist kaputt“ vorzuschlagen. Dies erleichtert die Erstellung und Bearbeitung von Tickets auf folgende Weise:\\n\\nMaschinenführer:innen müssen keine Zeit mit dem Eintippen einer langen Problembeschreibung verschwenden. Stattdessen können sie ein paar Schlüsselwörter eingeben, auf deren Grundlage eine Liste mit Vorschlägen zur Auswahl bereitgestellt wird.\\nTechniker:innen haben eine Liste mit einheitlichen Problemen, die leichter zu verstehen und zu bearbeiten sind. Darüber hinaus werden ihnnen auf der Grundlage ähnlicher Problembeschreibungen potenzielle Problemlösungen angeboten, was die Bearbeitungszeit eines Tickets weiter verkürzt.\\n\\nUm ähnliche Probleme zu identifizieren, wurde das NLP-Modell Word2Vec implementiert. Word2Vec ist ein zweischichtiges neuronales Netz, das darauf trainiert ist, sprachliche Kontexte von Wörtern zu erkennen. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 3, '_split_overlap': [{'doc_id': '461a99f7eb9b5caa0b8317c748bcc354', 'range': (0, 405)}, {'doc_id': '5e1d49a6edba1ab972bac54192c5a964', 'range': (1054, 1547)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '2dc38077a97df62104bd3a23257917a7'}>,\n",
      "                     <Document: {'content': 'Techniker:innen haben eine Liste mit einheitlichen Problemen, die leichter zu verstehen und zu bearbeiten sind. Darüber hinaus werden ihnnen auf der Grundlage ähnlicher Problembeschreibungen potenzielle Problemlösungen angeboten, was die Bearbeitungszeit eines Tickets weiter verkürzt.\\n\\nUm ähnliche Probleme zu identifizieren, wurde das NLP-Modell Word2Vec implementiert. Word2Vec ist ein zweischichtiges neuronales Netz, das darauf trainiert ist, sprachliche Kontexte von Wörtern zu erkennen. Das Modell analysiert einen großen Textkorpus, um herauszufinden, welche Wörter häufig zusammen im gleichen Kontext verwendet werden. Die analysierten Wörter werden dann in einen mehrdimensionalen Vektorraum eingeordnet, der auf dem Kontext basiert, in dem sie erscheinen. Die Position eines Wortes im Vektorraum wird als Worteinbettung bezeichnet, die einen mehrdimensionalen Vektor darstellt.\\nWord2Vec hat zwei Ansätze: einen CBOW- und einen Skip-Gram-Ansatz. Beim CBOW-Ansatz wird ein Zielwort auf der Grundlage seines Kontextes vorhergesagt. Im Gegensatz dazu wird beim Skip-Gram-Ansatz der Kontext des Wortes auf der Grundlage des Zielwortes vorhergesagt.\\n\\nQuelle: Exploiting Similarities among Languages for Machine Translation\\nDie folgende Abbildung zeigt die grundlegende Struktur des W2V-Modells. Zunächst wird für jedes Wort eine Worteinbettung nach dem Zufallsprinzip initialisiert (könnte auch wie im Beispiel als ein One-Hot-codierter Vektor dargestellt werden). ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 4, '_split_overlap': [{'doc_id': '2dc38077a97df62104bd3a23257917a7', 'range': (0, 493)}, {'doc_id': '5e970b53c71ba95b9848516b8cb6872f', 'range': (1040, 1469)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5e1d49a6edba1ab972bac54192c5a964'}>,\n",
      "                     <Document: {'content': 'Im Gegensatz dazu wird beim Skip-Gram-Ansatz der Kontext des Wortes auf der Grundlage des Zielwortes vorhergesagt.\\n\\nQuelle: Exploiting Similarities among Languages for Machine Translation\\nDie folgende Abbildung zeigt die grundlegende Struktur des W2V-Modells. Zunächst wird für jedes Wort eine Worteinbettung nach dem Zufallsprinzip initialisiert (könnte auch wie im Beispiel als ein One-Hot-codierter Vektor dargestellt werden). Dann wird die Eingabe an eine versteckte Schicht weitergegeben, die eine voll verbundene Schicht ist, deren Gewichte die Worteinbettungen sind. Die Ausgabe der vollständig verknüpften Schicht wird durch einen Softmax-Klassifikator geleitet, um die Wahrscheinlichkeiten der Zielwörter aus dem Vokabular zu ermitteln.\\n\\nSource: The Architecture of Word2Vec.\\nFür unseren Anwendungsfall haben wir ein CBOW-Word2Vec-Modell implementiert, da es für kleinere Datensätze besser geeignet ist. Das Modell sagt jedes Wort im Satz auf der Grundlage des Kontexts voraus, in dem es erscheint. Nehmen wir ein Beispiel: „LED Lampe an der Maschine ist kaputt“. Bei jedem Durchlauf des Modells wird ein Wort aus dem Satz ausgeblendet (z. B. das Wort „Lampe“), und das Modell versucht, dieses Wort anhand des Kontexts (z. B. „LED __ an der Maschine ist kaputt“) vorherzusagen. Wir kombinieren die Worteinbettungen der einzelnen Wörter aus dem Kontext, um eine Kontexteinbettung zu bilden. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 5, '_split_overlap': [{'doc_id': '5e1d49a6edba1ab972bac54192c5a964', 'range': (0, 429)}, {'doc_id': '5086ee5521155b09f03ed1cc7cf413c5', 'range': (1073, 1398)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5e970b53c71ba95b9848516b8cb6872f'}>,\n",
      "                     <Document: {'content': 'Bei jedem Durchlauf des Modells wird ein Wort aus dem Satz ausgeblendet (z. B. das Wort „Lampe“), und das Modell versucht, dieses Wort anhand des Kontexts (z. B. „LED __ an der Maschine ist kaputt“) vorherzusagen. Wir kombinieren die Worteinbettungen der einzelnen Wörter aus dem Kontext, um eine Kontexteinbettung zu bilden. Die Kontexteinbettung wird an die versteckte Schicht weitergegeben, um vorherzusagen, welches Wort fehlt. Idealerweise sollen die Wahrscheinlichkeiten des echten Zielworts, d. h. „Lampe“, nahe bei 1 liegen, während die Wahrscheinlichkeiten der anderen Wörter nahe bei 0 liegen sollen. Nach jeder Trainingsiteration werden die Worteinbettungen auf der Grundlage der analysierten Sätze angepasst.\\nZunächst wurde das implementierte Word2Vec-Modell auf der Grundlage des deutschen Wikipedia-Korpus mit rund 50.000 Artikeln trainiert. Anschließend wurde das Modell auf Basis der kundenspezifischen Daten des ESW nachtrainiert.\\nNach dem Training konnte unser Modell erfolgreich ähnliche Wörter identifizieren, wie aus den Beispielen ersichtlich:\\n\\nEs ist wichtig zu erwähnen, dass unser Modell auch in der Lage ist, Wörter zu erkennen, die eine ähnliche semantische Bedeutung haben, aber völlig anders geschrieben werden, wie z. B. „Licht“ und „Strahlung“.\\n\\nClustering häufiger, ähnlicher Beschreibungen\\nEine weitere Anforderung an das ISTS ist eine Filtermöglichkeit nach häufigen Problemen und Lösungen. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 6, '_split_overlap': [{'doc_id': '5e970b53c71ba95b9848516b8cb6872f', 'range': (0, 325)}, {'doc_id': 'a0cad898e0c470af3c8b702106bc3656', 'range': (948, 1424)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5086ee5521155b09f03ed1cc7cf413c5'}>,\n",
      "                     <Document: {'content': 'Nach dem Training konnte unser Modell erfolgreich ähnliche Wörter identifizieren, wie aus den Beispielen ersichtlich:\\n\\nEs ist wichtig zu erwähnen, dass unser Modell auch in der Lage ist, Wörter zu erkennen, die eine ähnliche semantische Bedeutung haben, aber völlig anders geschrieben werden, wie z. B. „Licht“ und „Strahlung“.\\n\\nClustering häufiger, ähnlicher Beschreibungen\\nEine weitere Anforderung an das ISTS ist eine Filtermöglichkeit nach häufigen Problemen und Lösungen. Um die Häufigkeit angeben zu können, wollen wir semantisch ähnliche Probleme/Lösungen zusammenfassen. Die Schwierigkeit besteht darin, die Ähnlichkeit von Texten zu berechnen. Da zum Beispiel „Verriegelung an der Tür hinten defekt“ und „Verriegelung reagiert nicht“ für einen Mensch als ähnliche Probleme erkennbar sind. Für den Computer, der nur die einzelnen Wörter betrachtet, sind sie unterschiedlich. Um sie zusammenzufassen, werden Cluster mit ähnlichen Problemen oder Lösungen benötigt.\\nTF-IDF\\nVor dem Clustering wird der Text in einen Vektor umgewandelt mit Hilfe des TF-IDF Vectorizer. TF-IDF (Term Frequency – Inverse Document Frequency) definiert die Wichtigkeit eines Wortes in einem Dokument. Gegeben ist ein Korpus mit mehreren Dokumenten. Der Wert gibt an, wie oft jedes Wort in dem gegebenen Dokument vorhanden ist und wie oft in den anderen Dokumenten. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 7, '_split_overlap': [{'doc_id': '5086ee5521155b09f03ed1cc7cf413c5', 'range': (0, 476)}, {'doc_id': '8c7a75477c20a0620f547ee30cc81c13', 'range': (971, 1346)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a0cad898e0c470af3c8b702106bc3656'}>,\n",
      "                     <Document: {'content': 'TF-IDF\\nVor dem Clustering wird der Text in einen Vektor umgewandelt mit Hilfe des TF-IDF Vectorizer. TF-IDF (Term Frequency – Inverse Document Frequency) definiert die Wichtigkeit eines Wortes in einem Dokument. Gegeben ist ein Korpus mit mehreren Dokumenten. Der Wert gibt an, wie oft jedes Wort in dem gegebenen Dokument vorhanden ist und wie oft in den anderen Dokumenten. Das bedeutet, dass ein Wort, das oft in einem Dokument vorkommt, relevant für das Dokument ist. Das bedeutet im Umkehrschluss, dass das Dokument sich sehr wahrscheinlich auf das Wort bezieht. Tritt ein Wort aber häufig in mehreren Dokumenten auf, ist es entweder relevant für alle oder für keines der Dokumente. Das macht es schwer, ein Dokument durch dieses Wort zu finden.\\nDer TF-IDF wird für jedes Wort im Korpus berechnet. Mit jedem Auftreten des Wortes im Dokument wird der TF-IDF Wert erhöht und mit jedem Auftreten in den anderen Dokumenten verringert sich der Wert.\\nFolgende Variablen sind wichtig:\\n\\nN: ist die Anzahl der Dokumente, die in einem Datensatz sind\\nd: ist das gegebene Dokument aus dem Datensatz\\nD: ist die Sammlung aller Dokumente\\nw: ist das gegebene Wort aus einem Dokument\\n\\nTF-IDF besteht aus zwei Teilen: die Term-Frequency und die Inverse-Document-Frequency.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 8, '_split_overlap': [{'doc_id': 'a0cad898e0c470af3c8b702106bc3656', 'range': (0, 375)}, {'doc_id': 'b0a42b284c655fadf96d14d58befb6d', 'range': (803, 1259)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '8c7a75477c20a0620f547ee30cc81c13'}>,\n",
      "                     <Document: {'content': 'Mit jedem Auftreten des Wortes im Dokument wird der TF-IDF Wert erhöht und mit jedem Auftreten in den anderen Dokumenten verringert sich der Wert.\\nFolgende Variablen sind wichtig:\\n\\nN: ist die Anzahl der Dokumente, die in einem Datensatz sind\\nd: ist das gegebene Dokument aus dem Datensatz\\nD: ist die Sammlung aller Dokumente\\nw: ist das gegebene Wort aus einem Dokument\\n\\nTF-IDF besteht aus zwei Teilen: die Term-Frequency und die Inverse-Document-Frequency.\\nDie Term-Frequency wird durch die Frequency f(w,d) berechnet und gibt die Häufigkeit von Wort w im Dokument d an.\\n\\nQuelle: Formel der Term-Frequency\\nDie Inverse-Document-Frequency idf(w,D) wird durch die Frequency f(w,D) berechnet und gibt die Häufigkeit von Wort w in der Sammlung aller Dokument D an.\\n\\nQuelle: Formel der Inverse-Document-Frequency\\nUm den TF-IDF Score zu berechnen, werden die zwei Häufigkeiten multipliziert.\\n\\nQuelle: Formel des TF-IDF Score\\nDarauf wenden wir ein dichte-basiertes Clustering an, da man keine Anzahl der Cluster vorgeben muss, wie zum Beispiel KMeans. Wir haben uns für OPTICS entschieden, da es weniger Parameter gibt und diese zudem noch leicht anzupassen sind. Um OPTICS zu verstehen, muss man als erstes DBSCAN betrachten, da sie aufeinander aufbauen.\\nDBSCAN\\nDBSCAN ist ebenfalls ein dichte-basiertes Clustering. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 9, '_split_overlap': [{'doc_id': '8c7a75477c20a0620f547ee30cc81c13', 'range': (0, 456)}, {'doc_id': '400eb388d11e82d46ff9608b217b9d88', 'range': (886, 1308)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'b0a42b284c655fadf96d14d58befb6d'}>,\n",
      "                     <Document: {'content': 'Quelle: Formel des TF-IDF Score\\nDarauf wenden wir ein dichte-basiertes Clustering an, da man keine Anzahl der Cluster vorgeben muss, wie zum Beispiel KMeans. Wir haben uns für OPTICS entschieden, da es weniger Parameter gibt und diese zudem noch leicht anzupassen sind. Um OPTICS zu verstehen, muss man als erstes DBSCAN betrachten, da sie aufeinander aufbauen.\\nDBSCAN\\nDBSCAN ist ebenfalls ein dichte-basiertes Clustering. Die Idee ist es, dass jedes Objekt in einem bestimmten Radius (Eps-Nachbarschaft) eine Mindestanzahl von Objekt (MinPts) enthält, um einem Cluster zugewiesen zu werden.\\nDie Eps-Nachbarschaft NEps(p) von einem Punkt p ist somit definiert als NEps(p) = {q E D | dist(p,q) <= Eps}. Daraus ergeben sich 2 Arten von Punkten in einem Cluster: Kernpunkte und Randpunkte. Kernpunkte befinden sich in einem Cluster und Randpunkte am Rand eines Clusters. Ein Kernpunkt q ist als dieser definiert wenn |NEps(q)| >= MinPts gilt.\\nUm die Bildung von Clustern zu verstehen, brauchen wir noch 3 weitere Begriffe, die sich auf die Beziehung zwischen den Punkten beziehen.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 10, '_split_overlap': [{'doc_id': 'b0a42b284c655fadf96d14d58befb6d', 'range': (0, 422)}, {'doc_id': 'a254f150931be3f1591f1df2fbe2593d', 'range': (702, 1077)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '400eb388d11e82d46ff9608b217b9d88'}>,\n",
      "                     <Document: {'content': 'Daraus ergeben sich 2 Arten von Punkten in einem Cluster: Kernpunkte und Randpunkte. Kernpunkte befinden sich in einem Cluster und Randpunkte am Rand eines Clusters. Ein Kernpunkt q ist als dieser definiert wenn |NEps(q)| >= MinPts gilt.\\nUm die Bildung von Clustern zu verstehen, brauchen wir noch 3 weitere Begriffe, die sich auf die Beziehung zwischen den Punkten beziehen.\\nEin Cluster wird definiert durch 3 wichtige Begriffe:\\n\\nDirectly density-reachable\\nEin Punkt p ist direkt density-reachable von einem Punkt q, wenn p in der Eps-Nachbarschaft von q ist, unter der Bedingung, dass q ein Kernpunkt ist.\\nDensity-reachable\\nEin Punkt p ist density-reachable, wenn die Punkte einer Kette von Punkten „directly density-reachable“ vom Vorgänger sind.\\nDensity-connected\\nDie Punkte p und q sind density-connected, wenn beide von einem Punkt o „density-reachable“ sind.\\n\\nQuelle: PERAFÁN-LÓPEZ, Juan Carlos; SIERRA-PÉREZ, Julián. An unsupervised pattern recognition methodology based on factor analysis and a genetic-DBSCAN algorithm to infer operational conditions from strain measurements in structural applications. Chinese Journal of Aeronautics, 2021, 34. Jg., Nr. 2, S. 165-181.\\nWann gehört ein Punkt zu einem Cluster?\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 11, '_split_overlap': [{'doc_id': '400eb388d11e82d46ff9608b217b9d88', 'range': (0, 375)}, {'doc_id': '86c90cba744f82e9fcabd239475f533a', 'range': (750, 1219)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a254f150931be3f1591f1df2fbe2593d'}>,\n",
      "                     <Document: {'content': 'Density-connected\\nDie Punkte p und q sind density-connected, wenn beide von einem Punkt o „density-reachable“ sind.\\n\\nQuelle: PERAFÁN-LÓPEZ, Juan Carlos; SIERRA-PÉREZ, Julián. An unsupervised pattern recognition methodology based on factor analysis and a genetic-DBSCAN algorithm to infer operational conditions from strain measurements in structural applications. Chinese Journal of Aeronautics, 2021, 34. Jg., Nr. 2, S. 165-181.\\nWann gehört ein Punkt zu einem Cluster?\\nEin Punkt q gehört zum Cluster C, wenn er von Punkt p, der zum Cluster C gehört, „density-reachable“ ist und wenn q und p „density-connected“ sind. Somit ist ein dichte-basiertes Cluster eine Menge von density-connected Objekten, die maximal ist unter Berücksichtigung der Dichteerreichbarkeit. Als Rauschen werden Punkte definiert, die zu keinem Cluster gehören.\\nOPTICS\\nOPTICS (Ordering Points to Identify Cluster Structure) basiert auf DBSCAN. Der Unterschied ist, dass OPTICS jedes Objekt nach ihrer Erreichbarkeitsdistanz in einer Vorrangwarteschlange einordnet. Der OPTICS-Algorithmus generiert die erweiterte Cluster-Ordnung, bestehend aus der Reihenfolge der Punkte und der Erreichbarkeitsentfernung. Diese bestimmt die Clusterzugehörigkeit.\\nDas Festlegen von Epsilon auf einen niedrigeren Wert führt zu kürzeren Laufzeiten und kann als maximaler Nachbarschaftsradius von jedem Punkt betrachtet werden, um andere potenziell erreichbare Punkte zu finden.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 12, '_split_overlap': [{'doc_id': 'a254f150931be3f1591f1df2fbe2593d', 'range': (0, 469)}, {'doc_id': 'ea359cc960a674c64b6557518f94bb15', 'range': (916, 1430)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '86c90cba744f82e9fcabd239475f533a'}>,\n",
      "                     <Document: {'content': 'Der Unterschied ist, dass OPTICS jedes Objekt nach ihrer Erreichbarkeitsdistanz in einer Vorrangwarteschlange einordnet. Der OPTICS-Algorithmus generiert die erweiterte Cluster-Ordnung, bestehend aus der Reihenfolge der Punkte und der Erreichbarkeitsentfernung. Diese bestimmt die Clusterzugehörigkeit.\\nDas Festlegen von Epsilon auf einen niedrigeren Wert führt zu kürzeren Laufzeiten und kann als maximaler Nachbarschaftsradius von jedem Punkt betrachtet werden, um andere potenziell erreichbare Punkte zu finden.\\nAnwendung des Modells\\nÄhnliche Probleme sind durch OPTICS in Cluster eingeteilt. Wir können die Häufigkeit bestimmen, indem wir die Probleme innerhalb eines Clusters pro AP (Arbeitsplatz) zählen und durch die Gesamtanzahl von Problemen am AP teilen. Die n häufigsten Probleme sollen vorgeschlagen werden, sobald man im Frontend einen AP ausgewählt hat.\\nWelche:r Service-Techniker:in ist der/die Richtige?\\nUm zu verhindern, dass Maschinenführer:innen eine falsche Problemkategorie in das Ticket-System eintragen, wodurch dann falsche Techniker:innen gerufen werden, haben wir ein Klassifizierungsmodell auf den Daten der vergangenen Aufträge trainiert.\\nTraining\\nDas Modell besteht intern aus fünf verschiedenen Teilmodellen. Für jede der Fehlerkategorien Elektronik, Mechanik, Sensorik, Hydraulik und Pneumatik wird ein eigener Algorithmus trainiert.\\nDie Problembeschreibungen der vergangenen Tickets, die als Feature für das Modell dienen sollen, werden für das Training zunächst mit einem TF-IDF-Vectorizer umgewandelt, damit die Algorithmen das Feature verarbeiten können.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 13, '_split_overlap': [{'doc_id': '86c90cba744f82e9fcabd239475f533a', 'range': (0, 514)}, {'doc_id': 'a716891f73161f1b807136ed4429fea3', 'range': (1167, 1589)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ea359cc960a674c64b6557518f94bb15'}>,\n",
      "                     <Document: {'content': 'Training\\nDas Modell besteht intern aus fünf verschiedenen Teilmodellen. Für jede der Fehlerkategorien Elektronik, Mechanik, Sensorik, Hydraulik und Pneumatik wird ein eigener Algorithmus trainiert.\\nDie Problembeschreibungen der vergangenen Tickets, die als Feature für das Modell dienen sollen, werden für das Training zunächst mit einem TF-IDF-Vectorizer umgewandelt, damit die Algorithmen das Feature verarbeiten können.\\nNach dieser Transformation wird nun für jedes der fünf Teilmodelle, aus denen das gesamte Modell am Ende besteht, der bestmögliche Algorithmus gesucht.\\nDie Algorithmen, die getestet werden, sind ein Naive Bayes Classifier und eine logistische Regression. Für beide Algorithmen wird jeweils noch ein Grid-Search auf einige vordefinierte Hyperparameter durchgeführt, um diese zu optimieren.\\nNachdem hierdurch für jede Kategorie das Modell mit der höchsten Präzision gefunden wurde, werden die besten Modelle mit den besten Hyperparametern jeweils auf den Trainingsdaten trainiert. Daraufhin werden die Modelle auf Testdaten noch einmal validiert und eine durchschnittliche Präzision auf allen fünf Modellen berechnet.\\nDie Hyperparameter der Teil-Modelle werden dann in MLFlow gespeichert und das gesamte Modell mit dem Python-Modul pickle in eine Bytestreamdatei verpackt und als Artefakt in einem Google Cloud Storage Bucket gespeichert.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 14, '_split_overlap': [{'doc_id': 'ea359cc960a674c64b6557518f94bb15', 'range': (0, 422)}, {'doc_id': '65059b2c20b46c32cd5d82d69c37d87a', 'range': (812, 1359)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a716891f73161f1b807136ed4429fea3'}>,\n",
      "                     <Document: {'content': 'Nachdem hierdurch für jede Kategorie das Modell mit der höchsten Präzision gefunden wurde, werden die besten Modelle mit den besten Hyperparametern jeweils auf den Trainingsdaten trainiert. Daraufhin werden die Modelle auf Testdaten noch einmal validiert und eine durchschnittliche Präzision auf allen fünf Modellen berechnet.\\nDie Hyperparameter der Teil-Modelle werden dann in MLFlow gespeichert und das gesamte Modell mit dem Python-Modul pickle in eine Bytestreamdatei verpackt und als Artefakt in einem Google Cloud Storage Bucket gespeichert.\\nAnwendung des Modells\\nZur Anwendung des Multi-Out-Modells wird die Problembeschreibung, die als Input dient, ebenfalls mit einem TF-IDF-Vectorizer in einen Wortvektor umgewandelt.\\nDer Vektor wird dann als Input in das Multi-Out-Modell gegeben, das ihn jeweils an die fünf internen Modelle weitergibt. Die einzelnen Modelle sagen dann jeweils die Wahrscheinlichkeit vorher, dass die Problembeschreibung zu der Kategorie gehört.\\nDas Objekt der Multi-Out-Klasse fügt diese Ergebnisse dann zusammen und gibt das Ergebnis als ein Dictionary zurück.\\n\\nOutro\\nDas intelligente Service-Ticket-System ist eine Lösung, die entwickelt wurde, um die täglichen Arbeitsprozesse innerhalb der ESW-Gruppe zu erleichtern. Das System vereinfacht insbesondere die tägliche Arbeit der ESW-Mitarbeiter:innen. So müssen beispielsweise Maschinenführer:innen nicht mehr alle notwendigen Informationen in einen Auftrag eintragen, da viele Felder bereits vorausgefüllt sind.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 15, '_split_overlap': [{'doc_id': 'a716891f73161f1b807136ed4429fea3', 'range': (0, 547)}, {'doc_id': '68b33f0ecb46cc667cd3dbb24d078543', 'range': (975, 1494)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '65059b2c20b46c32cd5d82d69c37d87a'}>,\n",
      "                     <Document: {'content': 'Das Objekt der Multi-Out-Klasse fügt diese Ergebnisse dann zusammen und gibt das Ergebnis als ein Dictionary zurück.\\n\\nOutro\\nDas intelligente Service-Ticket-System ist eine Lösung, die entwickelt wurde, um die täglichen Arbeitsprozesse innerhalb der ESW-Gruppe zu erleichtern. Das System vereinfacht insbesondere die tägliche Arbeit der ESW-Mitarbeiter:innen. So müssen beispielsweise Maschinenführer:innen nicht mehr alle notwendigen Informationen in einen Auftrag eintragen, da viele Felder bereits vorausgefüllt sind.\\nDarüber hinaus werden Maschinenbedienenden die letzten, häufigsten oder ähnlichen Probleme vorgeschlagen, sodass sie keine zusätzliche Zeit für das Schreiben langer Problembeschreibungen aufwenden müssen. Zusätzlich wird ihnen eine Problemkategorie vorgeschlagen, um die Auftragserstellung weiter zu vereinfachen.\\nTechniker:innen profitieren ebenfalls von der Anwendung, da ihnen potenzielle Problemlösungen vorgeschlagen werden, was den Prozess der Auftragsbearbeitung beschleunigt. Ein: Teamleiter:in kann mit Hilfe von benutzerdefinierten Filtern (z. B. letzte/häufigste Probleme) einfach durch die Aufträge navigieren und erhält einen umfassenderen Überblick über die erstellten Aufträge.\\nDie ISTS App läuft in der Google Cloud unter Verwendung von Docker Images. Der „intelligente“ Teil der Anwendung ist in Form von zwei Machine-Learning-Modellen implementiert: dem intelligenten Suchmodell Word2Vec und Naive Bayes, zusammen mit logistischer Regression als Modell zur Klassifizierung von Kategorien. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 16, '_split_overlap': [{'doc_id': '65059b2c20b46c32cd5d82d69c37d87a', 'range': (0, 519)}, {'doc_id': 'fe52233c848fb377e7afd237b69cf9ab', 'range': (1074, 1526)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '68b33f0ecb46cc667cd3dbb24d078543'}>,\n",
      "                     <Document: {'content': 'B. letzte/häufigste Probleme) einfach durch die Aufträge navigieren und erhält einen umfassenderen Überblick über die erstellten Aufträge.\\nDie ISTS App läuft in der Google Cloud unter Verwendung von Docker Images. Der „intelligente“ Teil der Anwendung ist in Form von zwei Machine-Learning-Modellen implementiert: dem intelligenten Suchmodell Word2Vec und Naive Bayes, zusammen mit logistischer Regression als Modell zur Klassifizierung von Kategorien. Zusätzlich wurde ein Clustering ähnlicher Probleme implementiert, um ähnliche Problembeschreibungen zu gruppieren und die häufigsten Probleme zu identifizieren.\\nLiteraturverzeichnis\\n[1] SINGH, Prasoon. Deep Dive Into Word2Vec. Medium [online]. 13 September 2019 [viewed 19 October 2022]. Available from: https://medium.com/analytics-vidhya/deep-dive-into-word2vec-7fcefa765c17\\n[2] ANKERST, Mihael, et al. OPTICS: Ordering points to identify the clustering structure. ACM Sigmod record, 1999, 28. Jg., Nr. 2, S. 49-60.\\n[3] BORCAN, Marius. TF-IDF Explained And Python Sklearn Implementation. Medium [online]. 08 June 2020 [viewed 23 October 2022].\\nAvailable from: https://towardsdatascience.com/tf-idf-explained-and-python-sklearn-implementation-b020c5e83275\\n[4]\\xa0 ESTER, Martin, et al. A density-based algorithm for discovering clusters in large spatial databases with noise. In: kdd. 1996. S. 226-231.\\n[5]\\xa0 KHAN, Kamran, et al. DBSCAN: Past, present and future. In: The fifth international conference on the applications of digital information and web technologies (ICADIWT 2014). IEEE, 2014. S. 232-238.', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/ki-optimierung-in-der-industrie-intelligentes-service-ticket-system-fuer-die-wartung-teil-2/', 'authors': ['Anastasiia Malyk', 'Hannah Hepke', 'Niklas Küchen', 'Muhammad Daniel Bin Mohd Khir', 'Marius Jost'], 'date': '18.12.2023', 'title': 'KI-Optimierung in der Industrie: Intelligentes Service-Ticket-System für die Wartung (Teil 2)', '_split_id': 17, '_split_overlap': [{'doc_id': '68b33f0ecb46cc667cd3dbb24d078543', 'range': (0, 452)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'fe52233c848fb377e7afd237b69cf9ab'}>,\n",
      "                     <Document: {'content': 'Creating user-friendly explanations still poses a challenge in the field of Explainable AI. Yet, it is indispensable to meet the demand for transparency and comprehension in black box models of various user groups without ML expertise.\\xa0Considering the social-psychological origin of explanations, effective XAI requires designing the interaction between an agent and a human user. Transitioning from AI as a black box to an explainer, interactive user interfaces offer a promising solution for facilitating this dialogue.\\nThe following blog post summarizes the findings of my bachelor thesis where I explore the linking of UI/UX Design and XAI. To make this tangible I will guide you through my process of researching, selecting, and visualizing XAI methods, following the user-centered design process, eventually resulting in the approach for an explainable user interface of an ML-based demand forecasting system.\\n\\nThe dilemma surrounding Explainable AIExplanations are social interactionsUser-Centered Design ProcessUse Case: Demand Forecasting in RetailPhase 1: Researching User and Context of UsePhase 2: Selection of XAI methodsDefining Meta RequirementsCounterfactual ExamplesPhase 3: Visualizing example-based XAI in a user interfacePhase 4: EvaluationWhat now?\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 0, '_split_overlap': [{'doc_id': 'fa6caf7b8d5a6486d1428b77d5a921f0', 'range': (645, 1269)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '8470c7e9f25809875366370dc53b942b'}>,\n",
      "                     <Document: {'content': 'To make this tangible I will guide you through my process of researching, selecting, and visualizing XAI methods, following the user-centered design process, eventually resulting in the approach for an explainable user interface of an ML-based demand forecasting system.\\n\\nThe dilemma surrounding Explainable AIExplanations are social interactionsUser-Centered Design ProcessUse Case: Demand Forecasting in RetailPhase 1: Researching User and Context of UsePhase 2: Selection of XAI methodsDefining Meta RequirementsCounterfactual ExamplesPhase 3: Visualizing example-based XAI in a user interfacePhase 4: EvaluationWhat now?\\nThe dilemma surrounding Explainable AI\\nIn the ever-evolving landscape of technology, artificial intelligence has not only seamlessly integrated into our daily lives but is profoundly impacting high-stakes decision-making in sectors like healthcare, finance, criminal justice, and retail. While AI models excel in accuracy and efficiency with growing data sets, they often operate as black boxes, making it challenging to understand their outcomes and decision processes.\\nExplainable Artificial Intelligence (XAI) as an emerging research field is concerned with moving towards a more transparent approach to AI. It is therefore traded as a key element for developing trustworthy machine-learning applications. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 1, '_split_overlap': [{'doc_id': '8470c7e9f25809875366370dc53b942b', 'range': (0, 624)}, {'doc_id': '7b31f1cc197b8c1012e6ae85905a60b0', 'range': (913, 1333)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'fa6caf7b8d5a6486d1428b77d5a921f0'}>,\n",
      "                     <Document: {'content': 'While AI models excel in accuracy and efficiency with growing data sets, they often operate as black boxes, making it challenging to understand their outcomes and decision processes.\\nExplainable Artificial Intelligence (XAI) as an emerging research field is concerned with moving towards a more transparent approach to AI. It is therefore traded as a key element for developing trustworthy machine-learning applications. While various terms like interpretability, explicability, and transparency are interchangeably used, the core goal of XAI is to make AI decisions understandable to humans.\\nDespite the substantial algorithm-centric progress in XAI, critics argue that the field primarily caters to the needs and expertise of ML engineers. However, the increasing automation of processes has brought AI into direct interaction with various user types, including decision-makers, domain experts, business stakeholders, and lay users, most of whom lack in-depth AI knowledge.\\nTo fulfill the diverse explainability needs of its user groups, XAI must adopt a human-centered approach. Yet, one fundamental question remains: What defines user-friendly explanations? Exploring the concept of explanations from a social psychology perspective is expected to be an insightful approach.\\nExplanations are social interactions\\nEver since explanations have been an integral part of human learning and cognitive processing. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 2, '_split_overlap': [{'doc_id': 'fa6caf7b8d5a6486d1428b77d5a921f0', 'range': (0, 420)}, {'doc_id': '406df64828a16ed4c775d75b5f751965', 'range': (976, 1410)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '7b31f1cc197b8c1012e6ae85905a60b0'}>,\n",
      "                     <Document: {'content': 'To fulfill the diverse explainability needs of its user groups, XAI must adopt a human-centered approach. Yet, one fundamental question remains: What defines user-friendly explanations? Exploring the concept of explanations from a social psychology perspective is expected to be an insightful approach.\\nExplanations are social interactions\\nEver since explanations have been an integral part of human learning and cognitive processing. In his research on the intersection of social sciences and XAI, Researcher Tim Miller poses four findings when it comes to explanations:\\n\\nExplanations are contrastive and sought in response to counterfactual scenarios. We inquire not just why something occurred but why it happened instead of something else.\\nExplanations are selectively chosen, with a preference for concise and precise explanations. Humans tend to identify one or two causes for an event, favoring clarity over complexity.\\nProbabilities alone may not effectively identify underlying causes. Causal explanations alongside statistical generalizations enhance overall satisfaction.\\nExplanations are social. In its origin, an explanation is a social construct within a conversation or interaction where knowledge is transferred between an explainer and an explainee.\\n\\nApplying this understanding to XAI highlights the shift in human-computer interaction. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 3, '_split_overlap': [{'doc_id': '7b31f1cc197b8c1012e6ae85905a60b0', 'range': (0, 434)}, {'doc_id': 'ef9da2ed438b2e27f3c5ad2c0accb7a0', 'range': (927, 1354)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '406df64828a16ed4c775d75b5f751965'}>,\n",
      "                     <Document: {'content': 'Probabilities alone may not effectively identify underlying causes. Causal explanations alongside statistical generalizations enhance overall satisfaction.\\nExplanations are social. In its origin, an explanation is a social construct within a conversation or interaction where knowledge is transferred between an explainer and an explainee.\\n\\nApplying this understanding to XAI highlights the shift in human-computer interaction. In this conversation, the agent assumes the role of what Miller calls the ‘explainer’, conveying decisions to human users, the ‘explainees’.\\nAchieving genuine explainability in XAI makes it essential to create a common basis for communication between both, the AI system and the users. Employing user interfaces as mediators, we visually facilitate this dialogue. This approach enables users to interact, adjust inputs, and explore functionalities, fostering a deeper understanding and, ultimately, trust in the system.\\nStill, effective communication of explanations hinges on understanding users‘ specific explainability needs when using AI systems. This necessitates a tailored development process for AI tools, and that is where user-centered design comes into play.\\nUser-Centered Design Process\\n\\nUser-centered design (UCD) is rooted in the continuous involvement of users in the design and development process to maintain a focus on their needs. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 4, '_split_overlap': [{'doc_id': '406df64828a16ed4c775d75b5f751965', 'range': (0, 427)}, {'doc_id': '5e5d9d7cb4743003cb5556d39a6fbb55', 'range': (948, 1377)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'ef9da2ed438b2e27f3c5ad2c0accb7a0'}>,\n",
      "                     <Document: {'content': 'Still, effective communication of explanations hinges on understanding users‘ specific explainability needs when using AI systems. This necessitates a tailored development process for AI tools, and that is where user-centered design comes into play.\\nUser-Centered Design Process\\n\\nUser-centered design (UCD) is rooted in the continuous involvement of users in the design and development process to maintain a focus on their needs. This process, as per ISO standard ISO 9241-210 2010, comprises four key steps:\\n\\nUnderstand and specify the user and the context of use:\\nThis step involves understanding users, their goals, needs, and the context in which they engage with the system. Research methods such as interviews, surveys, and observations help uncover user pain points and preferences, ensuring a user-centric approach.\\nSpecify the user requirements:\\nBased on insights from the prior step, this phase establishes clear design goals and key challenges the design solution needs to address to guide the design process effectively.\\nProduce design solutions:\\nThe third phase involves creating design solutions that meet the defined requirements and user needs. Designers engage in brainstorming, sketching, prototyping, and iterative refinement, with user feedback playing a pivotal role in aligning the design with user expectations.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 5, '_split_overlap': [{'doc_id': 'ef9da2ed438b2e27f3c5ad2c0accb7a0', 'range': (0, 429)}, {'doc_id': 'a388466f3a392885bc62f09574b2f322', 'range': (824, 1334)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5e5d9d7cb4743003cb5556d39a6fbb55'}>,\n",
      "                     <Document: {'content': 'Specify the user requirements:\\nBased on insights from the prior step, this phase establishes clear design goals and key challenges the design solution needs to address to guide the design process effectively.\\nProduce design solutions:\\nThe third phase involves creating design solutions that meet the defined requirements and user needs. Designers engage in brainstorming, sketching, prototyping, and iterative refinement, with user feedback playing a pivotal role in aligning the design with user expectations.\\nEvaluate the design against the requirements\\nIn the final step, the design is evaluated for alignment with evolving user needs. Usability testing and feedback sessions involve users throughout the development process, allowing for early identification of usability issues. The design is then refined and iterated to enhance user satisfaction and usability.\\n\\nIn essence, UCD revolves around constant user involvement, ensuring that the design process remains user-focused, from understanding their needs to delivering a user-friendly final product.\\nUse Case: Demand Forecasting in Retail\\nNumerous open-source libraries and toolkits strive to empower practitioners with access to a range of XAI techniques and explanations for black-box ML models. Yet, what remains challenging is translating these theoretical frameworks into real-world applications.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 6, '_split_overlap': [{'doc_id': '5e5d9d7cb4743003cb5556d39a6fbb55', 'range': (0, 510)}, {'doc_id': '523cdaba5c747f92b277a7a35c05fbd7', 'range': (869, 1360)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a388466f3a392885bc62f09574b2f322'}>,\n",
      "                     <Document: {'content': 'In essence, UCD revolves around constant user involvement, ensuring that the design process remains user-focused, from understanding their needs to delivering a user-friendly final product.\\nUse Case: Demand Forecasting in Retail\\nNumerous open-source libraries and toolkits strive to empower practitioners with access to a range of XAI techniques and explanations for black-box ML models. Yet, what remains challenging is translating these theoretical frameworks into real-world applications.\\nTo make things more tangible I will showcase a human-centered approach about how XAI can be effectively implemented through a practical example of an AI-driven demand forecasting system in retail. In the following sections, I will illustrate the results I acquired during the first iteration of the user-centered design process within my thesis, starting from the initial user research stage to the selection of suitable XAI methods accordingly. Finally, I will introduce my approach for visually applying XAI in a user interface using design patterns, specifically tailored for AI products.\\nPhase 1: Researching User and Context of Use\\nEnd users of AI-based forecasting systems are typically domain experts, highly skilled in logistics, supply chain management, and demand forecasting. Their extensive experience drives their reliance on instinct and intuition for assessing the system’s trustworthiness. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 7, '_split_overlap': [{'doc_id': 'a388466f3a392885bc62f09574b2f322', 'range': (0, 491)}, {'doc_id': '36582088b3ca64b8e7287510110396f9', 'range': (938, 1397)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '523cdaba5c747f92b277a7a35c05fbd7'}>,\n",
      "                     <Document: {'content': 'Finally, I will introduce my approach for visually applying XAI in a user interface using design patterns, specifically tailored for AI products.\\nPhase 1: Researching User and Context of Use\\nEnd users of AI-based forecasting systems are typically domain experts, highly skilled in logistics, supply chain management, and demand forecasting. Their extensive experience drives their reliance on instinct and intuition for assessing the system’s trustworthiness. Understanding the rationale behind specific predictions is their primary concern, guiding their decision-making.\\nDeviations in AI predictions from their expectations erode their confidence in the system. When faced with incomprehensible forecasts, users seek explanations and support from the development team, typically ML engineers and Data Scientists. However, for the developers providing these explanations entails significant time and resources through additional manual effort, eventually hindering system scalability.\\nAdditionally, end users demand control to override AI predictions, especially when discrepancies arise due to their domain expertise and intuition. Despite users are already able to adjust predictions, the decentralized implementation of the system landscape, however, leads to opacity in prediction changes made by users, resulting in hidden feedback loops that impact system development.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 8, '_split_overlap': [{'doc_id': '523cdaba5c747f92b277a7a35c05fbd7', 'range': (0, 459)}, {'doc_id': '56ad281a77a9bd6bda3f9b89e0a2acd3', 'range': (986, 1375)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '36582088b3ca64b8e7287510110396f9'}>,\n",
      "                     <Document: {'content': 'Additionally, end users demand control to override AI predictions, especially when discrepancies arise due to their domain expertise and intuition. Despite users are already able to adjust predictions, the decentralized implementation of the system landscape, however, leads to opacity in prediction changes made by users, resulting in hidden feedback loops that impact system development.\\nPhase 2: Selection of XAI methods\\nAt this point, the procedure within the user-centered design process entails deriving user requirements from these findings. For selecting appropriate XAI methods, an intermediate step becomes necessary: identifying specific explainability needs based on our user research.\\nWe recall explanations in XAI are a form of knowledge exchange between an AI agent and human users. In this interaction, the AI system is supposed to provide understandable explanations in response to user queries. In a similar effort, Liao et al. categorized the questions users pose to AI systems into nine explainability need categories within their “XAI Question Bank“. Accordingly, they also developed a “Mapping Guide“ recommending explanations and suitable XAI methods for each category.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 9, '_split_overlap': [{'doc_id': '36582088b3ca64b8e7287510110396f9', 'range': (0, 389)}, {'doc_id': 'd21446209c3347bc5b43419824bb82b1', 'range': (798, 1192)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '56ad281a77a9bd6bda3f9b89e0a2acd3'}>,\n",
      "                     <Document: {'content': 'In this interaction, the AI system is supposed to provide understandable explanations in response to user queries. In a similar effort, Liao et al. categorized the questions users pose to AI systems into nine explainability need categories within their “XAI Question Bank“. Accordingly, they also developed a “Mapping Guide“ recommending explanations and suitable XAI methods for each category.\\nWithin my process, I have referred to this XAI Question Bank to also classify the findings from my user research into the given categories to guide the selection of suitable XAI methods. The results reveal that most of the insights gathered from the user research align with categories that pertain to local explanations rather than explaining the complex global model-wide logic. ‘Local’ here defines explanations for specific, individual predictions, rather than the entire model behavior which would, in contrast, be the case for ‘global’ explanations.\\nNotably, all of the identified categories are commonly mapped to an example-based method, which means explaining the predictions using example instances.\\nExample-based explanation distinguishes two types:\\nPrototypical examples: These closely resemble the instance and yield the same (or a nearly similar) predicted outcome, making them suitable for substantiating the model’s prediction.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 10, '_split_overlap': [{'doc_id': '56ad281a77a9bd6bda3f9b89e0a2acd3', 'range': (0, 394)}, {'doc_id': '98d35af7d7c808849fc1814863f8fa77', 'range': (951, 1338)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'd21446209c3347bc5b43419824bb82b1'}>,\n",
      "                     <Document: {'content': 'Notably, all of the identified categories are commonly mapped to an example-based method, which means explaining the predictions using example instances.\\nExample-based explanation distinguishes two types:\\nPrototypical examples: These closely resemble the instance and yield the same (or a nearly similar) predicted outcome, making them suitable for substantiating the model’s prediction.\\nCounterfactual examples: They are similar to the instance in most but not all circumstances (features) but lead to a significantly different prediction. Counterfactual examples highlight the smallest change required to achieve an alternative outcome, offering insights into the actions needed to reach the desired result.\\nDefining Meta Requirements\\nThese insights served as the foundation for defining two overarching objectives, which I call meta requirements. In this case, user research highlighted that users predominantly inquire about why a particular prediction occurred or why it did not align with their expectations. From this, the first meta-requirement emerged: prioritizing clear explanations for local predictions rather than explaining the complex global model-wide logic. A global approach is deemed to be very complex and less useful, given the users‘ primary focus on understanding specific predictions.\\nThe second meta-requirement relates to the user’s desire for control, a need also identified in the user research. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 11, '_split_overlap': [{'doc_id': 'd21446209c3347bc5b43419824bb82b1', 'range': (0, 387)}, {'doc_id': '2d596b33877f7bcbe5357a36feab780e', 'range': (1015, 1424)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '98d35af7d7c808849fc1814863f8fa77'}>,\n",
      "                     <Document: {'content': 'From this, the first meta-requirement emerged: prioritizing clear explanations for local predictions rather than explaining the complex global model-wide logic. A global approach is deemed to be very complex and less useful, given the users‘ primary focus on understanding specific predictions.\\nThe second meta-requirement relates to the user’s desire for control, a need also identified in the user research. This is especially relevant when obvious prediction errors occur or when there are circumstances in the real world that the AI model is not able to know because it is not encoded in its input features (e.g. the occurrence of Covid). Thus, the design solution should address this essential user need for control, empowering users to have agency over the system.\\nCounterfactual Examples\\nIn the realm of XAI, counterfactual explanations emerge as an evolving method for explaining the complex interplay between actions and outcomes. They offer an understanding of an elemental cause-and-effect relationship.\\nThey do so by illustrating the smallest necessary modifications required to attain the desired prediction compared to a reference example. In this framework, the term ‘effect’ refers to the anticipated outcome, while the ‘causes’ encompass the specific feature values of the instance that have influenced the model’s prediction.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 12, '_split_overlap': [{'doc_id': '98d35af7d7c808849fc1814863f8fa77', 'range': (0, 409)}, {'doc_id': 'efaae77540cdced03a1c0070a1a0e2f9', 'range': (940, 1343)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '2d596b33877f7bcbe5357a36feab780e'}>,\n",
      "                     <Document: {'content': 'They offer an understanding of an elemental cause-and-effect relationship.\\nThey do so by illustrating the smallest necessary modifications required to attain the desired prediction compared to a reference example. In this framework, the term ‘effect’ refers to the anticipated outcome, while the ‘causes’ encompass the specific feature values of the instance that have influenced the model’s prediction.\\nThis approach aligns closely with the cognitive processes inherent in human counterfactual thinking. It mirrors the mental exercise where individuals contemplate alternative scenarios that could have unfolded in the past or may potentially occur in the future. This introspective ‘what if?’ questioning allows humans to mentally simulate divergent outcomes counter to factual events.\\nBy implementing analogous principles in machine learning, counterfactual examples can be strategically leveraged to enhance the interpretability and transparency of AI systems. They provide a mechanism for explaining local predictions without exposing the intricate internal logic governing the decision-making process. Consequently, counterfactual examples emerge as a compliant means of addressing the GDPR’s ‘right to explanation’, offering suitable and permissible explanations for end users, particularly in the quest for enhanced understanding and trust within the AI landscape.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 13, '_split_overlap': [{'doc_id': '2d596b33877f7bcbe5357a36feab780e', 'range': (0, 403)}, {'doc_id': '9e0f4a579769d9d2c4810ca500484cd', 'range': (965, 1372)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'efaae77540cdced03a1c0070a1a0e2f9'}>,\n",
      "                     <Document: {'content': 'They provide a mechanism for explaining local predictions without exposing the intricate internal logic governing the decision-making process. Consequently, counterfactual examples emerge as a compliant means of addressing the GDPR’s ‘right to explanation’, offering suitable and permissible explanations for end users, particularly in the quest for enhanced understanding and trust within the AI landscape.\\nPhase 3: Visualizing example-based XAI in a user interface\\nWhen creating a design solution in the third phase of UCD, it is important to clarify what information needs to be visualized. In the context of demand forecasting, each example of an instance represents the prediction of the demand for a particular product on a given day. A scenario contains two important pieces of information: the predicted outcome, which signifies the expected sales volume, and the relevant features that the AI model considers when making its prediction. For the initial iteration of our user interface, I have focused on six key features: day of the week, month, price, temperature, campaign, and event.\\nTo ensure a consistent user experience, first, I established a standardized design for examples being horizontal cards within the interface, displaying predicted sales on the left and listing corresponding feature values on the right. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 14, '_split_overlap': [{'doc_id': 'efaae77540cdced03a1c0070a1a0e2f9', 'range': (0, 407)}, {'doc_id': '62bd4c0e0be21199f0d15411ce857ab1', 'range': (946, 1330)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '9e0f4a579769d9d2c4810ca500484cd'}>,\n",
      "                     <Document: {'content': 'For the initial iteration of our user interface, I have focused on six key features: day of the week, month, price, temperature, campaign, and event.\\nTo ensure a consistent user experience, first, I established a standardized design for examples being horizontal cards within the interface, displaying predicted sales on the left and listing corresponding feature values on the right. This design choice facilitates easy scaling, allowing stacking for multiple instances, each explaining a single prediction. The table-like format simplifies comparisons between instances, enabling users to comprehend diverse scenarios at a glance. Furthermore, the examples are visually distinguished based on the kind of instance they represent: comparable past sales, the initially predicted forecast, and AI-generated instances.\\nTo provide a realistic and business-relevant scenario for my user interface, I chose a specific product, ‘Apple Pink Lady 6 pieces in a bowl,’ commonly found in retail stores. As this is a fictional use case, so are all the sales figures I use.\\nFollowing the Human-Centered AI (HCAI) pattern language proposed by Ben Shneiderman in 2022, the initial view of the interface provides users with a contextual overview. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 15, '_split_overlap': [{'doc_id': '9e0f4a579769d9d2c4810ca500484cd', 'range': (0, 384)}, {'doc_id': 'eb85ff016964548d9067bfc7f5c6425', 'range': (817, 1231)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '62bd4c0e0be21199f0d15411ce857ab1'}>,\n",
      "                     <Document: {'content': 'To provide a realistic and business-relevant scenario for my user interface, I chose a specific product, ‘Apple Pink Lady 6 pieces in a bowl,’ commonly found in retail stores. As this is a fictional use case, so are all the sales figures I use.\\nFollowing the Human-Centered AI (HCAI) pattern language proposed by Ben Shneiderman in 2022, the initial view of the interface provides users with a contextual overview. A bar chart takes center stage, providing a holistic view of both forecast and historical sales of the viewed article. Bar charts are an effective means of data visualization, offering quick and accurate comprehension of value disparities and visually distinguishing each day as the distinct data point that it is. The chart spans five weeks, divided into two sections: the past three weeks of sales on the left and a two-week forecast on the right. Additional features impacting sales, including price, event, and campaign, are incorporated into the design, providing users with pertinent information at a glance.\\n\\nIf the output of the AI is unpleasant, surprising, or unfamiliar, users need explanations to evaluate the AI’s decision. A detailed view allows for simultaneously accessing more detailed information, enhancing understanding. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 16, '_split_overlap': [{'doc_id': '62bd4c0e0be21199f0d15411ce857ab1', 'range': (0, 414)}, {'doc_id': '32ce8fecb7aad9f3a5a1a9b8a32f50b1', 'range': (865, 1255)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'eb85ff016964548d9067bfc7f5c6425'}>,\n",
      "                     <Document: {'content': 'Additional features impacting sales, including price, event, and campaign, are incorporated into the design, providing users with pertinent information at a glance.\\n\\nIf the output of the AI is unpleasant, surprising, or unfamiliar, users need explanations to evaluate the AI’s decision. A detailed view allows for simultaneously accessing more detailed information, enhancing understanding. The additional information includes two service levels indicating the statistical probability of meeting the demand for the item over a specific period, factoring in an efficient optimization parameter. To foster trust, prototypical examples from past sales are presented to substantiate the current prediction. Additionally, a bar chart illustrating the importance of a feature’s influence is displayed, serving as an explanation of how each feature contributes to the forecast.\\n\\nTo cater to users‘ desire for control, the interface integrates a simulation mode. This view allows users to explore the system’s functionalities without triggering consequential outcomes. However, the challenge lies in explaining the interdependencies between features and predicted outcomes. As a solution, the interface is split into two parts: the left side displaying the distinct features, and the right side showing the corresponding prediction. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 17, '_split_overlap': [{'doc_id': 'eb85ff016964548d9067bfc7f5c6425', 'range': (0, 390)}, {'doc_id': '4b661283bb898ef6c6392c3cf4e5c4d9', 'range': (955, 1324)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '32ce8fecb7aad9f3a5a1a9b8a32f50b1'}>,\n",
      "                     <Document: {'content': 'This view allows users to explore the system’s functionalities without triggering consequential outcomes. However, the challenge lies in explaining the interdependencies between features and predicted outcomes. As a solution, the interface is split into two parts: the left side displaying the distinct features, and the right side showing the corresponding prediction. This division enables accurate visualization of both: one-to-one relations, where a single feature combination results in one prediction, and one-to-many relations, where one prediction can stem from multiple feature combinations.\\nUpon entering the simulation view, each feature is presented as an individual interactive element allowing users to adjust its value. Any adjustments made to these features trigger immediate feedback as alterations in the prediction on the right side of the screen whereby users can witness the effect it has in real time. Further, users can tailor their experience by selectively enabling the features they wish to observe, through toggling the feature list on the left side of the screen.\\n\\nWithin the simulation view, users can also switch directions to modify the predicted outcome. The left side of the screen serves as a platform for providing a comprehensive explanation of the prediction, showcasing two categories of prototypical examples. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 18, '_split_overlap': [{'doc_id': '32ce8fecb7aad9f3a5a1a9b8a32f50b1', 'range': (0, 369)}, {'doc_id': 'aa98a9bc889bb68a7f47f68a4e7aac2b', 'range': (924, 1348)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '4b661283bb898ef6c6392c3cf4e5c4d9'}>,\n",
      "                     <Document: {'content': 'Further, users can tailor their experience by selectively enabling the features they wish to observe, through toggling the feature list on the left side of the screen.\\n\\nWithin the simulation view, users can also switch directions to modify the predicted outcome. The left side of the screen serves as a platform for providing a comprehensive explanation of the prediction, showcasing two categories of prototypical examples. Firstly, the system generates instances based on the AI model, illustrating similar scenarios resulting in the same demand prediction. Beneath these, specific instances of comparable past sales are displayed, underscoring similar sales achieved under analogous conditions.\\nTo customize the required explanation, users have the option to lock features within the feature list on the left, thus limiting the set of possible examples and accounting for the fact that not all features are alterable.\\n\\nBy adjusting the predicted outcome, the system promptly responds with new examples on the left side, providing a range of instances, both generated by the AI and drawn from comparable past demand. Being alternative scenarios to the initial prediction those are explained by counterfactual examples, illustrating the smallest change required to produce an alternative outcome. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 19, '_split_overlap': [{'doc_id': '4b661283bb898ef6c6392c3cf4e5c4d9', 'range': (0, 424)}, {'doc_id': '5f2543f7669c1e75f95beb9d73784571', 'range': (922, 1297)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'aa98a9bc889bb68a7f47f68a4e7aac2b'}>,\n",
      "                     <Document: {'content': 'By adjusting the predicted outcome, the system promptly responds with new examples on the left side, providing a range of instances, both generated by the AI and drawn from comparable past demand. Being alternative scenarios to the initial prediction those are explained by counterfactual examples, illustrating the smallest change required to produce an alternative outcome. To make this change immediately apparent to the user,\\xa0 the feature value responsible for this outcome is visually highlighted with a red background.\\n\\nPhase 4: Evaluation\\nQualitatively evaluating the interface with real end users revealed that, first and foremost, feature visualization, highlighting the corresponding features influencing a forecast, plays a pivotal role in enhancing users‘ understanding of AI-based predictions. This insight underscores the importance of integrating visual representations of such features in user-centric interfaces, as it enriches the interpretability of AI predictions. Additionally, the interactive simulation view emerges as a helpful tool for explaining the interplay of features and their impact on the predicted outcome. This view empowers users to explore, experiment, and adjust variables, providing them with a profound sense of control over the process.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 20, '_split_overlap': [{'doc_id': 'aa98a9bc889bb68a7f47f68a4e7aac2b', 'range': (0, 375)}, {'doc_id': 'a4f57b9f38d594d33bdcf71a513a9cc8', 'range': (807, 1277)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5f2543f7669c1e75f95beb9d73784571'}>,\n",
      "                     <Document: {'content': 'This insight underscores the importance of integrating visual representations of such features in user-centric interfaces, as it enriches the interpretability of AI predictions. Additionally, the interactive simulation view emerges as a helpful tool for explaining the interplay of features and their impact on the predicted outcome. This view empowers users to explore, experiment, and adjust variables, providing them with a profound sense of control over the process.\\nThe inclusion of prototypical examples showcasing instances of past sales that closely resemble the initial forecast also contributes to increasing user trust. These examples provide tangible evidence supporting the AI’s predictions and serve as a significant factor in building confidence among users. Furthermore, end users consistently express a desire for a visual reflection of the AI system’s past performance in terms of prediction quality. This emerged as an important insight that will be integrated within further iterations. This should be part of user-centric, explainable interfaces to calibrate trust in AI systems appropriately.\\nMoreover, integrating counterfactual examples in user interfaces turned out as a promising approach for increasing confidence and insight in AI predictions. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 21, '_split_overlap': [{'doc_id': '5f2543f7669c1e75f95beb9d73784571', 'range': (0, 470)}, {'doc_id': 'c346940eb03d241bd3f8afaf0f078a5d', 'range': (774, 1271)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'a4f57b9f38d594d33bdcf71a513a9cc8'}>,\n",
      "                     <Document: {'content': 'Furthermore, end users consistently express a desire for a visual reflection of the AI system’s past performance in terms of prediction quality. This emerged as an important insight that will be integrated within further iterations. This should be part of user-centric, explainable interfaces to calibrate trust in AI systems appropriately.\\nMoreover, integrating counterfactual examples in user interfaces turned out as a promising approach for increasing confidence and insight in AI predictions. This method not only explains AI predictions but also serves as actionable recommendations for end users when feature values are alterable and visually highlighted. One particularly promising application is the efficient management of remaining products, especially those nearing expiration or prone to spoilage. This approach not only generates revenue but also minimizes waste.\\nWhat now?\\nThe pace at which technology is advancing suggests that AI will continue having a substantial impact on orchestrating processes in retail. While automation plays a significant role in retail, humans remain accountable for decision-making. To ensure successful collaboration between humans and AI, it is necessary to design their interaction thoughtfully.\\nAchieving transparency in black-box models undoubtedly requires algorithmic-centric progress in XAI. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 22, '_split_overlap': [{'doc_id': 'a4f57b9f38d594d33bdcf71a513a9cc8', 'range': (0, 497)}, {'doc_id': 'e83d36aec9100d972ed6dc7da4e065ab', 'range': (888, 1343)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'c346940eb03d241bd3f8afaf0f078a5d'}>,\n",
      "                     <Document: {'content': 'The pace at which technology is advancing suggests that AI will continue having a substantial impact on orchestrating processes in retail. While automation plays a significant role in retail, humans remain accountable for decision-making. To ensure successful collaboration between humans and AI, it is necessary to design their interaction thoughtfully.\\nAchieving transparency in black-box models undoubtedly requires algorithmic-centric progress in XAI. Yet, it must be accompanied by a human-centered approach to effectively realize what we inherently mirror: an interactive knowledge exchange between an agent and human users.\\nFollowing a user-centered design process allows for identifying the recipient-specific explainability needs and requirements for the given use case. Moreover, an explorative approach through interactive user interfaces enhances the user’s need for control while fostering understanding and trust of the system’s capabilities and limitations.\\nFailing to address user needs and expectations regarding explainability ultimately causes neglect of advanced systems. Therefore, optimizing for user acceptance through a human-centered XAI approach becomes not just a recommendation but a strategic necessity for the future of AI in retail and other industries.\\n\\nHör in unseren aktuellen Podcast zum Thema Explainable AI rein!\\n\\nZum Podcast', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/explainable-ai-as-a-user-centered-design-approach/', 'authors': ['Alina Döring'], 'date': '12.01.2024', 'title': 'Explainable AI as a User-Centered Design Approach', '_split_id': 23, '_split_overlap': [{'doc_id': 'c346940eb03d241bd3f8afaf0f078a5d', 'range': (0, 455)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'e83d36aec9100d972ed6dc7da4e065ab'}>,\n",
      "                     <Document: {'content': 'Dieser Blog-Artikel widmet sich der Frage, wie sich die Verantwortung in agilen Teams ändert, wenn eine Künstliche Intelligenz als „Entwickler:in“ Teil des Teams ist.\\n„Bei meinem Ticket fehlt noch eine Genehmigung im Code Review. Alex, könntest du dich darum kümmern?“\\n„Wir haben auffällige Fehler auf der Produktion. Alex, die letzte Änderung stammt von dir. Was sollen wir am besten machen?“\\nNormale Sätze in einem Team, das ein Softwareprodukt entwickelt und betreibt. Das Team arbeitet eng zusammen und ist gemeinsam für das Produkt verantwortlich. Die Teammitglieder verlassen sich aufeinander.\\nAber was ist, wenn Alex kein Mensch, sondern eine künstliche Intelligenz ist? Kann ein Team Verantwortung übernehmen, wenn Teammitglieder künstliche Intelligenzen sind?\\ntl;dr: Ob KI-gemischte Teams ein Verantwortungsgefühl erzeugen können, bleibt unklar. Ich denke jedoch, dass es schwieriger wird, Motivation in den Teams hochzuhalten.\\n\\nStufen der ZusammenarbeitKI-Unterstützung in TeamsEigentlich ändert sich nichts. Oder?Die KI als TeammitgliedEigentlich ändert sich wieder nichts. Oder?Quellen\\nStufen der Zusammenarbeit\\nIn seinem Gedankenexperiment, wie sich KI auf Entwicklungsteam auswirken kann, definiert Henrik Kniberg 5 Phasen:\\n\\nKI unterstützt die Menschen als Assistenzsystem. Auf Anfrage generiert die KI Code, reviewed Code oder unterstützt andere Aktivitäten, immer vom Menschen initiiert.\\nKI ist Mitglied des Entwicklungsteams. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/', 'authors': ['Marc Wolter'], 'date': '16.02.2024', 'title': 'Verantwortung in KI-gemischten Teams: Was passiert, wenn die KI mitarbeitet?', '_split_id': 0, '_split_overlap': [{'doc_id': '21e5f982bbf5f0f110e9e05174f19a4e', 'range': (1019, 1442)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'bb78d74cd28b4db44ce3368e74677d97'}>,\n",
      "                     <Document: {'content': 'Oder?Die KI als TeammitgliedEigentlich ändert sich wieder nichts. Oder?Quellen\\nStufen der Zusammenarbeit\\nIn seinem Gedankenexperiment, wie sich KI auf Entwicklungsteam auswirken kann, definiert Henrik Kniberg 5 Phasen:\\n\\nKI unterstützt die Menschen als Assistenzsystem. Auf Anfrage generiert die KI Code, reviewed Code oder unterstützt andere Aktivitäten, immer vom Menschen initiiert.\\nKI ist Mitglied des Entwicklungsteams. D.h. sie nimmt an Design- und Planungs-Meetings teil, nimmt den Kontext auf, entwickelt eigene Lösungen für die besprochenen Probleme, reviewed Code von Team-Mitgliedern etc.\\nKleinere Entwicklungsteams formen sich. Durch die Geschwindigkeit der KI und dem gewonnenen Vertrauen reichen Zweier-Teams aus: eine KI und ein Mensch, die sich eng miteinander abstimmen.\\nEs gibt keine Entwicklungsteams mehr. Die Anforderungen gehen direkt an die KI, ohne einen Menschen, der sie steuert oder kontrolliert.\\nEs gibt keinen Source-Code mehr. Ohne Menschen in der Entwicklungsschleife wird Source Code obsolet, weil die KI auch direkt Maschinencode schreiben (und lesen) kann.\\n\\nFür diesen Artikel schauen wir uns Phase 1 (KI-Unterstützung in Teams) und die beiden Phasen 2 und 3 (Die KI als Teammitglied) an. Ohne Teams braucht es auch keine Team-Verantwortung mehr.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/', 'authors': ['Marc Wolter'], 'date': '16.02.2024', 'title': 'Verantwortung in KI-gemischten Teams: Was passiert, wenn die KI mitarbeitet?', '_split_id': 1, '_split_overlap': [{'doc_id': 'bb78d74cd28b4db44ce3368e74677d97', 'range': (0, 423)}, {'doc_id': '5b520a3ac0393fc86df6ea2bf06420f', 'range': (956, 1279)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '21e5f982bbf5f0f110e9e05174f19a4e'}>,\n",
      "                     <Document: {'content': 'Ohne Menschen in der Entwicklungsschleife wird Source Code obsolet, weil die KI auch direkt Maschinencode schreiben (und lesen) kann.\\n\\nFür diesen Artikel schauen wir uns Phase 1 (KI-Unterstützung in Teams) und die beiden Phasen 2 und 3 (Die KI als Teammitglied) an. Ohne Teams braucht es auch keine Team-Verantwortung mehr.\\nKI-Unterstützung in Teams\\nSolange Alex als Assistenzsystem die menschlichen Teammitglieder unterstützt, verhält es sich wie jede andere technische Unterstützung wie Build-Systeme oder Orchestratoren.\\nDie Verantwortung liegt weiterhin bei den individuellen Menschen, und das Verantwortungsgefühl des Teams bleibt intakt.\\nGenau wie mit zuverlässigen Automatisierungssystemen beginnen die Teammitglieder Alex durch positive Erfahrungen zu vertrauen.\\nEigentlich ändert sich nichts. Oder?\\nWas würde passieren, wenn Alex die Funktion des Code Reviews automatisiert? Sehr sicher wird Alex Code viel schneller und vor allem ohne Wartezeit überprüfen, als dies Menschen tun könnten. Wahrscheinlich wird auch die Qualität des Reviews irgendwann akzeptabel sein, sodass die Funktion im Team komplett von Alex übernommen werden kann … kein Warten auf Genehmigungen mehr, kein Nachfragen, ob sich jemand dafür Zeit nimmt, und trotzdem kein Qualitätsverlust.\\nWäre es für euer Team akzeptabel, wenn eine Person alle Reviews durchführt? Was verloren geht, ist die Übersicht über den erzeugten Code der anderen Teammitglieder.\\xa0', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/', 'authors': ['Marc Wolter'], 'date': '16.02.2024', 'title': 'Verantwortung in KI-gemischten Teams: Was passiert, wenn die KI mitarbeitet?', '_split_id': 2, '_split_overlap': [{'doc_id': '21e5f982bbf5f0f110e9e05174f19a4e', 'range': (0, 323)}, {'doc_id': 'f45282fdccb43d6a639caa34b1add77b', 'range': (998, 1433)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5b520a3ac0393fc86df6ea2bf06420f'}>,\n",
      "                     <Document: {'content': 'Wahrscheinlich wird auch die Qualität des Reviews irgendwann akzeptabel sein, sodass die Funktion im Team komplett von Alex übernommen werden kann … kein Warten auf Genehmigungen mehr, kein Nachfragen, ob sich jemand dafür Zeit nimmt, und trotzdem kein Qualitätsverlust.\\nWäre es für euer Team akzeptabel, wenn eine Person alle Reviews durchführt? Was verloren geht, ist die Übersicht über den erzeugten Code der anderen Teammitglieder.\\xa0XP hat die Idee des collective ownership eingeführt: jede:r Entwickler:in kann jede Codezeile verändern und neue Funktionalitäten hinzufügen.\\nTrotz Tests als Sicherheitsnetz übernehmen Teammitglieder nicht gerne Verantwortung für Bereiche, die sie nicht kennen. Wenn nur Alex Code Reviews übernimmt, kann es sein, dass sich das Team von der gemeinsamen Code-Basis distanziert. Was wiederum negative Auswirkungen auf die gemeinsame Verantwortlichkeit für das Produkt hat (“Das hast Du doch gebaut, ich weiß nicht wie ich das fixe“). Das übrige Team muss es schaffen, trotz KI-Unterstützung die Code-Basis als ihre eigene anzusehen und Verantwortung für diese zu übernehmen.\\nDie KI als Teammitglied\\nWas passiert mit der Team-Verantwortung, wenn Alex „vollwertiges“ Teammitglied ist, also die gleiche individuelle Verantwortung wie die anderen Mitglieder bekommt?\\nLaut [de Leede et al. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/', 'authors': ['Marc Wolter'], 'date': '16.02.2024', 'title': 'Verantwortung in KI-gemischten Teams: Was passiert, wenn die KI mitarbeitet?', '_split_id': 3, '_split_overlap': [{'doc_id': '5b520a3ac0393fc86df6ea2bf06420f', 'range': (0, 435)}, {'doc_id': '693626ff32f1d0644f37e206b63b9134', 'range': (813, 1318)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'f45282fdccb43d6a639caa34b1add77b'}>,\n",
      "                     <Document: {'content': 'Was wiederum negative Auswirkungen auf die gemeinsame Verantwortlichkeit für das Produkt hat (“Das hast Du doch gebaut, ich weiß nicht wie ich das fixe“). Das übrige Team muss es schaffen, trotz KI-Unterstützung die Code-Basis als ihre eigene anzusehen und Verantwortung für diese zu übernehmen.\\nDie KI als Teammitglied\\nWas passiert mit der Team-Verantwortung, wenn Alex „vollwertiges“ Teammitglied ist, also die gleiche individuelle Verantwortung wie die anderen Mitglieder bekommt?\\nLaut [de Leede et al. 1999] muss das Team ein collective mind formen, um gemeinsam Verantwortung zu übernehmen. Dabei sind die Interaktionen und Beziehungen der Teammitglieder zueinander wichtiger als individuelle Fähigkeiten.\\nFolgende Bedingungen sieht de Leede, damit sich dieser Zustand einstellen kann:\\n\\nVerpflichtung für eine wichtige kollektive Aufgabe\\nAchtsamer Umgang miteinander (Sorgfalt, Vertrauen, Respekt, Selbstverpflichtung sowie Redundanz der Funktionen – bereit und in der Lage, andere zu ersetzen, wenn es nötig ist)\\nLange und starke kollektive Erfahrungen in der Zusammenarbeit (Sprache/Zeichen/Verhaltensweisen haben ein gemeinsames und klares Verständnis)\\n\\nAlex ist respektvoll und kann alle Funktionen ausführen (Bedingung 2). Die gemeinsamen positiven Erfahrungen zwischen Alex und den menschlichen Team-Mitgliedern sind durch die maximale Länge des Kontextes, also quasi Alex Gedächtnis, begrenzt. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/', 'authors': ['Marc Wolter'], 'date': '16.02.2024', 'title': 'Verantwortung in KI-gemischten Teams: Was passiert, wenn die KI mitarbeitet?', '_split_id': 4, '_split_overlap': [{'doc_id': 'f45282fdccb43d6a639caa34b1add77b', 'range': (0, 505)}, {'doc_id': 'c1a7978b1deae69cfa931910c0448758', 'range': (711, 1405)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '693626ff32f1d0644f37e206b63b9134'}>,\n",
      "                     <Document: {'content': 'Folgende Bedingungen sieht de Leede, damit sich dieser Zustand einstellen kann:\\n\\nVerpflichtung für eine wichtige kollektive Aufgabe\\nAchtsamer Umgang miteinander (Sorgfalt, Vertrauen, Respekt, Selbstverpflichtung sowie Redundanz der Funktionen – bereit und in der Lage, andere zu ersetzen, wenn es nötig ist)\\nLange und starke kollektive Erfahrungen in der Zusammenarbeit (Sprache/Zeichen/Verhaltensweisen haben ein gemeinsames und klares Verständnis)\\n\\nAlex ist respektvoll und kann alle Funktionen ausführen (Bedingung 2). Die gemeinsamen positiven Erfahrungen zwischen Alex und den menschlichen Team-Mitgliedern sind durch die maximale Länge des Kontextes, also quasi Alex Gedächtnis, begrenzt. Um die Idee eines KI-Entwicklers zu ermöglichen, nehmen wir hier an, dass ein relevanter Kontext gesammelt werden kann, der alle wichtigen Erfahrungen für Teammitglieder einschließt – sowohl generelle Teamvereinbarungen und Architekturprinzipien, als auch Story- oder domänenspezifische Informationen (Bedingung 3). Aber kann sich Alex für eine kollektive Aufgabe verpflichten?\\nFrage ich ChatGPT (GPT-3.5) danach, so lautet die Antwort:\\n„…dass ich als KI-System immer auf die Anweisungen, Überwachung und das Fachwissen der menschlichen Entwickler angewiesen bin. ', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/', 'authors': ['Marc Wolter'], 'date': '16.02.2024', 'title': 'Verantwortung in KI-gemischten Teams: Was passiert, wenn die KI mitarbeitet?', '_split_id': 5, '_split_overlap': [{'doc_id': '693626ff32f1d0644f37e206b63b9134', 'range': (0, 694)}, {'doc_id': '423f97d5ba4c60e6fff6cd93f09dc8cd', 'range': (695, 1258)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': 'c1a7978b1deae69cfa931910c0448758'}>,\n",
      "                     <Document: {'content': 'Um die Idee eines KI-Entwicklers zu ermöglichen, nehmen wir hier an, dass ein relevanter Kontext gesammelt werden kann, der alle wichtigen Erfahrungen für Teammitglieder einschließt – sowohl generelle Teamvereinbarungen und Architekturprinzipien, als auch Story- oder domänenspezifische Informationen (Bedingung 3). Aber kann sich Alex für eine kollektive Aufgabe verpflichten?\\nFrage ich ChatGPT (GPT-3.5) danach, so lautet die Antwort:\\n„…dass ich als KI-System immer auf die Anweisungen, Überwachung und das Fachwissen der menschlichen Entwickler angewiesen bin. Ich kann keine eigenständigen strategischen Entscheidungen treffen, ethische Fragen klären oder menschliche Kreativität und Einsicht ersetzen…..\\nEs ist jedoch wichtig zu betonen, dass die Wirksamkeit eines kollektiven Geistes stark von der Qualität der Zusammenarbeit und Kommunikation innerhalb der Gruppe abhängt. Die Entwickler müssen aktiv Ideen austauschen, Informationen teilen und auf die Vorschläge und Analysen, die von der KI bereitgestellt werden, reagieren. Die KI kann als Werkzeug und Ressource dienen, um die kollektive Intelligenz zu erweitern, aber letztendlich sind die menschlichen Entwickler entscheidend für den Erfolg dieses Konzepts.“\\n\\nAktuell sieht sich zumindest eine KI eher in einer unterstützenden Rolle und nicht als Teammitglied mit Verantwortung.\\nAngenommen, Alex hätte all diese Fähigkeiten und es formt sich ein Collective Mind – das gesamte Team inklusive KI übernimmt also Verantwortung.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/', 'authors': ['Marc Wolter'], 'date': '16.02.2024', 'title': 'Verantwortung in KI-gemischten Teams: Was passiert, wenn die KI mitarbeitet?', '_split_id': 6, '_split_overlap': [{'doc_id': 'c1a7978b1deae69cfa931910c0448758', 'range': (0, 563)}, {'doc_id': '5c7fd8e36384cd00c3c01c323c5f25a9', 'range': (1034, 1486)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '423f97d5ba4c60e6fff6cd93f09dc8cd'}>,\n",
      "                     <Document: {'content': 'Die KI kann als Werkzeug und Ressource dienen, um die kollektive Intelligenz zu erweitern, aber letztendlich sind die menschlichen Entwickler entscheidend für den Erfolg dieses Konzepts.“\\n\\nAktuell sieht sich zumindest eine KI eher in einer unterstützenden Rolle und nicht als Teammitglied mit Verantwortung.\\nAngenommen, Alex hätte all diese Fähigkeiten und es formt sich ein Collective Mind – das gesamte Team inklusive KI übernimmt also Verantwortung.\\nEigentlich ändert sich wieder nichts. Oder?\\nAlex kann schneller Code schreiben als jeder Mensch. Stellt euch vor, in eurem Team ist ein Star, der jede Aufgabe schneller und besser als ihr löst. So schnell, dass es keinen Sinn für euch macht, es selbst zu versuchen. Und zwar nicht nur Routineaufgaben, sondern auch schwierige Aufgaben und Designs. Alex ist schnell genug, um mehrere Design-Alternativen parallel zu entwickeln und die beste auszuwählen (sog. Set-Based Design).\\nDie Menschen erhalten zudem die neue Aufgabe, Alex gute Anweisungen auf Basis ihres Fachwissens zu geben und die Ergebnisse zu überwachen (Phase 3). Henrik Kniberg hofft, dass Entwickler:innen durch die Arbeit mit den Stakeholdern oder Wissensaustausch mit anderen Entwickler:innen nicht einsam werden. Er argumentiert, dass es ja die Zusammenarbeit mit den Stakeholdern und anderen Entwickler:innen-KI-Paaren gibt, z. B. für gemeinsame Demos.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/', 'authors': ['Marc Wolter'], 'date': '16.02.2024', 'title': 'Verantwortung in KI-gemischten Teams: Was passiert, wenn die KI mitarbeitet?', '_split_id': 7, '_split_overlap': [{'doc_id': '423f97d5ba4c60e6fff6cd93f09dc8cd', 'range': (0, 452)}, {'doc_id': '81837ffb3d2c7c26f5e00a76c62325b7', 'range': (930, 1373)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '5c7fd8e36384cd00c3c01c323c5f25a9'}>,\n",
      "                     <Document: {'content': 'Die Menschen erhalten zudem die neue Aufgabe, Alex gute Anweisungen auf Basis ihres Fachwissens zu geben und die Ergebnisse zu überwachen (Phase 3). Henrik Kniberg hofft, dass Entwickler:innen durch die Arbeit mit den Stakeholdern oder Wissensaustausch mit anderen Entwickler:innen nicht einsam werden. Er argumentiert, dass es ja die Zusammenarbeit mit den Stakeholdern und anderen Entwickler:innen-KI-Paaren gibt, z. B. für gemeinsame Demos.\\nIch denke, dass Stakeholder-Treffen und qualitätssichernde Maßnahmen nicht gerade die Dinge sind, von denen die meisten Software-Entwickler:innen mit Begeisterung sprechen. Viele lösen gerne knifflige Probleme und entwerfen passende Lösungen. Aber mit steigenden Fähigkeiten einer KI ist ihnen Alex genau in diesen Tätigkeiten irgendwann weit überlegen.\\nVielleicht werden die menschlichen Teammitglieder nicht einsam, wie Knieberg sagt. Aber ich glaube, wenn man Menschen die Tätigkeit nimmt, die sie gerne machen, verlieren sie schnell an Motivation. Sollte eine KI uns nicht unterstützen und Dinge tun, die wir nicht gerne tun, aber nicht die Tätigkeiten, die uns motivieren?\\nDie sinkende Motivation der menschlichen Entwickler:innen und das Gefühl, redundant zu sein, wird sich negativ auf das Verantwortungsgefühl (zumindest der Menschen) auswirken. Vielleicht kommt Phase 4 (keine Entwicklungs-Teams mehr) dann doch schneller als gedacht. Und dann hängt es an Alex, Verantwortung zu übernehmen.\\n', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/', 'authors': ['Marc Wolter'], 'date': '16.02.2024', 'title': 'Verantwortung in KI-gemischten Teams: Was passiert, wenn die KI mitarbeitet?', '_split_id': 8, '_split_overlap': [{'doc_id': '5c7fd8e36384cd00c3c01c323c5f25a9', 'range': (0, 443)}, {'doc_id': '3cf4bb2266c5322ed96e3dfe56e9ba1f', 'range': (996, 1443)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '81837ffb3d2c7c26f5e00a76c62325b7'}>,\n",
      "                     <Document: {'content': 'Sollte eine KI uns nicht unterstützen und Dinge tun, die wir nicht gerne tun, aber nicht die Tätigkeiten, die uns motivieren?\\nDie sinkende Motivation der menschlichen Entwickler:innen und das Gefühl, redundant zu sein, wird sich negativ auf das Verantwortungsgefühl (zumindest der Menschen) auswirken. Vielleicht kommt Phase 4 (keine Entwicklungs-Teams mehr) dann doch schneller als gedacht. Und dann hängt es an Alex, Verantwortung zu übernehmen.\\nQuellen\\n[de Leede et al. 1999] de Leede, Jan, Andre H. J. Nijhof, and Olf A. M. Fisscher. „The Myth of Self-Managing Teams: A Reflection on the Allocation of Responsibilities between Individuals, Teams and the Organisation.“ Journal of Business Ethics 21.2 (1999): 203-15', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.inovex.de/de/blog/verantwortung-in-ki-gemischten-teams-was-passiert-wenn-die-ki-mitarbeitet/', 'authors': ['Marc Wolter'], 'date': '16.02.2024', 'title': 'Verantwortung in KI-gemischten Teams: Was passiert, wenn die KI mitarbeitet?', '_split_id': 9, '_split_overlap': [{'doc_id': '81837ffb3d2c7c26f5e00a76c62325b7', 'range': (0, 447)}]}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (384,)>', 'id': '3cf4bb2266c5322ed96e3dfe56e9ba1f'}>],\n",
      "    'node_id': 'document_store',\n",
      "    'params': {},\n",
      "    'root_node': 'File'}\n"
     ]
    }
   ],
   "source": [
    "# Print all documents that have been created\n",
    "pp.pprint(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (Snippet) Count: 1705\n"
     ]
    }
   ],
   "source": [
    "print(\"Document (Snippet) Count:\", len(document_store.get_all_documents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question Answering : Query PIpeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot validate index for custom mappings. Skipping index validation.\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import EmbeddingRetriever\n",
    "from haystack import Pipeline\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"embedding\": {\"type\": \"dense_vector\", \"dims\": 384},\n",
    "            \"authors\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"keyword\"},\n",
    "            \"date\": {\n",
    "                \"type\":   \"date\",\n",
    "                \"format\": \"dd.MM.yyyy\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Connect documentstore\n",
    "document_store = ElasticsearchDocumentStore(index=\"blogs_clean1\", custom_mapping=mapping)\n",
    "\n",
    "# Define nodes\n",
    "retriever = EmbeddingRetriever(\n",
    "        embedding_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        document_store=document_store,\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "query_pipe = Pipeline()\n",
    "query_pipe.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])    # Searches for relevant `documents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. The significant difference is that we receive two results from the neural network and have two labels for computing the loss. It is important to incorporate both outputs in the training process and to ensure that the outputs and the weights of both new encoder heads, given that the weight initialization is equal for all components, also differ from each other.\n",
      "During training, we calculated the loss for each single encoder output and then used the maximum of both to punish the model for the worse performing head and thus making the learning process more challenging. We chose the Cross-Entropy loss function and obtained the following equations for the loss:\n",
      "CE(Y, Ȳ) = –∑yi ·log ȳi\n",
      "Lk = CE(Yk, Ȳk}),     k ∈ (1, 2)\n",
      "LE = max(L1, L2)\n",
      "where CE(Y, Ȳ) is the Cross-Entropy loss function, Lk denotes the loss that the k-th encoder head causes. Note that Lk includes the output from the decoder instead of only the encoder head. \n",
      "\n",
      "1. We chose the Cross-Entropy loss function and obtained the following equations for the loss:\n",
      "CE(Y, Ȳ) = –∑yi ·log ȳi\n",
      "Lk = CE(Yk, Ȳk}),     k ∈ (1, 2)\n",
      "LE = max(L1, L2)\n",
      "where CE(Y, Ȳ) is the Cross-Entropy loss function, Lk denotes the loss that the k-th encoder head causes. Note that Lk includes the output from the decoder instead of only the encoder head. We then acquire the loss LE as described above with the label Ȳk for person k. We compared the similarity between the encoded outputs and multiplied them with a penalizing parameter γ, which acts as a weight for considering the similarity in the loss function. We sum the product with LE to penalize the learning process accordingly if the outputs are too similar.\n",
      "S = mean(SIM(H1, H2))\n",
      "L = LE + γS\n",
      "SIM is the similarity function from which we additionally calculate the mean for the score S to be a scalar still representative of similarity. For SIM we chose cosine similarity. This computes the total loss L from which it is now possible to acquire the training gradients.\n",
      "Setup\n",
      "For training, we used the weights from the pre-trained CODS architecture. \n",
      "\n",
      "2. Again, we used a BART decoder for fine-tuning from the works CODS which has been trained on the SAMSum datasets. The following equation completes the encoder-decoder process of our approach:\n",
      "Yk = DBART(Hk)\n",
      "Yk = (y0,k, …, ym,k),     k ∈ (1, 2)\n",
      "\n",
      "Ykis the sequence of tokens yi,k for person k acquired from the decoder DBART. The decoder processed the encodings Hk from each of the k heads separately. In our environment, H1 and H2 as well as Y1 and Y2 were not computed concurrently but sequentially.\n",
      "Training\n",
      "Loss function\n",
      "Since we have two different outputs for the DialogSum dataset, conventional training and computation of the loss are not possible. The significant difference is that we receive two results from the neural network and have two labels for computing the loss. It is important to incorporate both outputs in the training process and to ensure that the outputs and the weights of both new encoder heads, given that the weight initialization is equal for all components, also differ from each other.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = query_pipe.run(\n",
    "    query=\"Tell me about Loss functions in Machine Learning?\", params={\"Retriever\": {\"top_k\": 3}}\n",
    ")\n",
    "\n",
    "for idx, doc in enumerate(retrieved_docs[\"documents\"]):\n",
    "    print(f\"{idx}. \" + doc.content + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Reader model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot validate index for custom mappings. Skipping index validation.\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import EmbeddingRetriever, FARMReader\n",
    "from haystack import Pipeline\n",
    "from haystack.utils import print_answers\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"embedding\": {\"type\": \"dense_vector\", \"dims\": 384},\n",
    "            \"authors\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"keyword\"},\n",
    "            \"date\": {\n",
    "                \"type\":   \"date\",\n",
    "                \"format\": \"dd.MM.yyyy\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Connect documentstore\n",
    "document_store = ElasticsearchDocumentStore(index=\"blogs_clean1\", custom_mapping=mapping)\n",
    "\n",
    "# Define nodes\n",
    "retriever = EmbeddingRetriever(\n",
    "        embedding_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        document_store=document_store,\n",
    ")\n",
    "\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=False)\n",
    "\n",
    "# Define pipeline\n",
    "query_pipe = Pipeline()\n",
    "query_pipe.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])    # Searches for relevant `documents`\n",
    "query_pipe.add_node(component=reader, name=\"Reader\", inputs=[\"Retriever\"])      # Extract top answers from retrieved documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.74s/ Batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: Tell me about Loss functions in nerual networks?'\n",
      "'Answers:'\n",
      "[   <Answer {'answer': 'two labels', 'type': 'extractive', 'score': 0.3192610740661621, 'context': 'rence is that we receive two results from the neural network and have two labels for computing the loss. It is important to incorporate both outputs i', 'offsets_in_document': [{'start': 91, 'end': 101}], 'offsets_in_context': [{'start': 70, 'end': 80}], 'document_ids': ['433d4507782aed5e9e4a49c16e07df4c'], 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 40, '_split_overlap': [{'doc_id': 'b705f8e514a3f127328414daea753d44', 'range': [0, 362]}, {'doc_id': '193b00b5b855711ca96fde93155c27b1', 'range': [573, 928]}]}}>,\n",
      "    <Answer {'answer': 'Cross-Entropy loss function and obtained the following equations', 'type': 'extractive', 'score': 0.06748863309621811, 'context': 'We chose the Cross-Entropy loss function and obtained the following equations for the loss:\\nCE(Y, Ȳ) = –∑yi ·log ȳi\\nLk = CE(Yk, Ȳk}),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\nL', 'offsets_in_document': [{'start': 13, 'end': 77}], 'offsets_in_context': [{'start': 13, 'end': 77}], 'document_ids': ['193b00b5b855711ca96fde93155c27b1'], 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 41, '_split_overlap': [{'doc_id': '433d4507782aed5e9e4a49c16e07df4c', 'range': [0, 355]}, {'doc_id': '9b39b2ed5b0e78c4325029bec100c863', 'range': [721, 1110]}]}}>,\n",
      "    <Answer {'answer': 'converging loss curves', 'type': 'extractive', 'score': 0.044626835733652115, 'context': 'nimized loss on both training and validation sets, resulting in converging loss curves that were approximating 0. However, the validation and similari', 'offsets_in_document': [{'start': 880, 'end': 902}], 'offsets_in_context': [{'start': 64, 'end': 86}], 'document_ids': ['159809a76ce0e031a900a54e99edddf5'], 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 43, '_split_overlap': [{'doc_id': '9b39b2ed5b0e78c4325029bec100c863', 'range': [0, 356]}, {'doc_id': '3749912a8c41aabd4ccde4d10bc47cf0', 'range': [930, 1249]}]}}>,\n",
      "    <Answer {'answer': 'embeddings that lie between the targets for Person1 and Person2', 'type': 'extractive', 'score': 0.0320533849298954, 'context': 'assume that the architecture tried to learn embeddings that lie between the targets for Person1 and Person2, thus reducing the loss but increasing the', 'offsets_in_document': [{'start': 518, 'end': 581}], 'offsets_in_context': [{'start': 44, 'end': 107}], 'document_ids': ['ca9e5e408f5b2d528e13e90b48a85665'], 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 50, '_split_overlap': [{'doc_id': '3c6dcfb5e812f06f6a1a5fac86283db3', 'range': [0, 470]}, {'doc_id': 'd27208d7013c86528719d3809f0a1c0f', 'range': [635, 1130]}]}}>,\n",
      "    <Answer {'answer': '#Person2# tells #Person1# it helps to save money on fares', 'type': 'extractive', 'score': 0.02657313644886017, 'context': '#Person2# tells #Person1# it helps to save money on fares, and #Person1#’ll think about it.\\n}Architecture\\nMulti-headed neural networks have an adequat', 'offsets_in_document': [{'start': 0, 'end': 57}], 'offsets_in_context': [{'start': 0, 'end': 57}], 'document_ids': ['5877061fd8805811b779ec0db94edb2a'], 'meta': {'url': 'https://www.inovex.de/de/blog/perspective-dialogue-summarization-with-neural-networks/', 'authors': ['Thien Quang Nguyen'], 'date': '14.09.2022', 'title': 'Perspective Dialogue Summarization with Neural Networks', '_split_id': 35, '_split_overlap': [{'doc_id': 'ddff458e141a9307e8305d5c44112507', 'range': [0, 321]}, {'doc_id': '11c0ad1665504525586f461753181d20', 'range': [676, 1139]}]}}>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = query_pipe.run(\n",
    "    query=\"Tell me about Loss functions in nerual networks?\", params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    ")\n",
    "\n",
    "print_answers(prediction, details=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: Tell me about Loss functions in nerual networks?'\n",
      "'Answers:'\n",
      "[   {   'answer': 'two labels',\n",
      "        'context': 'rence is that we receive two results from the neural '\n",
      "                   'network and have two labels for computing the loss. It is '\n",
      "                   'important to incorporate both outputs i'},\n",
      "    {   'answer': 'Cross-Entropy loss function and obtained the following '\n",
      "                  'equations',\n",
      "        'context': 'We chose the Cross-Entropy loss function and obtained the '\n",
      "                   'following equations for the loss:\\n'\n",
      "                   'CE(Y, Ȳ) = –∑yi ·log ȳi\\n'\n",
      "                   'Lk = CE(Yk, Ȳk}),\\xa0\\xa0\\xa0\\xa0 k ∈ (1, 2)\\n'\n",
      "                   'L'},\n",
      "    {   'answer': 'converging loss curves',\n",
      "        'context': 'nimized loss on both training and validation sets, '\n",
      "                   'resulting in converging loss curves that were '\n",
      "                   'approximating 0. However, the validation and similari'},\n",
      "    {   'answer': 'embeddings that lie between the targets for Person1 and '\n",
      "                  'Person2',\n",
      "        'context': 'assume that the architecture tried to learn embeddings '\n",
      "                   'that lie between the targets for Person1 and Person2, thus '\n",
      "                   'reducing the loss but increasing the'},\n",
      "    {   'answer': '#Person2# tells #Person1# it helps to save money on fares',\n",
      "        'context': '#Person2# tells #Person1# it helps to save money on fares, '\n",
      "                   'and #Person1#’ll think about it.\\n'\n",
      "                   '}Architecture\\n'\n",
      "                   'Multi-headed neural networks have an adequat'}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"minimum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do better - Integrating GPT (Replacing the Reader model by gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack.nodes import PromptModel, PromptNode\n",
    "\n",
    "load_dotenv(\"./.env\")\n",
    "\n",
    "api_key = os.environ.get(\"AZURE_API_KEY\")\n",
    "deployment_name = os.environ.get(\"AZURE_DEPLOYMENT_NAME\")\n",
    "base_url = os.environ.get(\"AZURE_BASE_URL\")\n",
    "\n",
    "# Init Model - Connects to Azure\n",
    "azure_model = PromptModel(\n",
    "    model_name_or_path=\"gpt-35-turbo\",\n",
    "    api_key=api_key,\n",
    "    model_kwargs={\n",
    "        \"azure_deployment_name\": deployment_name,\n",
    "        \"azure_base_url\": base_url,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Init PromptNode\n",
    "prompt_node = PromptNode(model_name_or_path=azure_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Haystack by deepset is an open-source framework for building search algorithms, with a focus on natural language processing and deep learning.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Test PromptNode\n",
    "\n",
    "# Construct Message\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant\"}]\n",
    "messages.append({\"role\": \"user\", \"content\": \"Tell me 1 sentence about haystack by deepset?\"})\n",
    "\n",
    "# Call PromptNode -> Calls OpenAI/Azure API\n",
    "result = prompt_node(messages)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot validate index for custom mappings. Skipping index validation.\n"
     ]
    }
   ],
   "source": [
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser\n",
    "from haystack.nodes import BM25Retriever\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(index=\"blogs_clean1\", custom_mapping=mapping)\n",
    "\n",
    "# Create nodes\n",
    "retriever = BM25Retriever(document_store=document_store)\n",
    "\n",
    "\n",
    "# PromptTemplate adds additional context to PromptNode\n",
    "qa_prompt = PromptTemplate(\n",
    "    prompt=\"\"\"Given the context, provide a short consise answer to the question.\n",
    "                Context: {join(documents)};\n",
    "                Question: {query};\n",
    "                Answer:\"\"\",\n",
    "    output_parser=AnswerParser(),\n",
    ")\n",
    "\n",
    "# Combine Azure Model with Prompt\n",
    "prompt_node = PromptNode(\n",
    "    model_name_or_path=azure_model,\n",
    "    default_prompt_template=qa_prompt\n",
    ")\n",
    "\n",
    "\n",
    "# Create Pipeline\n",
    "inovex_query_pipe = Pipeline()\n",
    "inovex_query_pipe.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "inovex_query_pipe.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: Tell me about Loss functions in nerual networks?'\n",
      "'Answers:'\n",
      "[   {   'answer': 'The Cross-Entropy loss function is commonly used in neural '\n",
      "                  'networks, and it was also used in the training process '\n",
      "                  'described in the given context. The loss function is used '\n",
      "                  'to calculate the error between predicted and actual '\n",
      "                  'outputs, and it is important to incorporate both outputs in '\n",
      "                  'the training process. The maximum of both outputs is used '\n",
      "                  'to punish the model for the worse performing head and make '\n",
      "                  'the learning process more challenging.'}]\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "\n",
    "output = inovex_query_pipe.run(query=\"Tell me about Loss functions in nerual networks?\", params={\"Retriever\": {\"top_k\": 3}})\n",
    "# print(output[\"answers\"][0].answer)\n",
    "print_answers(output, details=\"minimum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversations : Introducing Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Agent's Tools\n",
    "\n",
    "- inovex_query_pipeline (from before)\n",
    "- download Game of Thrones dataset\n",
    "- game_query_pipeline (Pipeline accesses 'Game of Thrones' database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot validate index for custom mappings. Skipping index validation.\n",
      "Converting files: 100%|██████████| 183/183 [00:01<00:00, 164.96it/s]\n",
      "Preprocessing:   0%|          | 0/183 [00:00<?, ?docs/s]We found one or more sentences whose split count is higher than the split length.\n",
      "Preprocessing: 100%|██████████| 183/183 [00:01<00:00, 156.24docs/s]\n",
      "Batches: 100%|██████████| 50/50 [00:34<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled documentstore\n"
     ]
    }
   ],
   "source": [
    "from haystack.pipelines import Pipeline\n",
    "import os\n",
    "from haystack.nodes import Crawler, EmbeddingRetriever, TextConverter, PreProcessor\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from helper_functions.preprocessor import CustomPreProcessor\n",
    "from haystack.utils import fetch_archive_from_http\n",
    "# Define nodes\n",
    "\n",
    "\n",
    "\n",
    "# Init documentstore with custom\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"embedding\": {\"type\": \"dense_vector\", \"dims\": 384},\n",
    "            \"authors\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"keyword\"},\n",
    "            \"date\": {\n",
    "                \"type\":   \"date\",\n",
    "                \"format\": \"dd.MM.yyyy\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(index=\"blogs_clean1\", custom_mapping=mapping)\n",
    "\n",
    "doc_dir = \"data/build_your_first_question_answering_system\"\n",
    "fetch_archive_from_http(\n",
    "    url=\"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt1.zip\",\n",
    "    output_dir=doc_dir,\n",
    ")\n",
    "\n",
    "textConverter = TextConverter()\n",
    "preProcessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=True,\n",
    "  \tremove_substrings=None,\n",
    "    split_by=\"word\",\n",
    "    split_length=300,                     # Split length abhaengig von Modell\n",
    "    split_respect_sentence_boundary=True, # Dont cut in the middle of sentence\n",
    "    split_overlap=0,                      # Overlap between Document splits (number corresponds to ~words?)\n",
    "  \tmax_chars_check = 15000\n",
    ")\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "        embedding_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        document_store=document_store,\n",
    ")\n",
    "\n",
    "\n",
    "# Define pipeline\n",
    "got_indexing_pipeline = Pipeline()\n",
    "got_indexing_pipeline.add_node(component=textConverter, name=\"TextConverter\", inputs=[\"File\"])            # .txt-File -> Document class\n",
    "got_indexing_pipeline.add_node(component=preProcessor, name=\"PreProcessor\", inputs=[\"TextConverter\"])     # Cleans & Splits documents\n",
    "got_indexing_pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"PreProcessor\"])            # Creates Embeddings\n",
    "got_indexing_pipeline.add_node(component=document_store, name=\"DocumentStore\", inputs=[\"Retriever\"])      # Stores documents\n",
    "\n",
    "\n",
    "# Execute pipeline\n",
    "files_to_index = [doc_dir + \"/\" + f for f in os.listdir(doc_dir)]\n",
    "got_indexing_pipeline.run(file_paths=files_to_index)\n",
    "\n",
    "print(\"Filled documentstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot validate index for custom mappings. Skipping index validation.\n"
     ]
    }
   ],
   "source": [
    "# Add PromptTemplate & Define Pipeline\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser, BM25Retriever\n",
    "\n",
    "# Init database\n",
    "document_store = ElasticsearchDocumentStore(index=\"blogs_clean1\", custom_mapping=mapping)\n",
    "\n",
    "# Create nodes\n",
    "# Create PromptTemplate with additinal context send PromptModel\n",
    "qa_prompt = PromptTemplate(\n",
    "    prompt=\"\"\"Given the context, answer the question in 1 or 2 sentences.\n",
    "                Context: {join(documents)};\n",
    "                Question: {query};\n",
    "                Answer:\"\"\",\n",
    "    output_parser=AnswerParser(),\n",
    ")\n",
    "\n",
    "# Combine PromptModel & PromptTemplate\n",
    "prompt_node = PromptNode(\n",
    "    model_name_or_path=azure_model,\n",
    "    default_prompt_template=qa_prompt\n",
    ")\n",
    "\n",
    "retriever = BM25Retriever(document_store=document_store)\n",
    "\n",
    "\n",
    "# Create Pipeline\n",
    "game_prompt_pipeline = Pipeline()\n",
    "game_prompt_pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "game_prompt_pipeline.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Retriever\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.agents.base import Tool\n",
    "from haystack.agents.conversational import ConversationalAgent\n",
    "from haystack.agents.memory import ConversationSummaryMemory\n",
    "\n",
    "inovex_blog_crawler_tool = Tool(\n",
    "    name=\"inovex_blog_crawler\",\n",
    "    pipeline_or_node=inovex_query_pipe,\n",
    "    description=\"useful for when you need to find content from the inovex blog\", # agent uses this for its decision!\n",
    "    output_variable=\"answers\",\n",
    ")\n",
    "\n",
    "got_qa_tool = Tool(\n",
    "    name=\"games_of_thrones_QA\",\n",
    "    pipeline_or_node=game_prompt_pipeline,\n",
    "    description=\"useful for when you need to answer questions about games of thrones\",\n",
    "    output_variable=\"answers\",\n",
    ")\n",
    "\n",
    "tools = [inovex_blog_crawler_tool, got_qa_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgill/miniconda/envs/meetup/lib/python3.12/site-packages/haystack/nodes/prompt/prompt_template.py:444: UserWarning: You're using a legacy prompt template 'conversational-summary', we strongly suggest you use prompts from the official Haystack PromptHub: https://prompthub.deepset.ai/\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conversational_agent_prompt_node = PromptNode(\n",
    "    model_name_or_path=azure_model,\n",
    "    max_length=256,\n",
    "    top_k=2,\n",
    "    stop_words=[\"Observation:\"], # react framework\n",
    "    model_kwargs={\"temperature\": 0.5, \"top_p\": 0.9}\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(conversational_agent_prompt_node, summary_frequency=2)\n",
    "\n",
    "zero_shot_agent_template = PromptTemplate(\"deepset/zero-shot-react\")\n",
    "\n",
    "agent = ConversationalAgent(\n",
    "    prompt_node=conversational_agent_prompt_node, prompt_template=zero_shot_agent_template, tools=tools, memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent deepset/zero-shot-react started with {'query': 'What can you tell me about loss functions?', 'params': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'transcript' parameter is missing from the Agent's prompt template. All ReAct agents that go through multiple steps to reach a goal require this parameter. Please append {transcript} to the end of the Agent's prompt template to ensure its proper functioning. A temporary prompt template with {transcript} appended will be used for this run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m in\u001b[0m\u001b[32mov\u001b[0m\u001b[32mex\u001b[0m\u001b[32m_blog\u001b[0m\u001b[32m_c\u001b[0m\u001b[32mrawler\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m \"\u001b[0m\u001b[32mloss\u001b[0m\u001b[32m functions\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m \n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m in\u001b[0m\u001b[32mov\u001b[0m\u001b[32mex\u001b[0m\u001b[32m_blog\u001b[0m\u001b[32m_c\u001b[0m\u001b[32mrawler\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m \"\u001b[0m\u001b[32mloss\u001b[0m\u001b[32m functions\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m \n",
      "\u001b[0mObservation: \u001b[33mThe chosen loss function is the Cross-Entropy loss function, and the loss is calculated separately for each encoder head. The maximum of the two losses is then used to compute the final loss. Additionally, a similarity score is calculated using cosine similarity and multiplied with a penalizing parameter to penalize the learning process if the outputs are too similar.\u001b[0m\n",
      "Thought: \u001b[32mFinal\u001b[0m\u001b[32m Answer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m The\u001b[0m\u001b[32m Cross\u001b[0m\u001b[32m-\u001b[0m\u001b[32mEntropy\u001b[0m\u001b[32m loss\u001b[0m\u001b[32m function\u001b[0m\u001b[32m is\u001b[0m\u001b[32m used\u001b[0m\u001b[32m and\u001b[0m\u001b[32m the\u001b[0m\u001b[32m similarity\u001b[0m\u001b[32m score\u001b[0m\u001b[32m is\u001b[0m\u001b[32m penal\u001b[0m\u001b[32mized\u001b[0m\u001b[32m if\u001b[0m\u001b[32m the\u001b[0m\u001b[32m outputs\u001b[0m\u001b[32m are\u001b[0m\u001b[32m too\u001b[0m\u001b[32m similar\u001b[0m\u001b[32m.\u001b[0m\u001b[32mFinal\u001b[0m\u001b[32m Answer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m The\u001b[0m\u001b[32m Cross\u001b[0m\u001b[32m-\u001b[0m\u001b[32mEntropy\u001b[0m\u001b[32m loss\u001b[0m\u001b[32m function\u001b[0m\u001b[32m is\u001b[0m\u001b[32m used\u001b[0m\u001b[32m,\u001b[0m\u001b[32m and\u001b[0m\u001b[32m a\u001b[0m\u001b[32m similarity\u001b[0m\u001b[32m score\u001b[0m\u001b[32m is\u001b[0m\u001b[32m calculated\u001b[0m\u001b[32m using\u001b[0m\u001b[32m cosine\u001b[0m\u001b[32m similarity\u001b[0m\u001b[32m.\u001b[0m"
     ]
    }
   ],
   "source": [
    "res_crawl = agent.run(\"What can you tell me about loss functions?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'answers': [   <Answer {'answer': 'The Cross-Entropy loss function is used and the similarity score is penalized if the outputs are too similar.Final Answer: The Cross-Entropy loss function is used, and a similarity score is calculated using cosine similarity.', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': None, 'meta': {}}>],\n",
      "    'query': 'What can you tell me about loss functions?',\n",
      "    'transcript': 'Tool: inovex_blog_crawler\\n'\n",
      "                  'Tool Input: \"loss functions\" \\n'\n",
      "                  'Tool: inovex_blog_crawler\\n'\n",
      "                  'Tool Input: \"loss functions\"\\n'\n",
      "                  'Observation: The chosen loss function is the Cross-Entropy '\n",
      "                  'loss function, and the loss is calculated separately for '\n",
      "                  'each encoder head. The maximum of the two losses is then '\n",
      "                  'used to compute the final loss. Additionally, a similarity '\n",
      "                  'score is calculated using cosine similarity and multiplied '\n",
      "                  'with a penalizing parameter to penalize the learning '\n",
      "                  'process if the outputs are too similar.\\n'\n",
      "                  'Thought:Final Answer: The Cross-Entropy loss function is '\n",
      "                  'used and the similarity score is penalized if the outputs '\n",
      "                  'are too similar.Final Answer: The Cross-Entropy loss '\n",
      "                  'function is used, and a similarity score is calculated '\n",
      "                  'using cosine similarity.'}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(res_crawl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Cross-Entropy loss function is used and the similarity score is penalized if the outputs are too similar.Final Answer: The Cross-Entropy loss function is used, and a similarity score is calculated using cosine similarity.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_crawl['answers'][0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent custom-at-query-time started with {'query': 'Who is the Son of Eddard?', 'params': None}\n",
      "\u001b[32mknow\u001b[0m\u001b[32m which\u001b[0m\u001b[32m E\u001b[0m\u001b[32mdd\u001b[0m\u001b[32mard\u001b[0m\u001b[32m we\u001b[0m\u001b[32m are\u001b[0m\u001b[32m talking\u001b[0m\u001b[32m about\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m games\u001b[0m\u001b[32m_of\u001b[0m\u001b[32m_th\u001b[0m\u001b[32mrones\u001b[0m\u001b[32m_Q\u001b[0m\u001b[32mA\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m \"\u001b[0m\u001b[32mWho\u001b[0m\u001b[32m is\u001b[0m\u001b[32m the\u001b[0m\u001b[32m father\u001b[0m\u001b[32m of\u001b[0m\u001b[32m Jon\u001b[0m\u001b[32m Snow\u001b[0m\u001b[32m?\"\n",
      "\u001b[0m\u001b[32mknow\u001b[0m\u001b[32m whether\u001b[0m\u001b[32m this\u001b[0m\u001b[32m is\u001b[0m\u001b[32m a\u001b[0m\u001b[32m Game\u001b[0m\u001b[32m of\u001b[0m\u001b[32m Thrones\u001b[0m\u001b[32m question\u001b[0m\u001b[32m or\u001b[0m\u001b[32m not\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m games\u001b[0m\u001b[32m_of\u001b[0m\u001b[32m_th\u001b[0m\u001b[32mrones\u001b[0m\u001b[32m_Q\u001b[0m\u001b[32mA\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m \"\u001b[0m\u001b[32mWho\u001b[0m\u001b[32m is\u001b[0m\u001b[32m the\u001b[0m\u001b[32m Son\u001b[0m\u001b[32m of\u001b[0m\u001b[32m E\u001b[0m\u001b[32mdd\u001b[0m\u001b[32mard\u001b[0m\u001b[32m?\"\n",
      "\u001b[0mObservation: \u001b[33mEddard \"Ned\" Stark is the father of Jon Snow.\u001b[0m\n",
      "Thought: \u001b[32mNow\u001b[0m\u001b[32m that\u001b[0m\u001b[32m I\u001b[0m\u001b[32m know\u001b[0m\u001b[32m we\u001b[0m\u001b[32m are\u001b[0m\u001b[32m talking\u001b[0m\u001b[32m about\u001b[0m\u001b[32m Game\u001b[0m\u001b[32m of\u001b[0m\u001b[32m Thrones\u001b[0m\u001b[32m and\u001b[0m\u001b[32m the\u001b[0m\u001b[32m father\u001b[0m\u001b[32m is\u001b[0m\u001b[32m Ned\u001b[0m\u001b[32m Stark\u001b[0m\u001b[32m,\u001b[0m\u001b[32m the\u001b[0m\u001b[32m son\u001b[0m\u001b[32m of\u001b[0m\u001b[32m E\u001b[0m\u001b[32mdd\u001b[0m\u001b[32mard\u001b[0m\u001b[32m is\u001b[0m\u001b[32m...\n",
      "\n",
      "\u001b[0m\u001b[32mFinal\u001b[0m\u001b[32m Answer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Jon\u001b[0m\u001b[32m Snow\u001b[0m\u001b[32m.\u001b[0m\u001b[32mSo\u001b[0m\u001b[32m the\u001b[0m\u001b[32m answer\u001b[0m\u001b[32m is\u001b[0m\u001b[32m Jon\u001b[0m\u001b[32m Snow\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32mFinal\u001b[0m\u001b[32m Answer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Jon\u001b[0m\u001b[32m Snow\u001b[0m\u001b[32m.\u001b[0m"
     ]
    }
   ],
   "source": [
    "res_got = agent.run(\"Who is the Son of Eddard?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jon Snow.So the answer is Jon Snow.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_got['answers'][0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
